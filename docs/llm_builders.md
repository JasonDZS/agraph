# LLM Builders ä½¿ç”¨æ•™ç¨‹

æœ¬æ•™ç¨‹å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨ agraph é¡¹ç›®ä¸­çš„å„ç§ LLM æ„å»ºå™¨æ¥æ„å»ºå’Œç®¡ç†çŸ¥è¯†å›¾è°±ã€‚è¿™äº›æ„å»ºå™¨éµå¾ªæ¥å£éš”ç¦»åŸåˆ™ï¼ˆISPï¼‰ï¼Œä¸ºä¸åŒçš„ä½¿ç”¨åœºæ™¯æä¾›äº†ä¸“é—¨çš„æ¥å£ã€‚

## æ¦‚è¿°

agraph æä¾›äº†å¤šç§ LLM æ„å»ºå™¨ï¼Œæ¯ç§éƒ½ä¸“é—¨é’ˆå¯¹ç‰¹å®šçš„ç”¨ä¾‹è®¾è®¡ï¼š

- **MinimalLLMGraphBuilder**: åŸºç¡€æ„å»ºå™¨ï¼Œåªæä¾›æœ€åŸºæœ¬çš„å›¾è°±æ„å»ºåŠŸèƒ½
- **FlexibleLLMGraphBuilder**: çµæ´»æ„å»ºå™¨ï¼Œæ”¯æŒæ„å»ºå’Œæ›´æ–°åŠŸèƒ½
- **StreamingLLMGraphBuilder**: æµå¼æ„å»ºå™¨ï¼Œæ”¯æŒå®æ—¶æ–‡æ¡£æµå¤„ç†
- **BatchLLMGraphBuilder**: æ‰¹é‡æ„å»ºå™¨ï¼Œä¼˜åŒ–å¤§é‡æ–‡æ¡£å’Œå¤šæ•°æ®æºå¤„ç†
- **LLMGraphBuilder**: å…¨åŠŸèƒ½æ„å»ºå™¨ï¼ŒåŒ…å«æ‰€æœ‰åŠŸèƒ½ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰

## å‡†å¤‡å·¥ä½œ

### ç¯å¢ƒé…ç½®

é¦–å…ˆç¡®ä¿å®‰è£…äº†å¿…è¦çš„ä¾èµ–ï¼š

```bash
# å®‰è£…å¼€å‘ä¾èµ–
make install-dev

# æˆ–è€…ç›´æ¥ä½¿ç”¨ pip
pip install -e .
```

è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
export OPENAI_API_KEY="your-openai-api-key"
export OPENAI_API_BASE="https://api.openai.com/v1"  # å¯é€‰
```

### å¯¼å…¥ä¾èµ–

```python
import asyncio
from agraph.builders.llm_builders import (
    MinimalLLMGraphBuilder,
    FlexibleLLMGraphBuilder,
    StreamingLLMGraphBuilder,
    BatchLLMGraphBuilder,
    LLMGraphBuilder,
)
from agraph.embeddings import JsonVectorStorage
from agraph.entities import Entity
from agraph.types import EntityType
from agraph.config import Settings
```

## 1. åŸºç¡€æ„å»ºå™¨ï¼ˆMinimalLLMGraphBuilderï¼‰

### é€‚ç”¨åœºæ™¯
- åªéœ€è¦ç®€å•çš„æ–‡æœ¬åˆ°å›¾è°±è½¬æ¢
- ä¸éœ€è¦æ›´æ–°ã€åˆå¹¶ã€éªŒè¯ç­‰åŠŸèƒ½
- è¿½æ±‚æœ€å°ä¾èµ–å’Œç®€å•æ€§
- è½»é‡çº§åº”ç”¨

### ä½¿ç”¨ç¤ºä¾‹

```python
async def basic_builder_example():
    # åˆ›å»ºåŸºç¡€æ„å»ºå™¨
    builder = MinimalLLMGraphBuilder(
        openai_api_key=Settings.OPENAI_API_KEY,
        openai_api_base=Settings.OPENAI_API_BASE,
        llm_model=Settings.LLM_MODEL,
        temperature=0.1,
    )

    # å‡†å¤‡æ–‡æ¡£
    texts = [
        "è‹¹æœå…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½æŠ€æœ¯å…¬å¸ï¼Œæ€»éƒ¨ä½äºåŠ åˆ©ç¦å°¼äºšå·åº“æ¯”è’‚è¯ºã€‚",
        "å²è’‚å¤«Â·ä¹”å¸ƒæ–¯æ˜¯è‹¹æœå…¬å¸çš„è”åˆåˆ›å§‹äººï¼Œä»–åœ¨2011å¹´å»ä¸–ã€‚",
        "iPhoneæ˜¯è‹¹æœå…¬å¸å¼€å‘çš„æ™ºèƒ½æ‰‹æœºäº§å“çº¿ã€‚"
    ]

    try:
        # æ„å»ºå›¾è°± - å¼‚æ­¥æ“ä½œ
        graph = await builder.build_graph(
            texts=texts,
            graph_name="basic_example_graph"
        )

        print(f"âœ… æˆåŠŸæ„å»ºåŸºç¡€å›¾è°±:")
        print(f"   - å®ä½“æ•°é‡: {len(graph.entities)}")
        print(f"   - å…³ç³»æ•°é‡: {len(graph.relations)}")
        print(f"   - å›¾è°±åç§°: {graph.name}")

        # æ˜¾ç¤ºå®ä½“ç¤ºä¾‹
        print(f"\nğŸ“‹ å®ä½“ç¤ºä¾‹:")
        for i, (entity_id, entity) in enumerate(list(graph.entities.items())[:3]):
            print(f"   {i+1}. {entity.name} ({entity.entity_type.value})")

        return graph

    except Exception as e:
        print(f"âŒ åŸºç¡€æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")
        return None

# è¿è¡Œç¤ºä¾‹
asyncio.run(basic_builder_example())
```

## 2. çµæ´»æ„å»ºå™¨ï¼ˆFlexibleLLMGraphBuilderï¼‰

### é€‚ç”¨åœºæ™¯
- éœ€è¦æ„å»ºå›¾è°±åè¿›è¡Œå¢é‡æ›´æ–°
- ä¸éœ€è¦åˆå¹¶ã€éªŒè¯ç­‰é«˜çº§åŠŸèƒ½
- è¿½æ±‚æ„å»º+æ›´æ–°çš„ç»„åˆåŠŸèƒ½
- ä¸­ç­‰å¤æ‚åº¦åº”ç”¨

### ä½¿ç”¨ç¤ºä¾‹

```python
async def flexible_builder_example():
    # åˆ›å»ºçµæ´»æ„å»ºå™¨
    builder = FlexibleLLMGraphBuilder(
        openai_api_key=Settings.OPENAI_API_KEY,
        openai_api_base=Settings.OPENAI_API_BASE,
        llm_model=Settings.LLM_MODEL,
        embedding_model=Settings.EMBEDDING_MODEL,
        vector_storage=JsonVectorStorage(file_path="workdir/vector_store.json"),
    )

    # åˆå§‹æ–‡æœ¬
    initial_texts = [
        "å¾®è½¯å…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½æŠ€æœ¯å…¬å¸ã€‚",
        "æ¯”å°”Â·ç›–èŒ¨æ˜¯å¾®è½¯å…¬å¸çš„è”åˆåˆ›å§‹äººã€‚"
    ]

    try:
        # æ„å»ºåˆå§‹å›¾è°±
        graph = await builder.build_graph(
            texts=initial_texts,
            graph_name="updatable_example_graph"
        )

        print(f"âœ… åˆå§‹å›¾è°±æ„å»ºå®Œæˆ:")
        print(f"   - åˆå§‹å®ä½“æ•°: {len(graph.entities)}")
        print(f"   - åˆå§‹å…³ç³»æ•°: {len(graph.relations)}")

        # å‡†å¤‡æ–°å®ä½“è¿›è¡Œæ›´æ–°
        new_entity = Entity(
            id="entity_new_001",
            name="Windowsæ“ä½œç³»ç»Ÿ",
            entity_type=EntityType.PRODUCT,
            description="å¾®è½¯å…¬å¸å¼€å‘çš„æ“ä½œç³»ç»Ÿ",
        )

        # æ›´æ–°å›¾è°±
        updated_graph = await builder.update_graph(
            graph=graph,
            new_entities=[new_entity],
        )

        print(f"\nğŸ”„ å›¾è°±æ›´æ–°å®Œæˆ:")
        print(f"   - æ›´æ–°åå®ä½“æ•°: {len(updated_graph.entities)}")
        print(f"   - æ›´æ–°åå…³ç³»æ•°: {len(updated_graph.relations)}")

        return updated_graph

    except Exception as e:
        print(f"âŒ å¯æ›´æ–°æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")
        return None

# è¿è¡Œç¤ºä¾‹
asyncio.run(flexible_builder_example())
```

## 3. æµå¼æ„å»ºå™¨ï¼ˆStreamingLLMGraphBuilderï¼‰

### é€‚ç”¨åœºæ™¯
- å®æ—¶å¤„ç†æµå¼åˆ°è¾¾çš„æ–‡æ¡£
- éœ€è¦æ–‡æ¡£çº§åˆ«çš„å¢åˆ æ“ä½œ
- è¿½æ±‚å¢é‡å¤„ç†èƒ½åŠ›
- å®æ—¶æ•°æ®å¤„ç†åº”ç”¨

### ä½¿ç”¨ç¤ºä¾‹

```python
async def streaming_builder_example():
    # åˆ›å»ºæµå¼æ„å»ºå™¨
    builder = StreamingLLMGraphBuilder(
        openai_api_key=Settings.OPENAI_API_KEY,
        openai_api_base=Settings.OPENAI_API_BASE,
        llm_model=Settings.LLM_MODEL,
    )

    # åˆå§‹æ–‡æ¡£
    initial_docs = [
        "è°·æ­Œå…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½æŠ€æœ¯å…¬å¸ã€‚",
        "æ‹‰é‡ŒÂ·ä½©å¥‡å’Œè°¢å°”ç›–Â·å¸ƒæ—åˆ›ç«‹äº†è°·æ­Œã€‚"
    ]

    try:
        # æ„å»ºåˆå§‹å›¾è°±
        graph = await builder.build_graph(
            texts=initial_docs,
            graph_name="streaming_example_graph"
        )

        print(f"âœ… æµå¼å›¾è°±åˆå§‹åŒ–:")
        print(f"   - åˆå§‹å®ä½“æ•°: {len(graph.entities)}")

        # æ¨¡æ‹Ÿæ–°æ–‡æ¡£åˆ°è¾¾
        new_documents = [
            "YouTubeæ˜¯è°·æ­Œæ——ä¸‹çš„è§†é¢‘åˆ†äº«å¹³å°ã€‚",
            "Androidæ˜¯è°·æ­Œå¼€å‘çš„ç§»åŠ¨æ“ä½œç³»ç»Ÿã€‚"
        ]

        # å¢é‡æ·»åŠ æ–‡æ¡£
        updated_graph = await builder.add_documents_async(
            documents=new_documents,
            document_ids=["doc_youtube", "doc_android"]
        )

        print(f"\nğŸ“„ æ–°æ–‡æ¡£å¤„ç†å®Œæˆ:")
        print(f"   - æ›´æ–°åå®ä½“æ•°: {len(updated_graph.entities)}")

        # æŸ¥çœ‹æ–‡æ¡£æ³¨å†Œè¡¨
        registry = builder.get_document_registry()
        print(f"\nğŸ“š æ–‡æ¡£æ³¨å†Œè¡¨:")
        for doc_id, entity_ids in registry.items():
            print(f"   - {doc_id}: {len(entity_ids)} ä¸ªå®ä½“")

        return updated_graph

    except Exception as e:
        print(f"âŒ æµå¼æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")
        return None

# è¿è¡Œç¤ºä¾‹
asyncio.run(streaming_builder_example())
```

## 4. æ‰¹é‡æ„å»ºå™¨ï¼ˆBatchLLMGraphBuilderï¼‰

### é€‚ç”¨åœºæ™¯
- éœ€è¦å¤„ç†å¤§é‡æ–‡æ¡£
- éœ€è¦åˆå¹¶å¤šä¸ªæ•°æ®æº
- è¿½æ±‚é«˜æ€§èƒ½æ‰¹é‡å¤„ç†
- å¤§è§„æ¨¡æ•°æ®å¤„ç†

### ä½¿ç”¨ç¤ºä¾‹

```python
async def batch_builder_example():
    # åˆ›å»ºæ‰¹é‡æ„å»ºå™¨
    builder = BatchLLMGraphBuilder(
        openai_api_key=Settings.OPENAI_API_KEY,
        openai_api_base=Settings.OPENAI_API_BASE,
        llm_model=Settings.LLM_MODEL,
        embedding_model=Settings.EMBEDDING_MODEL,
        max_concurrent=8,  # é«˜å¹¶å‘æ‰¹é‡å¤„ç†
    )

    # å¤§é‡æ–‡æ¡£ç¤ºä¾‹
    batch_texts = [
        "ç‰¹æ–¯æ‹‰æ˜¯ä¸€å®¶ç¾å›½ç”µåŠ¨æ±½è½¦åˆ¶é€ å•†ã€‚",
        "åŸƒéš†Â·é©¬æ–¯å…‹æ˜¯ç‰¹æ–¯æ‹‰çš„CEOã€‚",
        "Model Sæ˜¯ç‰¹æ–¯æ‹‰çš„è±ªåç”µåŠ¨è½¿è½¦ã€‚",
        "Autopilotæ˜¯ç‰¹æ–¯æ‹‰çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯ã€‚",
        "Gigafactoryæ˜¯ç‰¹æ–¯æ‹‰çš„ç”µæ± å·¥å‚ã€‚",
    ]

    try:
        # æ‰¹é‡æ„å»ºå›¾è°±
        graph = await builder.build_graph(
            texts=batch_texts,
            graph_name="batch_example_graph"
        )

        print(f"âœ… æ‰¹é‡å›¾è°±æ„å»ºå®Œæˆ:")
        print(f"   - å¤„ç†æ–‡æ¡£æ•°: {len(batch_texts)}")
        print(f"   - ç”Ÿæˆå®ä½“æ•°: {len(graph.entities)}")
        print(f"   - ç”Ÿæˆå…³ç³»æ•°: {len(graph.relations)}")

        # æ¼”ç¤ºå¤šæºåˆå¹¶
        sources = [
            {
                "type": "text",
                "data": ["äºšé©¬é€Šæ˜¯å…¨çƒæœ€å¤§çš„ç”µå­å•†åŠ¡å…¬å¸ã€‚"]
            },
            {
                "type": "text",
                "data": ["æ°å¤«Â·è´ä½æ–¯åˆ›ç«‹äº†äºšé©¬é€Šå…¬å¸ã€‚"]
            }
        ]

        merged_graph = await builder.build_from_multiple_sources(
            sources=sources,
            graph_name="multi_source_graph"
        )

        print(f"\nğŸ”— å¤šæºåˆå¹¶å®Œæˆ:")
        print(f"   - åˆå¹¶åå®ä½“æ•°: {len(merged_graph.entities)}")

        return merged_graph

    except Exception as e:
        print(f"âŒ æ‰¹é‡æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")
        return None

# è¿è¡Œç¤ºä¾‹
asyncio.run(batch_builder_example())
```

## 5. å…¨åŠŸèƒ½æ„å»ºå™¨ï¼ˆLLMGraphBuilderï¼‰

### é€‚ç”¨åœºæ™¯
âš ï¸ **æ³¨æ„ï¼šè¿™è¿åäº†ISPåŸåˆ™ï¼Œåªæœ‰çœŸæ­£éœ€è¦æ‰€æœ‰åŠŸèƒ½æ—¶æ‰ä½¿ç”¨ï¼**

- éœ€è¦æ‰€æœ‰åŠŸèƒ½ï¼šæ„å»ºã€æ›´æ–°ã€åˆå¹¶ã€éªŒè¯ã€å¯¼å‡º
- ä¼ä¸šçº§åº”ç”¨ï¼Œéœ€è¦å®Œæ•´åŠŸèƒ½
- å¯ä»¥æ‰¿å—é¢å¤–çš„å¤æ‚æ€§å’Œä¾èµ–

### ä½¿ç”¨ç¤ºä¾‹

```python
async def full_featured_builder_example():
    # åˆ›å»ºå…¨åŠŸèƒ½æ„å»ºå™¨
    builder = LLMGraphBuilder(
        openai_api_key=Settings.OPENAI_API_KEY,
        openai_api_base=Settings.OPENAI_API_BASE,
        llm_model=Settings.LLM_MODEL,
        embedding_model=Settings.EMBEDDING_MODEL,
        max_concurrent=10,
        vector_storage=JsonVectorStorage(file_path="workdir/full_vector_store.json"),
    )

    # å¤æ‚æ–‡æ¡£
    complex_texts = [
        "é˜¿é‡Œå·´å·´é›†å›¢æ˜¯ä¸­å›½çš„ä¸€å®¶è·¨å›½æŠ€æœ¯å…¬å¸ã€‚",
        "é©¬äº‘æ˜¯é˜¿é‡Œå·´å·´é›†å›¢çš„åˆ›å§‹äººä¹‹ä¸€ã€‚",
        "æ·˜å®æ˜¯é˜¿é‡Œå·´å·´æ——ä¸‹çš„åœ¨çº¿è´­ç‰©å¹³å°ã€‚",
        "æ”¯ä»˜å®æ˜¯é˜¿é‡Œå·´å·´çš„æ•°å­—æ”¯ä»˜å¹³å°ã€‚"
    ]

    try:
        # æ„å»ºå›¾è°±ï¼ˆè‡ªåŠ¨åŒ…å«åµŒå…¥å’ŒéªŒè¯ï¼‰
        graph = await builder.build_graph(
            texts=complex_texts,
            graph_name="full_featured_graph"
        )

        print(f"âœ… å…¨åŠŸèƒ½å›¾è°±æ„å»ºå®Œæˆ:")
        print(f"   - å®ä½“æ•°é‡: {len(graph.entities)}")
        print(f"   - å…³ç³»æ•°é‡: {len(graph.relations)}")

        # éªŒè¯å›¾è°±
        validation_result = await builder.validate_graph(graph)
        print(f"\nğŸ” å›¾è°±éªŒè¯ç»“æœ:")
        print(f"   - éªŒè¯é€šè¿‡: {validation_result.get('valid', False)}")
        if validation_result.get('issues'):
            print(f"   - å‘ç°é—®é¢˜: {len(validation_result['issues'])} ä¸ª")

        # å¯¼å‡ºå›¾è°±
        exported_data = await builder.export_to_format(graph, "json")
        print(f"\nğŸ“¤ å›¾è°±å¯¼å‡º:")
        print(f"   - å¯¼å‡ºæ ¼å¼: JSON")
        print(f"   - æ•°æ®é”®: {list(exported_data.keys())}")

        # ä¿å­˜å¯¼å‡ºæ•°æ®
        import json
        with open("workdir/full_featured_graph.json", "w", encoding="utf8") as f:
            json.dump(exported_data, f, ensure_ascii=False, indent=2)

        # è·å–è¯¦ç»†ç»Ÿè®¡
        detailed_stats = await builder.get_detailed_statistics(graph)
        print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
        for key, value in detailed_stats.items():
            if isinstance(value, (int, float)):
                print(f"   - {key}: {value}")

        # æ‰“å°ä½¿ç”¨æ‘˜è¦
        builder.print_usage_summary()

        # æ¸…ç†èµ„æº
        builder.cleanup()

        return graph

    except Exception as e:
        print(f"âŒ å…¨åŠŸèƒ½æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")
        return None

# è¿è¡Œç¤ºä¾‹
asyncio.run(full_featured_builder_example())
```

## å®Œæ•´ç¤ºä¾‹è¿è¡Œ

```python
import asyncio
from pathlib import Path

async def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸ¯ LLM ISPæ„å»ºå™¨ç¤ºä¾‹é›†åˆ")
    print("æ¼”ç¤ºInterface Segregation Principleåœ¨LLMå›¾æ„å»ºä¸­çš„åº”ç”¨")
    print("=" * 60)

    # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
    Path("./workdir").mkdir(exist_ok=True)

    try:
        # ä¾æ¬¡è¿è¡Œå„ä¸ªç¤ºä¾‹
        await basic_builder_example()
        await flexible_builder_example()
        await streaming_builder_example()
        await batch_builder_example()
        await full_featured_builder_example()

    except Exception as e:
        print(f"ç¤ºä¾‹æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

    print(f"\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
    print(f"ğŸ“ é€šè¿‡è¿™äº›ç¤ºä¾‹ï¼Œä½ å¯ä»¥çœ‹åˆ°:")
    print(f"   1. æ¯ä¸ªæ„å»ºå™¨åªå®ç°å¿…è¦çš„æ¥å£")
    print(f"   2. å®¢æˆ·ç«¯å¯ä»¥é€‰æ‹©æœ€é€‚åˆçš„æ„å»ºå™¨")
    print(f"   3. é¿å…äº†ä¸å¿…è¦çš„ä¾èµ–å’Œå¤æ‚æ€§")
    print(f"   4. éµå¾ªäº†Interface Segregation Principle")

if __name__ == "__main__":
    asyncio.run(main())
```

## é…ç½®è¯´æ˜

### Settings é…ç½®

é¡¹ç›®ä½¿ç”¨ `Settings` ç±»æ¥ç®¡ç†é…ç½®ï¼š

```python
from agraph.config import Settings

# å¸¸ç”¨è®¾ç½®
Settings.OPENAI_API_KEY      # OpenAI API å¯†é’¥
Settings.OPENAI_API_BASE     # OpenAI API åŸºç¡€URL
Settings.LLM_MODEL           # ä½¿ç”¨çš„LLMæ¨¡å‹
Settings.EMBEDDING_MODEL     # ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹
```

### å‘é‡å­˜å‚¨é…ç½®

```python
from agraph.embeddings import JsonVectorStorage

# JSONæ–‡ä»¶å­˜å‚¨
vector_storage = JsonVectorStorage(file_path="workdir/vector_store.json")

# ä¼ é€’ç»™æ„å»ºå™¨
builder = FlexibleLLMGraphBuilder(
    # ... å…¶ä»–å‚æ•°
    vector_storage=vector_storage
)
```

## æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„æ„å»ºå™¨

```python
# âœ… å¥½çš„åšæ³•ï¼šæ ¹æ®éœ€æ±‚é€‰æ‹©æœ€å°æ¥å£
if only_need_basic_build:
    builder = MinimalLLMGraphBuilder(...)
elif need_updates:
    builder = FlexibleLLMGraphBuilder(...)
elif need_streaming:
    builder = StreamingLLMGraphBuilder(...)

# âŒ é¿å…ï¼šæ€»æ˜¯ä½¿ç”¨å…¨åŠŸèƒ½æ„å»ºå™¨
# builder = LLMGraphBuilder(...)  # é™¤éçœŸçš„éœ€è¦æ‰€æœ‰åŠŸèƒ½
```

### 2. èµ„æºç®¡ç†

```python
try:
    builder = LLMGraphBuilder(...)
    graph = await builder.build_graph(...)
    # ä½¿ç”¨å›¾è°±...
finally:
    # æ¸…ç†èµ„æº
    builder.cleanup()
```

### 3. é”™è¯¯å¤„ç†

```python
try:
    graph = await builder.build_graph(texts=texts)
except Exception as e:
    logger.error(f"æ„å»ºå›¾è°±å¤±è´¥: {e}")
    # å¤„ç†é”™è¯¯...
```

### 4. å¼‚æ­¥æœ€ä½³å®è·µ

```python
# å¹¶å‘å¤„ç†å¤šä¸ªä»»åŠ¡
tasks = [
    builder1.build_graph(texts1),
    builder2.build_graph(texts2),
]
results = await asyncio.gather(*tasks, return_exceptions=True)
```

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†

```python
# âœ… ä½¿ç”¨æ‰¹é‡æ„å»ºå™¨å¤„ç†å¤§é‡æ–‡æ¡£
builder = BatchLLMGraphBuilder(max_concurrent=8)
graph = await builder.build_graph(texts=large_text_list)
```

### 2. æµå¼å¤„ç†

```python
# âœ… ä½¿ç”¨æµå¼æ„å»ºå™¨å¤„ç†å®æ—¶æ•°æ®
builder = StreamingLLMGraphBuilder()
for batch in document_stream:
    await builder.add_documents_async(batch)
```

### 3. å‘é‡å­˜å‚¨ä¼˜åŒ–

```python
# ä½¿ç”¨é«˜æ•ˆçš„å‘é‡å­˜å‚¨
vector_storage = JsonVectorStorage(
    file_path="workdir/optimized_vectors.json"
)
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **API å¯†é’¥é”™è¯¯**
   ```bash
   export OPENAI_API_KEY="your-actual-api-key"
   ```

2. **ä¾èµ–ç¼ºå¤±**
   ```bash
   make install-dev
   ```

3. **æƒé™é—®é¢˜**
   ```bash
   mkdir -p workdir
   chmod 755 workdir
   ```

4. **å†…å­˜ä¸è¶³**
   ```python
   # å‡å°‘å¹¶å‘æ•°
   builder = BatchLLMGraphBuilder(max_concurrent=2)
   ```

### è°ƒè¯•æŠ€å·§

```python
import logging
logging.basicConfig(level=logging.INFO)

# å¯ç”¨è¯¦ç»†æ—¥å¿—
builder = MinimalLLMGraphBuilder(
    # ... å…¶ä»–å‚æ•°
    verbose=True
)
```

## æ€»ç»“

é€šè¿‡æœ¬æ•™ç¨‹ï¼Œä½ å­¦ä¼šäº†ï¼š

1. **æ¥å£éš”ç¦»åŸåˆ™**ï¼šæ ¹æ®éœ€æ±‚é€‰æ‹©æœ€å°çš„å¿…è¦æ¥å£
2. **æ€§èƒ½ä¼˜åŒ–**ï¼šä½¿ç”¨åˆé€‚çš„æ„å»ºå™¨å¤„ç†ä¸åŒè§„æ¨¡çš„æ•°æ®
3. **èµ„æºç®¡ç†**ï¼šæ­£ç¡®å¤„ç†å¼‚æ­¥æ“ä½œå’Œèµ„æºæ¸…ç†
4. **é”™è¯¯å¤„ç†**ï¼šå®ç°å¥å£®çš„é”™è¯¯å¤„ç†æœºåˆ¶

é€‰æ‹©åˆé€‚çš„ LLM æ„å»ºå™¨å¯ä»¥è®©ä½ çš„çŸ¥è¯†å›¾è°±åº”ç”¨æ›´åŠ é«˜æ•ˆã€å¯ç»´æŠ¤å’Œå¯æ‰©å±•ã€‚
