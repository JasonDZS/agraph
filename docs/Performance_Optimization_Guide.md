# AGraph æ€§èƒ½ä¼˜åŒ–æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»äº† AGraph Phase 1.1 æ€§èƒ½ä¼˜åŒ–çš„å®ç°ç»†èŠ‚ã€ä½¿ç”¨æ–¹æ³•å’Œè¿ç§»æŒ‡å—ã€‚é€šè¿‡ç´¢å¼•ç³»ç»Ÿå’Œç¼“å­˜æœºåˆ¶ï¼Œæ–°çš„ä¼˜åŒ–ç‰ˆæœ¬åœ¨å¸¸è§æ“ä½œä¸Šæä¾›äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚

## ğŸš€ æ€§èƒ½æ”¹è¿›äº®ç‚¹

### æ ¸å¿ƒæ€§èƒ½æå‡

| æ“ä½œç±»å‹ | åŸå®ç°å¤æ‚åº¦ | ä¼˜åŒ–åå¤æ‚åº¦ | é¢„æœŸæå‡ |
|---------|------------|------------|---------|
| æŒ‰ç±»å‹æŸ¥è¯¢å®ä½“ | O(n) | O(1) | **10-100x** |
| è·å–å®ä½“å…³ç³» | O(m) | O(1) | **10-50x** |
| çº§è”åˆ é™¤å®ä½“ | O(n+m+p) | O(k) | **2-10x** |
| å›¾ç»Ÿè®¡è®¡ç®— | O(n*m) | O(1) ç¼“å­˜ | **20-100x** |
| è¿é€šåˆ†é‡åˆ†æ | O(n+m) | O(1) ç¼“å­˜ | **50-200x** |

> **è¯´æ˜**: n=å®ä½“æ•°, m=å…³ç³»æ•°, p=èšç±»æ•°, k=ç›¸å…³å¯¹è±¡æ•°

## ğŸ—ï¸ æ¶æ„ç»„ä»¶

### 1. IndexManager - ç´¢å¼•ç®¡ç†ç³»ç»Ÿ

```python
# æ–‡ä»¶ä½ç½®: agraph/base/indexes.py
class IndexManager:
    """ç»´æŠ¤å¤šç§ç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½"""

    def __init__(self):
        # å®ä½“ç±»å‹ç´¢å¼•: EntityType -> Set[entity_id]
        self._entity_type_index: Dict[Union[EntityType, str], Set[str]]

        # å®ä½“å…³ç³»ç´¢å¼•: entity_id -> Set[relation_id]
        self._entity_relations_index: Dict[str, Set[str]]

        # èšç±»å®ä½“ç´¢å¼•: cluster_id -> Set[entity_id]
        self._cluster_entities_index: Dict[str, Set[str]]

        # æ–‡æœ¬å—å®ä½“ç´¢å¼•: text_chunk_id -> Set[entity_id]
        self._text_chunk_entities_index: Dict[str, Set[str]]
```

**æ ¸å¿ƒåŠŸèƒ½**:
- **O(1) ç±»å‹æŸ¥è¯¢**: ç›´æ¥é€šè¿‡ç´¢å¼•æŸ¥æ‰¾ç‰¹å®šç±»å‹çš„æ‰€æœ‰å®ä½“
- **O(1) å…³ç³»æŸ¥è¯¢**: å¿«é€Ÿæ‰¾åˆ°ä¸å®ä½“ç›¸å…³çš„æ‰€æœ‰å…³ç³»
- **çº§è”åˆ é™¤ä¼˜åŒ–**: é€šè¿‡ç´¢å¼•å¿«é€Ÿå®šä½éœ€è¦æ›´æ–°çš„å¯¹è±¡
- **çº¿ç¨‹å®‰å…¨**: å†…ç½®è¯»å†™é”ä¿è¯å¹¶å‘å®‰å…¨

### 2. CacheManager - ç¼“å­˜ç®¡ç†ç³»ç»Ÿ

```python
# æ–‡ä»¶ä½ç½®: agraph/base/cache.py
class CacheManager:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨æ”¯æŒå¤šç§æ·˜æ±°ç­–ç•¥"""

    def __init__(self, max_size=1000, default_ttl=None, strategy=CacheStrategy.LRU_TTL):
        # ç¼“å­˜å­˜å‚¨
        self._cache: Dict[str, CacheEntry]

        # æ·˜æ±°ç­–ç•¥: LRU, TTL, LRU_TTL
        self.strategy = strategy
```

**æ ¸å¿ƒåŠŸèƒ½**:
- **æ™ºèƒ½ç¼“å­˜**: LRU + TTL ç»„åˆç­–ç•¥
- **æ ‡ç­¾å¤±æ•ˆ**: æ”¯æŒæŒ‰æ ‡ç­¾æ‰¹é‡å¤±æ•ˆç¼“å­˜
- **æ€§èƒ½ç›‘æ§**: å†…ç½®ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡
- **å†…å­˜æ§åˆ¶**: å¯é…ç½®å¤§å°å’Œæ·˜æ±°ç­–ç•¥

### 3. OptimizedKnowledgeGraph - ä¼˜åŒ–ç‰ˆçŸ¥è¯†å›¾è°±

```python
# æ–‡ä»¶ä½ç½®: agraph/base/optimized_graph.py
class OptimizedKnowledgeGraph(BaseModel, SerializableMixin, ImportExportMixin):
    """é›†æˆç´¢å¼•å’Œç¼“å­˜çš„ä¼˜åŒ–ç‰ˆçŸ¥è¯†å›¾è°±"""

    def __init__(self, **data):
        # ä¼˜åŒ–ç»„ä»¶
        self.index_manager = IndexManager()
        self.cache_manager = CacheManager(max_size=2000, default_ttl=300)

        # ä¼˜åŒ–ç‰ˆç®¡ç†å™¨
        self._entity_manager = OptimizedEntityManager(...)
        self._relation_manager = OptimizedRelationManager(...)
```

## ğŸ“š ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

#### 1. åˆ›å»ºä¼˜åŒ–ç‰ˆçŸ¥è¯†å›¾è°±

```python
from agraph.base.graphs.optimized import KnowledgeGraph
from agraph.base.models.entities import Entity
from agraph.base.models.relations import Relation
from agraph.base.core.types import EntityType, RelationType

# åˆ›å»ºä¼˜åŒ–ç‰ˆå›¾è°±
kg = KnowledgeGraph(name = "é«˜æ€§èƒ½çŸ¥è¯†å›¾è°±")

# æ­£å¸¸ä½¿ç”¨ï¼ŒAPI ä¿æŒå…¼å®¹
person = Entity(name = "å¼ ä¸‰", entity_type = EntityType.PERSON)
company = Entity(name = "ABCå…¬å¸", entity_type = EntityType.ORGANIZATION)

kg.add_entity(person)
kg.add_entity(company)

relation = Relation(
    head_entity = person,
    tail_entity = company,
    relation_type = RelationType.WORKS_FOR
)
kg.add_relation(relation)
```

#### 2. ä½“éªŒæ€§èƒ½æ”¹è¿›

```python
import time

# å¤§é‡æ•°æ®æµ‹è¯•
entities = []
for i in range(10000):
    entity = Entity(name=f"Person_{i}", entity_type=EntityType.PERSON)
    entities.append(entity)
    kg.add_entity(entity)

# å¿«é€Ÿç±»å‹æŸ¥è¯¢ (O(1) vs O(n))
start_time = time.time()
persons = kg.get_entities_by_type(EntityType.PERSON)
query_time = time.time() - start_time

print(f"æŸ¥è¯¢ {len(persons)} ä¸ªäººå‘˜å®ä½“è€—æ—¶: {query_time:.4f} ç§’")
# è¾“å‡º: æŸ¥è¯¢ 10000 ä¸ªäººå‘˜å®ä½“è€—æ—¶: 0.0001 ç§’ (ç´¢å¼•æŸ¥è¯¢)
```

#### 3. ç›‘æ§æ€§èƒ½æŒ‡æ ‡

```python
# è·å–è¯¦ç»†æ€§èƒ½æŒ‡æ ‡
metrics = kg.get_performance_metrics()

print("æ€§èƒ½æŒ‡æ ‡:")
print(f"æ€»æ“ä½œæ•°: {metrics['graph_metrics']['total_operations']}")
print(f"ç¼“å­˜å‘½ä¸­ç‡: {metrics['cache_statistics']['hit_ratio']:.2%}")
print(f"ç´¢å¼•å‘½ä¸­ç‡: {metrics['index_statistics']['hit_ratio']:.2%}")
print(f"å¹³å‡æ“ä½œè€—æ—¶: {metrics['optimization_summary']['average_operation_time']:.6f}ç§’")
```

### é«˜çº§åŠŸèƒ½

#### 1. ç¼“å­˜æ§åˆ¶

```python
# æ¸…é™¤æ‰€æœ‰ç¼“å­˜
kg.clear_caches()

# æ‰‹åŠ¨è§¦å‘ä¼˜åŒ–
optimization_result = kg.optimize_performance()
print(f"ä¼˜åŒ–ç»“æœ: {optimization_result}")

# é‡å»ºç´¢å¼•
kg.rebuild_indexes()
```

#### 2. è‡ªå®šä¹‰ç¼“å­˜ç­–ç•¥

```python
from agraph.base.infrastructure.cache import CacheManager, CacheStrategy

# åˆ›å»ºè‡ªå®šä¹‰ç¼“å­˜ç®¡ç†å™¨
custom_cache = CacheManager(
    max_size=5000,           # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
    default_ttl=600,         # é»˜è®¤ 10 åˆ†é’Ÿ TTL
    strategy=CacheStrategy.LRU_TTL  # LRU + TTL ç­–ç•¥
)

# åœ¨åˆ›å»ºçŸ¥è¯†å›¾è°±æ—¶ä½¿ç”¨
kg = OptimizedKnowledgeGraph()
kg.cache_manager = custom_cache
```

#### 3. æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜

```python
# å®šæœŸæ€§èƒ½æ£€æŸ¥
def monitor_performance(kg):
    metrics = kg.get_performance_metrics()
    cache_hit_ratio = metrics['cache_statistics']['hit_ratio']

    if cache_hit_ratio < 0.5:  # ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½
        print("ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œå»ºè®®è°ƒæ•´ç¼“å­˜ç­–ç•¥")
        kg.optimize_performance()

    return metrics

# è®¾ç½®å®šæ—¶ç›‘æ§
import threading
import time

def periodic_monitor():
    while True:
        metrics = monitor_performance(kg)
        time.sleep(300)  # æ¯ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

monitor_thread = threading.Thread(target=periodic_monitor, daemon=True)
monitor_thread.start()
```

## ğŸ”„ è¿ç§»æŒ‡å—

### ä»åŸç‰ˆæœ¬è¿ç§»

#### 1. å…¼å®¹æ€§ä¿è¯

âœ… **API å®Œå…¨å…¼å®¹**: æ‰€æœ‰ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯ä½¿ç”¨

```python
# åŸæœ‰ä»£ç 
from agraph.base.graphs.legacy import KnowledgeGraph

kg = KnowledgeGraph()

# æ–°ä¼˜åŒ–ç‰ˆæœ¬ - åªéœ€æ›´æ”¹å¯¼å…¥
from agraph.base.graphs.optimized import KnowledgeGraph

kg = KnowledgeGraph()  # API å®Œå…¨ç›¸åŒ

# æ‰€æœ‰åŸæœ‰æ–¹æ³•è°ƒç”¨éƒ½ä¿æŒä¸å˜
kg.add_entity(entity)
kg.get_entities_by_type(EntityType.PERSON)
# ...
```

#### 2. æ¸è¿›å¼è¿ç§»

**é˜¶æ®µ1**: è¯„ä¼°å’Œæµ‹è¯•
```python
# å¹¶è¡Œè¿è¡Œä¸¤ä¸ªç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”
original_kg = KnowledgeGraph()
optimized_kg = OptimizedKnowledgeGraph()

# åŠ è½½ç›¸åŒæ•°æ®è¿›è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•
```

**é˜¶æ®µ2**: ç”Ÿäº§ç¯å¢ƒåˆ‡æ¢

```python
# ä½¿ç”¨ç‰¹æ€§å¼€å…³æ§åˆ¶
USE_OPTIMIZED_GRAPH = True  # é…ç½®é¡¹

if USE_OPTIMIZED_GRAPH:
    from agraph.base.graphs.optimized import KnowledgeGraph as KG
else:
    from agraph.base.graphs.legacy import KnowledgeGraph as KG

kg = KG()  # ä½¿ç”¨ç»Ÿä¸€æ¥å£
```

**é˜¶æ®µ3**: å®Œå…¨è¿ç§»

```python
# å®Œå…¨åˆ‡æ¢åˆ°ä¼˜åŒ–ç‰ˆæœ¬
from agraph.base.graphs.optimized import KnowledgeGraph
```

#### 3. æ•°æ®è¿ç§»

```python
# ä»åŸç‰ˆæœ¬è¿ç§»æ•°æ®
def migrate_knowledge_graph(original_kg: KnowledgeGraph) -> OptimizedKnowledgeGraph:
    """è¿ç§»çŸ¥è¯†å›¾è°±æ•°æ®åˆ°ä¼˜åŒ–ç‰ˆæœ¬"""

    # å¯¼å‡ºåŸç‰ˆæœ¬æ•°æ®
    graph_data = original_kg.to_dict()

    # åˆ›å»ºä¼˜åŒ–ç‰ˆæœ¬å¹¶å¯¼å…¥æ•°æ®
    optimized_kg = OptimizedKnowledgeGraph.from_dict(graph_data)

    # éªŒè¯è¿ç§»ç»“æœ
    assert len(optimized_kg.entities) == len(original_kg.entities)
    assert len(optimized_kg.relations) == len(original_kg.relations)

    print(f"æˆåŠŸè¿ç§» {len(optimized_kg.entities)} ä¸ªå®ä½“å’Œ {len(optimized_kg.relations)} ä¸ªå…³ç³»")

    return optimized_kg

# ä½¿ç”¨ç¤ºä¾‹
new_kg = migrate_knowledge_graph(old_kg)
```

### é…ç½®ä¼˜åŒ–

#### 1. å†…å­˜é…ç½®

```python
# æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´ç¼“å­˜å¤§å°
import psutil

total_memory_gb = psutil.virtual_memory().total / (1024**3)

if total_memory_gb >= 16:
    cache_size = 10000  # å¤§å†…å­˜ç¯å¢ƒ
elif total_memory_gb >= 8:
    cache_size = 5000   # ä¸­ç­‰å†…å­˜ç¯å¢ƒ
else:
    cache_size = 2000   # å°å†…å­˜ç¯å¢ƒ

kg = OptimizedKnowledgeGraph()
kg.cache_manager.max_size = cache_size
```

#### 2. å¹¶å‘é…ç½®

```python
# é«˜å¹¶å‘ç¯å¢ƒé…ç½®
import threading

# ç¡®ä¿ä½¿ç”¨è¯»å†™é” (å¦‚æœå¯ç”¨)
if hasattr(threading, 'RWLock'):
    print("ä½¿ç”¨è¯»å†™é”ä¼˜åŒ–å¹¶å‘æ€§èƒ½")
else:
    print("ä½¿ç”¨æ ‡å‡†é”ï¼Œå»ºè®®å‡çº§Pythonæˆ–å®‰è£…readerwriterlock")
    # pip install readerwriterlock
```

## ğŸ§ª æ€§èƒ½æµ‹è¯•

### è¿è¡ŒåŸºå‡†æµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶
cd agraph
python -m pytest tests/test_performance_optimization.py -v

# è¿è¡Œæ€§èƒ½æ¼”ç¤º
python examples/performance_optimization_demo.py
```

### é¢„æœŸæµ‹è¯•ç»“æœ

```
=== Entity Type Query Performance ===
Original implementation: 0.0823 seconds
Optimized implementation: 0.0008 seconds
Speed improvement: 102.88x

=== Entity Removal Cascade Performance ===
Original implementation: 0.1245 seconds
Optimized implementation: 0.0034 seconds
Speed improvement: 36.62x

=== Graph Statistics Caching ===
First calculation (cold): 0.0156 seconds
Second calculation (cached): 0.0003 seconds
Cache speed improvement: 52.00x
```

### è‡ªå®šä¹‰åŸºå‡†æµ‹è¯•

```python
from agraph.base.graphs.optimized import KnowledgeGraph
import time


def custom_benchmark():
    """è‡ªå®šä¹‰æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    kg = KnowledgeGraph()

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    entities = [Entity(name = f"Test_{i}", entity_type = EntityType.CONCEPT)
                for i in range(5000)]

    # æµ‹è¯•æ‰¹é‡æ·»åŠ æ€§èƒ½
    start_time = time.time()
    for entity in entities:
        kg.add_entity(entity)
    add_time = time.time() - start_time

    # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
    start_time = time.time()
    results = kg.get_entities_by_type(EntityType.CONCEPT)
    query_time = time.time() - start_time

    print(f"æ‰¹é‡æ·»åŠ  {len(entities)} ä¸ªå®ä½“: {add_time:.4f} ç§’")
    print(f"æŸ¥è¯¢ {len(results)} ä¸ªå®ä½“: {query_time:.4f} ç§’")
    print(f"æ¯ç§’å¤„ç†èƒ½åŠ›: {len(entities) / add_time:.0f} entities/sec")


custom_benchmark()
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å†…å­˜ä½¿ç”¨è¿‡é«˜

**é—®é¢˜**: ä¼˜åŒ–ç‰ˆæœ¬å†…å­˜ä½¿ç”¨æ˜æ˜¾å¢åŠ 

**è§£å†³æ–¹æ¡ˆ**:
```python
# è°ƒæ•´ç¼“å­˜å¤§å°
kg.cache_manager.max_size = 1000  # å‡å°‘ç¼“å­˜æ¡ç›®

# å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜
kg.cache_manager.cleanup_expired()

# é‡ç½®ç¼“å­˜ç­–ç•¥
from agraph.base.infrastructure.cache import CacheStrategy
kg.cache_manager.strategy = CacheStrategy.TTL  # åªä½¿ç”¨TTLç­–ç•¥
```

#### 2. ç´¢å¼•ä¸ä¸€è‡´

**é—®é¢˜**: æŸ¥è¯¢ç»“æœä¸é¢„æœŸä¸ç¬¦

**è§£å†³æ–¹æ¡ˆ**:
```python
# é‡å»ºæ‰€æœ‰ç´¢å¼•
kg.rebuild_indexes()

# éªŒè¯ç´¢å¼•å®Œæ•´æ€§
index_stats = kg.index_manager.get_statistics()
print(f"ç´¢å¼•ç»Ÿè®¡: {index_stats}")

# æ¸…é™¤ç¼“å­˜é¿å…è„æ•°æ®
kg.clear_caches()
```

#### 3. æ€§èƒ½æå‡ä¸æ˜æ˜¾

**é—®é¢˜**: ä¼˜åŒ–æ•ˆæœä¸å¦‚é¢„æœŸ

**æ’æŸ¥æ­¥éª¤**:
```python
# æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
metrics = kg.get_performance_metrics()
cache_hit_ratio = metrics['cache_statistics']['hit_ratio']

if cache_hit_ratio < 0.3:
    print("ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½ï¼Œæ£€æŸ¥æŸ¥è¯¢æ¨¡å¼")

# æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ
index_hit_ratio = metrics['index_statistics']['hit_ratio']
if index_hit_ratio < 0.5:
    print("ç´¢å¼•ä½¿ç”¨ç‡ä½ï¼Œæ£€æŸ¥æŸ¥è¯¢ç±»å‹")

# å¯ç”¨è¯¦ç»†æ€§èƒ½æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)
```

### è°ƒè¯•å·¥å…·

#### 1. æ€§èƒ½åˆ†æå™¨

```python
import cProfile
import pstats

def profile_operations():
    """æ€§èƒ½åˆ†æç¤ºä¾‹"""
    profiler = cProfile.Profile()

    # å¼€å§‹åˆ†æ
    profiler.enable()

    # æ‰§è¡Œæ“ä½œ
    kg = OptimizedKnowledgeGraph()
    for i in range(1000):
        entity = Entity(name=f"Profile_{i}", entity_type=EntityType.PERSON)
        kg.add_entity(entity)

    results = kg.get_entities_by_type(EntityType.PERSON)

    # ç»“æŸåˆ†æ
    profiler.disable()

    # è¾“å‡ºç»“æœ
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumtime')
    stats.print_stats(10)

profile_operations()
```

#### 2. å†…å­˜åˆ†æ

```python
import tracemalloc

def memory_analysis():
    """å†…å­˜ä½¿ç”¨åˆ†æ"""
    tracemalloc.start()

    # æ‰§è¡Œæ“ä½œ
    kg = OptimizedKnowledgeGraph()
    # ... æ·»åŠ æ•°æ® ...

    # è·å–å†…å­˜å¿«ç…§
    snapshot = tracemalloc.take_snapshot()
    top_stats = snapshot.statistics('lineno')

    print("å†…å­˜ä½¿ç”¨ Top 10:")
    for stat in top_stats[:10]:
        print(stat)

memory_analysis()
```

## ğŸ“ˆ æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–å»ºè®®

- **åˆç†è®¾ç½®ç¼“å­˜å¤§å°**: æ ¹æ®å¯ç”¨å†…å­˜å’Œæ•°æ®è§„æ¨¡è°ƒæ•´
- **é€‰æ‹©åˆé€‚çš„ç¼“å­˜ç­–ç•¥**: LRU_TTL é€‚åˆå¤§å¤šæ•°åœºæ™¯
- **å®šæœŸç›‘æ§æ€§èƒ½æŒ‡æ ‡**: åŠæ—¶å‘ç°æ€§èƒ½é—®é¢˜
- **ä½¿ç”¨æ‰¹é‡æ“ä½œ**: å‡å°‘é¢‘ç¹çš„å•ä¸ªæ“ä½œ
- **é¿å…é¢‘ç¹çš„å®Œæ•´æ€§æ£€æŸ¥**: ä»…åœ¨å¿…è¦æ—¶æ‰§è¡Œ

### 2. ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
# ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®
def create_production_kg():
    kg = OptimizedKnowledgeGraph()

    # é…ç½®ç¼“å­˜
    kg.cache_manager.max_size = 10000
    kg.cache_manager.default_ttl = 1800  # 30åˆ†é’Ÿ

    # å¯ç”¨æ€§èƒ½ç›‘æ§
    def log_metrics():
        metrics = kg.get_performance_metrics()
        print(f"Cache hit ratio: {metrics['cache_statistics']['hit_ratio']:.2%}")

    return kg, log_metrics
```

### 3. å¼€å‘ç¯å¢ƒè°ƒè¯•

```python
# å¼€å‘ç¯å¢ƒé…ç½®
def create_debug_kg():
    kg = OptimizedKnowledgeGraph()

    # è¾ƒå°çš„ç¼“å­˜ä¾¿äºè°ƒè¯•
    kg.cache_manager.max_size = 100
    kg.cache_manager.default_ttl = 60

    # å¯ç”¨è¯¦ç»†æ—¥å¿—
    import logging
    logging.basicConfig(level=logging.DEBUG)

    return kg
```

## ğŸ”® æœªæ¥è®¡åˆ’

Phase 1.1 æ€§èƒ½ä¼˜åŒ–ä¸ºåç»­æ”¹è¿›å¥ å®šäº†åŸºç¡€ï¼š

- **Phase 1.2**: å†…å­˜ç®¡ç†ä¼˜åŒ–ï¼ˆè§£å†³å¾ªç¯å¼•ç”¨ï¼‰
- **Phase 1.3**: çº¿ç¨‹å®‰å…¨æ”¹è¿›ï¼ˆè¯»å†™é”æœºåˆ¶ï¼‰
- **Phase 2.1**: æ¶æ„é‡æ„ï¼ˆManager è§£è€¦ï¼‰
- **Phase 3.1**: äº‹åŠ¡æ”¯æŒï¼ˆACID ç‰¹æ€§ï¼‰

æŒç»­å…³æ³¨æ€§èƒ½ç›‘æ§æ•°æ®ï¼Œä¸ºä¸‹ä¸€é˜¶æ®µä¼˜åŒ–æä¾›æ•°æ®æ”¯æ’‘ã€‚

---

**æ€»ç»“**: Phase 1.1 æ€§èƒ½ä¼˜åŒ–é€šè¿‡ç´¢å¼•ç³»ç»Ÿå’Œç¼“å­˜æœºåˆ¶ï¼Œåœ¨ä¿æŒ API å®Œå…¨å…¼å®¹çš„å‰æä¸‹ï¼Œä¸º AGraph å¸¦æ¥äº†æ•°åå€çš„æ€§èƒ½æå‡ã€‚è¿™ä¸ºæ„å»ºå¤§è§„æ¨¡çŸ¥è¯†å›¾è°±åº”ç”¨å¥ å®šäº†åšå®åŸºç¡€ã€‚
