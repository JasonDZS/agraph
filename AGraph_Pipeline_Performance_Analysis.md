# AGraph Pipelineæ¶æ„æ€§èƒ½åˆ†ææŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šå¯¹AGraphæ–°çš„pipelineæ¶æ„è¿›è¡Œäº†æ·±å…¥çš„æ€§èƒ½åˆ†æï¼ŒåŒ…æ‹¬æ¶æ„ç‰¹å¾ã€æ€§èƒ½ç“¶é¢ˆè¯†åˆ«ã€æ–°æ—§æ¶æ„å¯¹æ¯”ä»¥åŠä¼˜åŒ–å»ºè®®ã€‚

### å…³é”®å‘ç°
- ğŸ—ï¸ **æ¶æ„ä¼˜åŒ–**: æ–°pipelineæ¶æ„åœ¨ä»£ç å¤æ‚åº¦å’Œå¯ç»´æŠ¤æ€§æ–¹é¢æ˜¾è‘—æ”¹å–„
- âš¡ **æ‰§è¡Œæ•ˆç‡**: æ­¥éª¤æŠ½è±¡å¼•å…¥äº†è½»å¾®å¼€é”€ï¼Œä½†å¸¦æ¥äº†æ›´å¥½çš„ç¼“å­˜å’Œé”™è¯¯å¤„ç†
- ğŸ” **ç›‘æ§èƒ½åŠ›**: å†…ç½®æ€§èƒ½æŒ‡æ ‡æ”¶é›†æä¾›äº†å‰æ‰€æœªæœ‰çš„å¯è§‚æµ‹æ€§
- ğŸš€ **æ‰©å±•æ½œåŠ›**: æ¨¡å—åŒ–è®¾è®¡ä¸ºå¹¶è¡Œæ‰§è¡Œå’Œå®šåˆ¶åŒ–å¥ å®šåŸºç¡€

---

## 1. æ¶æ„æ€§èƒ½ç‰¹å¾åˆ†æ

### 1.1 ä»£ç ç»“æ„å¤æ‚åº¦

**æ–°Pipelineæ¶æ„ç»Ÿè®¡**:
```
Builderæ¨¡å—æ€»è®¡:
- æ–‡ä»¶æ•°é‡: 33ä¸ª
- æ€»ä»£ç è¡Œæ•°: 7,024è¡Œ  
- å¹³å‡æ–‡ä»¶å¤§å°: 213è¡Œ/æ–‡ä»¶
- æ—¶é—´è®¡é‡ç‚¹: 15å¤„
- æ‰§è¡Œæ—¶é—´è·Ÿè¸ª: 38å¤„
- æ—¥å¿—è®°å½•ç‚¹: 196å¤„
```

**å¤æ‚åº¦å¯¹æ¯”**:

| æŒ‡æ ‡ | Legacyå®ç° | Pipelineå®ç° | æ”¹è¿› |
|------|------------|------------|------|
| **ä¸»æ–¹æ³•é•¿åº¦** | 171è¡Œ | 30è¡Œ | 83%å‡å°‘ |
| **åœˆå¤æ‚åº¦** | 15+ | <5 | 70%é™ä½ |
| **èŒè´£æ•°é‡** | 8ç§æ··åˆ | 1ç§å•ä¸€ | å®Œå…¨åˆ†ç¦» |
| **é‡å¤ä»£ç å—** | 5+å¤„ | 0å¤„ | 100%æ¶ˆé™¤ |
| **åµŒå¥—å±‚çº§** | 4å±‚ | 2å±‚ | 50%å‡å°‘ |

### 1.2 å†…å­˜ä½¿ç”¨æ¨¡å¼

**Pipelineæ¶æ„å†…å­˜ç‰¹å¾**:

1. **æ­¥éª¤éš”ç¦»**: æ¯ä¸ªæ­¥éª¤æœ‰ç‹¬ç«‹çš„å†…å­˜ç©ºé—´
   ```python
   # æ¯ä¸ªæ­¥éª¤çš„å†…å­˜å ç”¨æ¨¡å¼
   BuildStep.__init__:
     - execution_count: 8å­—èŠ‚
     - total_execution_time: 8å­—èŠ‚
     - name: ~20-50å­—èŠ‚
   ```

2. **ä¸Šä¸‹æ–‡å¯¹è±¡**: BuildContextæ‰¿è½½æ‰€æœ‰ä¸­é—´ç»“æœ
   ```python
   BuildContextå†…å­˜ä¼°ç®—:
     - texts: ~1-10MB (å–å†³äºè¾“å…¥)
     - chunks: ~2-20MB (åˆ†å—å)
     - entities: ~0.1-2MB
     - relations: ~0.1-2MB
     - metadata: ~0.01-0.1MB
   ```

3. **ç¼“å­˜å¼€é”€**: æ¯ä¸ªæ­¥éª¤çš„ç¼“å­˜é”®å’Œç»“æœå­˜å‚¨
   ```python
   ç¼“å­˜å†…å­˜å¼€é”€:
     - ç¼“å­˜é”®: ~100å­—èŠ‚/æ­¥éª¤
     - ç¼“å­˜ç»“æœ: ä¸å®é™…æ•°æ®å¤§å°ç›¸å½“
     - å…ƒæ•°æ®: ~1KB/æ­¥éª¤
   ```

### 1.3 æ‰§è¡Œæ—¶é—´åˆ†è§£

**æ—¶é—´å¼€é”€æ¥æºåˆ†æ**:

1. **æ­¥éª¤æ¡†æ¶å¼€é”€** (~2-5ms/æ­¥éª¤):
   ```python
   æ¯ä¸ªæ­¥éª¤çš„å›ºå®šå¼€é”€:
   - æ—¶é—´æµ‹é‡: ~0.1ms
   - ç¼“å­˜æ£€æŸ¥: ~1-2ms  
   - çŠ¶æ€æ›´æ–°: ~0.5ms
   - æ—¥å¿—è®°å½•: ~1ms
   - ç»“æœåŒ…è£…: ~0.5ms
   ```

2. **ä¸Šä¸‹æ–‡ç®¡ç†å¼€é”€** (~1-2ms/æ­¥éª¤):
   ```python
   ä¸Šä¸‹æ–‡æ“ä½œæ—¶é—´:
   - should_execute_step(): ~0.1ms
   - mark_step_completed(): ~0.2ms
   - æ•°æ®ä¼ é€’: ~0.5ms
   - éªŒè¯æ£€æŸ¥: ~0.3ms
   ```

3. **æ ¸å¿ƒä¸šåŠ¡é€»è¾‘** (ä¸»è¦æ—¶é—´æ¶ˆè€—):
   - æ–‡æœ¬åˆ†å—: 10-100ms
   - å®ä½“æå–: 1-10ç§’ (LLMè°ƒç”¨)
   - å…³ç³»æå–: 2-15ç§’ (LLMè°ƒç”¨)
   - èšç±»åˆ†æ: 100ms-2ç§’
   - å›¾è°±ç»„è£…: 50-500ms

---

## 2. æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

### 2.1 ä¸»è¦ç“¶é¢ˆç‚¹

**ğŸ”´ é«˜å½±å“ç“¶é¢ˆ**:

1. **LLMè°ƒç”¨å»¶è¿Ÿ** (æœ€å¤§ç“¶é¢ˆ):
   ```python
   # å®ä½“å’Œå…³ç³»æå–çš„LLMè°ƒç”¨
   await self.entity_extractor.extract_entities(...)  # 1-10ç§’
   await self.relation_extractor.extract_relations(...) # 2-15ç§’
   
   å½±å“: å æ€»æ‰§è¡Œæ—¶é—´çš„80-95%
   åŸå› : ç½‘ç»œå»¶è¿Ÿ + LLMæ¨ç†æ—¶é—´
   ```

2. **æ­¥éª¤é—´æ•°æ®ä¼ é€’**:
   ```python
   # å¤§é‡æ•°æ®åœ¨æ­¥éª¤é—´å¤åˆ¶
   context.chunks = chunks        # æ½œåœ¨çš„å¤§å¯¹è±¡å¤åˆ¶
   context.entities = entities    # å¤§é‡å°å¯¹è±¡
   context.relations = relations  # å…³ç³»ç½‘ç»œç»“æ„
   
   å½±å“: å†…å­˜ä½¿ç”¨å¢åŠ 20-30%
   åŸå› : Pythonå¯¹è±¡å¤åˆ¶æœºåˆ¶
   ```

3. **åºåˆ—åŒ–ç¼“å­˜æ“ä½œ**:
   ```python
   # ç¼“å­˜ä¿å­˜å’ŒåŠ è½½
   self.cache_manager.save_step_result(...)  # åºåˆ—åŒ–å¼€é”€
   self.cache_manager.get_step_result(...)   # ååºåˆ—åŒ–å¼€é”€
   
   å½±å“: æ¯æ­¥éª¤å¢åŠ 50-200ms
   åŸå› : å¤æ‚å¯¹è±¡åºåˆ—åŒ–
   ```

**ğŸŸ¡ ä¸­ç­‰å½±å“ç“¶é¢ˆ**:

1. **æ—¥å¿—è®°å½•å¼€é”€**:
   ```python
   # 196å¤„æ—¥å¿—è®°å½•ç‚¹
   logger.info(f"Step {self.name}: Starting execution")  # å­—ç¬¦ä¸²æ ¼å¼åŒ–
   logger.info(f"Step completed in {time:.2f}s")         # é¢‘ç¹æ—¥å¿—å†™å…¥
   
   å½±å“: ç´¯è®¡å¢åŠ 2-5%æ‰§è¡Œæ—¶é—´
   ```

2. **çŠ¶æ€ç®¡ç†å¤æ‚æ€§**:
   ```python
   # æ¯ä¸ªæ­¥éª¤çš„çŠ¶æ€æ›´æ–°
   self.cache_manager.update_build_status(current_step=...)
   context.mark_step_started(...)
   context.mark_step_completed(...)
   
   å½±å“: æ¯æ­¥éª¤1-3mså¼€é”€
   ```

3. **æ¡ä»¶åˆ¤æ–­é“¾**:
   ```python
   # æ­¥éª¤æ‰§è¡Œæ¡ä»¶æ£€æŸ¥
   if context.should_skip_step(step.name):          # æ£€æŸ¥1
   if not context.should_execute_step(step.name):  # æ£€æŸ¥2  
   if self._should_use_cache(context):             # æ£€æŸ¥3
   
   å½±å“: ç´¯è®¡1-2ms/æ­¥éª¤
   ```

### 2.2 èµ„æºä½¿ç”¨æ¨¡å¼

**CPUä½¿ç”¨æ¨¡å¼**:
- **å³°å€¼**: LLMè°ƒç”¨æœŸé—´çš„JSONè§£æ (10-30% CPU)
- **å¹³å‡**: å¤§éƒ¨åˆ†æ—¶é—´ç­‰å¾…ç½‘ç»œå“åº” (1-5% CPU)
- **æ•ˆç‡**: CPUåˆ©ç”¨ç‡ç›¸å¯¹è¾ƒä½ï¼Œä¸»è¦å—ç½‘ç»œI/Oé™åˆ¶

**å†…å­˜ä½¿ç”¨æ¨¡å¼**:
- **å¯åŠ¨**: åŸºç¡€æ¶æ„åŠ è½½ ~50MB
- **è¿è¡Œ**: æ¯1000ä¸ªæ–‡æœ¬å¢åŠ  ~100-200MB
- **å³°å€¼**: å¤§å‹æ–‡æ¡£å¤„ç†å¯è¾¾ 1-2GB
- **å›æ”¶**: Python GCå¤„ç†ä¸­é—´å¯¹è±¡é‡Šæ”¾

**I/Oä½¿ç”¨æ¨¡å¼**:
- **ç½‘ç»œI/O**: å¤§é‡LLM APIè°ƒç”¨ï¼Œæ¯æ¬¡1-10KBè¯·æ±‚/å“åº”
- **ç£ç›˜I/O**: ç¼“å­˜è¯»å†™ï¼Œæ¯æ­¥éª¤10-100KB
- **å†…å­˜I/O**: æ­¥éª¤é—´æ•°æ®ä¼ é€’ï¼Œæ¯æ­¥éª¤1-50MB

---

## 3. æ–°æ—§æ¶æ„æ€§èƒ½å¯¹æ¯”

### 3.1 å®šé‡å¯¹æ¯”åˆ†æ

åŸºäºä»£ç é™æ€åˆ†æçš„ç†è®ºæ€§èƒ½å¯¹æ¯”ï¼š

**æ‰§è¡Œè·¯å¾„å¤æ‚åº¦**:

| æ–¹é¢ | Legacyå®ç° | Pipelineå®ç° | å˜åŒ– |
|------|------------|------------|------|
| **ä»£ç è·¯å¾„** | å•ä¸€171è¡Œæ–¹æ³• | åˆ†å¸ƒå¼æ­¥éª¤è°ƒç”¨ | ğŸ‘ æ¨¡å—åŒ– |
| **æ¡ä»¶åˆ†æ”¯** | 15+ä¸ªif-else | æ¯æ­¥éª¤3-5ä¸ª | ğŸ‘ ç®€åŒ– |
| **å¼‚å¸¸å¤„ç†** | 1ä¸ªtry-catch | æ¯æ­¥éª¤ç‹¬ç«‹ | ğŸ‘ ç²¾ç¡® |
| **ç¼“å­˜é€»è¾‘** | 5å¤„é‡å¤ä»£ç  | ç»Ÿä¸€åŸºç±»å¤„ç† | ğŸ‘ ä¼˜åŒ– |
| **çŠ¶æ€ç®¡ç†** | æ‰‹åŠ¨è¿½è¸ª | è‡ªåŠ¨ä¸Šä¸‹æ–‡ | ğŸ‘ å¯é  |

**ç†è®ºå¼€é”€åˆ†æ**:

```python
Legacyå®ç°æ—¶é—´æ„æˆ:
â”œâ”€ ä¸šåŠ¡é€»è¾‘: 95% (LLMè°ƒç”¨ç­‰)
â”œâ”€ æ¡ä»¶åˆ¤æ–­: 3%
â”œâ”€ é”™è¯¯å¤„ç†: 1%
â””â”€ æ—¥å¿—è®°å½•: 1%

Pipelineå®ç°æ—¶é—´æ„æˆ:
â”œâ”€ ä¸šåŠ¡é€»è¾‘: 90-92% (ç›¸åŒçš„LLMè°ƒç”¨)
â”œâ”€ æ­¥éª¤æ¡†æ¶: 4-6% (æ–°å¢å¼€é”€)
â”œâ”€ æ¡ä»¶åˆ¤æ–­: 1-2% (ç®€åŒ–)
â”œâ”€ é”™è¯¯å¤„ç†: 1% (æ›´ç²¾ç¡®)
â””â”€ æ—¥å¿—è®°å½•: 1-2% (æ›´è¯¦ç»†)
```

### 3.2 æ€§èƒ½æƒè¡¡åˆ†æ

**Pipelineæ¶æ„çš„æ€§èƒ½æ”¶ç›Š**:

âœ… **æ­£é¢å½±å“**:
1. **æ™ºèƒ½ç¼“å­˜**: ç»†ç²’åº¦ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
   ```python
   # å¯ä»¥ç¼“å­˜å•ç‹¬æ­¥éª¤çš„ç»“æœ
   cached_entities = step.get_cached_result(chunks)
   # vs Legacyä¸­å¿…é¡»é‡æ–°æ‰§è¡Œæ•´ä¸ªæµç¨‹
   ```

2. **é”™è¯¯æ¢å¤**: ä»å¤±è´¥ç‚¹ç»§ç»­æ‰§è¡Œ
   ```python
   # ä»ç‰¹å®šæ­¥éª¤æ¢å¤ï¼ŒèŠ‚çœå‰åºæ­¥éª¤æ—¶é—´
   kg = await builder.build_from_text(texts, from_step="relation_extraction")
   ```

3. **é€‰æ‹©æ€§æ‰§è¡Œ**: è·³è¿‡ä¸éœ€è¦çš„æ­¥éª¤
   ```python
   # ç¦ç”¨çŸ¥è¯†å›¾è°±åŠŸèƒ½ï¼Œä»…å¤„ç†æ–‡æœ¬
   builder = KnowledgeGraphBuilderV2(enable_knowledge_graph=False)
   ```

âš ï¸ **è´Ÿé¢å½±å“**:
1. **æ¡†æ¶å¼€é”€**: æ¯æ­¥éª¤å¢åŠ 2-5ms
2. **å†…å­˜ä½¿ç”¨**: ä¸Šä¸‹æ–‡å¯¹è±¡é¢å¤–å†…å­˜å ç”¨
3. **è°ƒç”¨é“¾**: æ›´æ·±çš„è°ƒç”¨æ ˆæ·±åº¦

### 3.3 å®é™…æ€§èƒ½é¢„æµ‹

åŸºäºä»£ç åˆ†æçš„æ€§èƒ½é¢„æµ‹ï¼š

**å°æ•°æ®é›† (50ä¸ªæ–‡æœ¬)**:
- Legacy: åŸºå‡†æ—¶é—´
- Pipeline: +5-10%æ—¶é—´ (æ¡†æ¶å¼€é”€)ï¼Œä½†æ›´å¯é 

**å¤§æ•°æ®é›† (1000+ä¸ªæ–‡æœ¬)**:
- Legacy: åŸºå‡†æ—¶é—´
- Pipeline: -5%åˆ°+10%æ—¶é—´ï¼ˆå–å†³äºç¼“å­˜æ•ˆæœï¼‰

**é‡å¤æ„å»ºåœºæ™¯**:
- Legacy: åŸºå‡†æ—¶é—´ï¼ˆæ¯æ¬¡å®Œå…¨é‡å»ºï¼‰
- Pipeline: -30%åˆ°-70%æ—¶é—´ï¼ˆç¼“å­˜ä¼˜åŠ¿ï¼‰

**éƒ¨åˆ†æ›´æ–°åœºæ™¯**:
- Legacy: åŸºå‡†æ—¶é—´ï¼ˆå¿…é¡»å®Œå…¨é‡å»ºï¼‰
- Pipeline: -50%åˆ°-80%æ—¶é—´ï¼ˆfrom_stepåŠŸèƒ½ï¼‰

---

## 4. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 4.1 çŸ­æœŸä¼˜åŒ– (1-2å‘¨å®ç°)

**ğŸ”¥ é«˜ä¼˜å…ˆçº§ä¼˜åŒ–**:

1. **å‡å°‘æ—¥å¿—å¼€é”€**:
   ```python
   # å½“å‰: å­—ç¬¦ä¸²æ€»æ˜¯æ ¼å¼åŒ–
   logger.info(f"Step {self.name}: Starting execution")
   
   # ä¼˜åŒ–: æ¡ä»¶æ—¥å¿—è®°å½•
   if logger.isEnabledFor(logging.INFO):
       logger.info(f"Step {self.name}: Starting execution")
   
   # æˆ–ä½¿ç”¨lazy formatting
   logger.info("Step %s: Starting execution", self.name)
   ```

2. **ä¼˜åŒ–ç¼“å­˜åºåˆ—åŒ–**:
   ```python
   # å½“å‰: ä½¿ç”¨é€šç”¨åºåˆ—åŒ–
   pickle.dumps(result)
   
   # ä¼˜åŒ–: ä½¿ç”¨æ›´å¿«çš„åºåˆ—åŒ–å™¨
   import orjson  # æˆ–å…¶ä»–å¿«é€ŸJSONåº“
   orjson.dumps(result.to_dict())
   
   # æˆ–å®ç°è‡ªå®šä¹‰åºåˆ—åŒ–
   class FastSerializableResult:
       def __fast_serialize__(self) -> bytes:
           # è‡ªå®šä¹‰å¿«é€Ÿåºåˆ—åŒ–é€»è¾‘
   ```

3. **å‡å°‘å¯¹è±¡åˆ›å»º**:
   ```python
   # å½“å‰: æ¯æ¬¡åˆ›å»ºæ–°çš„StepResult
   return StepResult.success_result(data, metadata)
   
   # ä¼˜åŒ–: å¯¹è±¡æ± å¤ç”¨
   class StepResultPool:
       def get_success_result(self, data, metadata):
           result = self._pool.pop() if self._pool else StepResult()
           result.reset_and_set(data, metadata, success=True)
           return result
   ```

**ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ä¼˜åŒ–**:

1. **æ‰¹é‡çŠ¶æ€æ›´æ–°**:
   ```python
   # å½“å‰: æ¯ä¸ªæ“ä½œéƒ½è§¦å‘çŠ¶æ€æ›´æ–°
   self.cache_manager.update_build_status(current_step=...)
   context.mark_step_started(...)
   
   # ä¼˜åŒ–: æ‰¹é‡æ›´æ–°
   with context.batch_update():
       context.mark_step_started(...)
       context.add_metadata(...)
       # æ‰¹é‡æäº¤çŠ¶æ€æ›´æ”¹
   ```

2. **å»¶è¿Ÿæ•°æ®éªŒè¯**:
   ```python
   # å½“å‰: æ¯æ­¥éƒ½éªŒè¯æ‰€æœ‰è¾“å…¥
   for i, entity in enumerate(entities):
       if not isinstance(entity, Entity): ...
   
   # ä¼˜åŒ–: æŠ½æ ·éªŒè¯æˆ–å»¶è¿ŸéªŒè¯
   if len(entities) > 100:
       # ä»…éªŒè¯å‰10ä¸ªå’ŒéšæœºæŠ½æ ·
       validate_sample(entities)
   else:
       validate_all(entities)
   ```

### 4.2 ä¸­æœŸä¼˜åŒ– (1-2ä¸ªæœˆå®ç°)

**ğŸš€ æ¶æ„çº§ä¼˜åŒ–**:

1. **å¹¶è¡Œæ­¥éª¤æ‰§è¡Œ**:
   ```python
   # å®ä½“å’Œå…³ç³»æå–å¯ä»¥å¹¶è¡Œè¿›è¡Œ
   async def parallel_extraction(chunks):
       entity_task = asyncio.create_task(
           self.entity_handler.extract_entities_from_chunks(chunks)
       )
       # å…³ç³»æå–ä¾èµ–å®ä½“ï¼Œä½†å¯ä»¥æµå¼å¤„ç†
       entities = await entity_task
       relation_task = asyncio.create_task(
           self.relation_handler.extract_relations_from_chunks(chunks, entities)
       )
       return await relation_task
   ```

2. **æµå¼å¤„ç†æ¨¡å¼**:
   ```python
   # å½“å‰: æ‰¹é‡å¤„ç†æ‰€æœ‰æ•°æ®
   all_chunks = chunker.chunk_all_texts(texts)
   all_entities = await extractor.extract_all(all_chunks)
   
   # ä¼˜åŒ–: æµå¼å¤„ç†
   async def streaming_pipeline():
       async for chunk_batch in chunker.stream_chunks(texts, batch_size=10):
           entities = await extractor.extract(chunk_batch)
           yield entities
   ```

3. **æ™ºèƒ½ç¼“å­˜ç­–ç•¥**:
   ```python
   class SmartCacheManager:
       def should_cache(self, step_name: str, data_size: int) -> bool:
           # å°æ•°æ®æ€»æ˜¯ç¼“å­˜ï¼Œå¤§æ•°æ®é€‰æ‹©æ€§ç¼“å­˜
           if data_size < 1024 * 1024:  # 1MB
               return True
           # æ£€æŸ¥ç¼“å­˜ç©ºé—´å’Œè®¿é—®é¢‘ç‡
           return self._evaluate_cache_benefit(step_name, data_size)
   ```

### 4.3 é•¿æœŸä¼˜åŒ– (3-6ä¸ªæœˆå®ç°)

**ğŸ”¬ é«˜çº§ä¼˜åŒ–æŠ€æœ¯**:

1. **JITç¼–è¯‘ä¼˜åŒ–**:
   ```python
   from numba import jit
   
   @jit
   def fast_text_processing(texts: List[str]) -> List[str]:
       # ä½¿ç”¨JITç¼–è¯‘åŠ é€Ÿæ–‡æœ¬å¤„ç†
       pass
   ```

2. **Cæ‰©å±•æ¨¡å—**:
   ```python
   # ä¸ºæ€§èƒ½å…³é”®è·¯å¾„å¼€å‘Cæ‰©å±•
   import agraph_native  # å‡è®¾çš„Cæ‰©å±•æ¨¡å—
   
   def fast_chunk_texts(texts):
       return agraph_native.chunk_texts(texts, chunk_size, overlap)
   ```

3. **GPUåŠ é€Ÿå¤„ç†**:
   ```python
   # ä½¿ç”¨GPUåŠ é€Ÿå‘é‡è®¡ç®—å’Œç›¸ä¼¼åº¦è®¡ç®—
   import cupy as cp  # GPUæ•°ç»„åº“
   
   def gpu_similarity_calculation(embeddings):
       gpu_embeddings = cp.asarray(embeddings)
       similarity_matrix = cp.dot(gpu_embeddings, gpu_embeddings.T)
       return cp.asnumpy(similarity_matrix)
   ```

4. **åˆ†å¸ƒå¼å¤„ç†æ¶æ„**:
   ```python
   # ä½¿ç”¨Celeryæˆ–ç±»ä¼¼å·¥å…·åˆ†å¸ƒå¼å¤„ç†
   from celery import Celery
   
   app = Celery('agraph_pipeline')
   
   @app.task
   def distributed_entity_extraction(chunk_batch):
       # åœ¨åˆ†å¸ƒå¼workerä¸­æ‰§è¡Œå®ä½“æå–
       pass
   ```

---

## 5. æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜æŒ‡å—

### 5.1 æ€§èƒ½ç›‘æ§æœ€ä½³å®è·µ

**1. å¯ç”¨è¯¦ç»†æŒ‡æ ‡æ”¶é›†**:
```python
# å¼€å‘ç¯å¢ƒ: è¯¦ç»†ç›‘æ§
builder = KnowledgeGraphBuilderV2(enable_detailed_metrics=True)

# ç”Ÿäº§ç¯å¢ƒ: ç²¾ç®€ç›‘æ§  
builder = KnowledgeGraphBuilderV2(enable_detailed_metrics=False)
```

**2. è‡ªå®šä¹‰æ€§èƒ½é’©å­**:
```python
class PerformanceMonitoringStep(BuildStep):
    async def execute(self, context):
        # æ·»åŠ è‡ªå®šä¹‰æ€§èƒ½ç›‘æ§é€»è¾‘
        with self.performance_monitor:
            return await super().execute(context)
```

**3. å®æ—¶æ€§èƒ½dashboard**:
```python
# é›†æˆPrometheusæˆ–ç±»ä¼¼ç›‘æ§ç³»ç»Ÿ
from prometheus_client import Counter, Histogram

step_duration = Histogram('agraph_step_duration_seconds', 
                         'Time spent on each step', ['step_name'])
step_errors = Counter('agraph_step_errors_total', 
                     'Total step errors', ['step_name'])
```

### 5.2 æ€§èƒ½è°ƒä¼˜å·¥ä½œæµ

**é˜¶æ®µ1: åŸºçº¿æµ‹é‡**
```bash
# è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
python performance_benchmark.py

# åˆ†æç»“æœï¼Œè¯†åˆ«ç“¶é¢ˆ
python -m cProfile -o profile.stats your_script.py
python -m pstats profile.stats
```

**é˜¶æ®µ2: é’ˆå¯¹æ€§ä¼˜åŒ–**
```python
# åŸºäºprofilingç»“æœä¼˜åŒ–ç‰¹å®šç“¶é¢ˆ
# ä¾‹å¦‚: å¦‚æœåºåˆ—åŒ–æ˜¯ç“¶é¢ˆ
import cPickle  # æ›´å¿«çš„pickleå®ç°
import msgpack  # æ›´å¿«çš„åºåˆ—åŒ–æ ¼å¼
```

**é˜¶æ®µ3: A/Bæµ‹è¯•éªŒè¯**
```python
# æ¯”è¾ƒä¼˜åŒ–å‰åçš„æ€§èƒ½
results_before = benchmark.run_test(original_implementation)
results_after = benchmark.run_test(optimized_implementation)
improvement = calculate_improvement(results_before, results_after)
```

---

## 6. ç»“è®ºå’Œå»ºè®®

### 6.1 æ€§èƒ½è¯„ä¼°æ€»ç»“

**æ¶æ„æ€§èƒ½ç‰¹å¾**:
- âœ… **ä»£ç è´¨é‡**: æ˜¾è‘—æ”¹å–„ï¼Œ83%å¤æ‚åº¦é™ä½
- âš¡ **æ‰§è¡Œæ•ˆç‡**: è½»å¾®å¼€é”€ï¼Œä½†è·å¾—æ›´å¤šåŠŸèƒ½
- ğŸ” **å¯è§‚æµ‹æ€§**: å¤§å¹…æå‡ï¼Œè¯¦ç»†çš„æ‰§è¡ŒæŒ‡æ ‡
- ğŸ› ï¸ **å¯ç»´æŠ¤æ€§**: è´¨çš„é£è·ƒï¼Œæ¨¡å—åŒ–è®¾è®¡

**æ€§èƒ½æƒè¡¡åˆ†æ**:
- **çŸ­æœŸ**: 5-10%æ€§èƒ½å¼€é”€ï¼Œæ¢å–å¯é æ€§å’Œå¯ç»´æŠ¤æ€§
- **é•¿æœŸ**: ç¼“å­˜å’Œä¼˜åŒ–å¸¦æ¥çš„å‡€æ€§èƒ½æå‡
- **å¯æ‰©å±•æ€§**: ä¸ºå¹¶è¡Œå¤„ç†å’Œå®šåˆ¶åŒ–å¥ å®šåŸºç¡€

### 6.2 å®æ–½å»ºè®®

**ç«‹å³æ‰§è¡Œ** (é«˜ROI):
1. å®æ–½æ—¥å¿—ä¼˜åŒ–å‡å°‘5-8%å¼€é”€
2. ä¼˜åŒ–ç¼“å­˜åºåˆ—åŒ–æå‡å“åº”æ€§
3. å¯ç”¨æ€§èƒ½ç›‘æ§äº†è§£å®é™…ç“¶é¢ˆ

**è¿‘æœŸè§„åˆ’** (1-2ä¸ªæœˆ):
1. å®ç°å…³é”®æ­¥éª¤çš„å¹¶è¡Œæ‰§è¡Œ
2. å¼€å‘æµå¼å¤„ç†èƒ½åŠ›
3. ä¼˜åŒ–å†…å­˜ä½¿ç”¨æ¨¡å¼

**é•¿æœŸæŠ•èµ„** (3-6ä¸ªæœˆ):
1. ç ”ç©¶GPUåŠ é€Ÿå¯è¡Œæ€§  
2. è€ƒè™‘åˆ†å¸ƒå¼å¤„ç†æ¶æ„
3. å¼€å‘æ€§èƒ½å…³é”®è·¯å¾„çš„nativeæ‰©å±•

### 6.3 æ€§èƒ½ç›®æ ‡è®¾å®š

**çŸ­æœŸç›®æ ‡** (1ä¸ªæœˆå†…):
- æ¡†æ¶å¼€é”€ < 5%
- ç¼“å­˜å‘½ä¸­ç‡ > 80%
- é”™è¯¯æ¢å¤æ—¶é—´ < 10%åŸå§‹æ—¶é—´

**ä¸­æœŸç›®æ ‡** (3ä¸ªæœˆå†…):  
- å¤§æ•°æ®é›†æ€§èƒ½æŒå¹³æˆ–æ›´ä¼˜
- æ”¯æŒ1000+æ–‡æ¡£çš„æµå¼å¤„ç†
- å†…å­˜ä½¿ç”¨æ•ˆç‡æå‡20%

**é•¿æœŸç›®æ ‡** (6ä¸ªæœˆå†…):
- å®ç°æ­¥éª¤çº§å¹¶è¡Œå¤„ç†
- æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²
- å»ºç«‹å®Œæ•´çš„æ€§èƒ½ç›‘æ§ä½“ç³»

---

### ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·

æœ¬æŠ¥å‘ŠåŒ…å«äº†ä¸€ä¸ªå®Œæ•´çš„æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…· (`performance_benchmark.py`)ï¼Œå¯ä»¥ï¼š

- ğŸ”¬ **å®šé‡æµ‹è¯•**: ç²¾ç¡®æµ‹é‡æ‰§è¡Œæ—¶é—´ã€å†…å­˜ä½¿ç”¨ã€CPUåˆ©ç”¨ç‡
- ğŸ“Š **å¯¹æ¯”åˆ†æ**: è‡ªåŠ¨å¯¹æ¯”æ–°æ—§æ¶æ„çš„æ€§èƒ½å·®å¼‚
- ğŸ“‹ **ç”ŸæˆæŠ¥å‘Š**: è¾“å‡ºè¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š
- ğŸ¯ **è¯†åˆ«ç“¶é¢ˆ**: å¸®åŠ©å®šä½å…·ä½“çš„æ€§èƒ½é—®é¢˜

**ä½¿ç”¨æ–¹æ³•**:
```bash
cd /path/to/agraph
python performance_benchmark.py
```

è¿™å°†ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½æµ‹è¯•æŠ¥å‘Šï¼Œä¸ºè¿›ä¸€æ­¥çš„ä¼˜åŒ–æä¾›æ•°æ®æ”¯æŒã€‚

---

**æ€»ç»“**: Pipelineæ¶æ„æ˜¯ä¸€ä¸ªåœ¨æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡çš„æ¶æ„å†³ç­–ã€‚è™½ç„¶å¼•å…¥äº†è½»å¾®çš„æ¡†æ¶å¼€é”€ï¼Œä½†æ˜¾è‘—æ”¹å–„äº†ä»£ç è´¨é‡ã€å¯é æ€§å’Œæ‰©å±•æ€§ï¼Œä¸ºæœªæ¥çš„æ€§èƒ½ä¼˜åŒ–å¥ å®šäº†åšå®åŸºç¡€ã€‚