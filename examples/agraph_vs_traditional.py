#!/usr/bin/env python3
"""
AGraph vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”ç¤ºä¾‹

æ­¤ç¤ºä¾‹å¯¹æ¯”å±•ç¤ºï¼š
1. ä¼ ç»Ÿçš„æ–‡æœ¬æ£€ç´¢æ–¹æ³•
2. AGraphçš„çŸ¥è¯†å›¾è°±å¢å¼ºæ£€ç´¢
3. ä¸¤ç§æ–¹æ³•åœ¨é—®ç­”ä»»åŠ¡ä¸Šçš„å·®å¼‚
4. AGraphçš„ä¼˜åŠ¿å’Œåº”ç”¨åœºæ™¯

å¸®åŠ©ç”¨æˆ·ç†è§£AGraphçš„ä»·å€¼å’Œé€‚ç”¨åœºæ™¯ã€‚
"""

import asyncio
import re
import sys
from pathlib import Path
from typing import List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agraph import AGraph


class TraditionalSearch:
    """ä¼ ç»Ÿæ–‡æœ¬æ£€ç´¢æ–¹æ³•"""

    def __init__(self, documents: List[str]):
        self.documents = documents
        self.processed_docs = [self._preprocess(doc) for doc in documents]

    def _preprocess(self, text: str) -> str:
        """ç®€å•çš„æ–‡æœ¬é¢„å¤„ç†"""
        # è½¬ä¸ºå°å†™ï¼Œç§»é™¤æ ‡ç‚¹ç¬¦å·
        return re.sub(r'[^\w\s]', '', text.lower())

    def search(self, query: str, top_k: int = 3) -> List[Tuple[str, float]]:
        """åŸºäºå…³é”®è¯åŒ¹é…çš„ç®€å•æœç´¢"""
        query_processed = self._preprocess(query)
        query_words = set(query_processed.split())

        results = []
        for i, doc in enumerate(self.processed_docs):
            doc_words = set(doc.split())
            # è®¡ç®—ç®€å•çš„è¯æ±‡é‡å åˆ†æ•°
            overlap = len(query_words & doc_words)
            score = overlap / len(query_words) if query_words else 0
            results.append((self.documents[i], score))

        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›top_k
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:top_k]

    def answer_question(self, question: str) -> str:
        """åŸºäºæ£€ç´¢ç»“æœçš„ç®€å•é—®ç­”"""
        results = self.search(question, top_k=1)
        if results and results[0][1] > 0:
            # è¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
            doc = results[0][0]
            sentences = doc.split('ã€‚')
            # è¿”å›ç¬¬ä¸€ä¸ªå¥å­ä½œä¸ºç­”æ¡ˆ
            return sentences[0] + "ã€‚" if sentences else "æ— æ³•æ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚"
        return "æ— æ³•æ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚"


class ComparisonDemo:
    """AGraph vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”æ¼”ç¤º"""

    def __init__(self):
        self.sample_documents = [
            "è‹¹æœå…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½ç§‘æŠ€å…¬å¸ï¼Œæ€»éƒ¨ä½äºåŠ åˆ©ç¦å°¼äºšå·åº“æ¯”è’‚è¯ºã€‚å…¬å¸ç”±å²è’‚å¤«Â·ä¹”å¸ƒæ–¯ã€å²è’‚å¤«Â·æ²ƒå…¹å°¼äºšå…‹å’Œç½—çº³å¾·Â·éŸ¦æ©äº1976å¹´4æœˆ1æ—¥åˆ›ç«‹ã€‚",

            "iPhoneæ˜¯è‹¹æœå…¬å¸è®¾è®¡å’Œé”€å”®çš„æ™ºèƒ½æ‰‹æœºç³»åˆ—ã€‚ç¬¬ä¸€ä»£iPhoneäº2007å¹´1æœˆ9æ—¥ç”±å²è’‚å¤«Â·ä¹”å¸ƒæ–¯å‘å¸ƒï¼Œå½»åº•æ”¹å˜äº†ç§»åŠ¨é€šä¿¡è¡Œä¸šã€‚",

            "å²è’‚å¤«Â·ä¹”å¸ƒæ–¯æ˜¯è‹¹æœå…¬å¸çš„è”åˆåˆ›å§‹äººå’Œå‰é¦–å¸­æ‰§è¡Œå®˜ã€‚ä»–ä»¥å…¶åˆ›æ–°çš„äº§å“è®¾è®¡å’Œè¥é”€ç­–ç•¥è€Œé—»åï¼Œè¢«è®¤ä¸ºæ˜¯ä¸ªäººç”µè„‘é©å‘½çš„å…ˆé©±äººç‰©ã€‚",

            "iPadæ˜¯è‹¹æœå…¬å¸å¼€å‘çš„å¹³æ¿ç”µè„‘ç³»åˆ—ï¼Œäº2010å¹´é¦–æ¬¡å‘å¸ƒã€‚iPadå¼€åˆ›äº†ç°ä»£å¹³æ¿ç”µè„‘å¸‚åœºï¼Œå¹¿æ³›åº”ç”¨äºæ•™è‚²ã€å•†åŠ¡å’Œå¨±ä¹ã€‚",

            "macOSæ˜¯è‹¹æœå…¬å¸ä¸ºMacè®¡ç®—æœºå¼€å‘çš„ä¸“æœ‰æ“ä½œç³»ç»Ÿã€‚å®ƒä»¥å…¶ç›´è§‚çš„ç”¨æˆ·ç•Œé¢å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œå—åˆ°ç”¨æˆ·å–œçˆ±ã€‚",

            "App Storeæ˜¯è‹¹æœå…¬å¸ä¸ºiOSè®¾å¤‡å¼€å‘çš„æ•°å­—å‘è¡Œå¹³å°ï¼Œäº2008å¹´æ¨å‡ºã€‚å¼€å‘è€…å¯ä»¥é€šè¿‡App Storeå‘ç”¨æˆ·åˆ†å‘åº”ç”¨ç¨‹åºã€‚",

            "è‹¹æœå…¬å¸åœ¨åº“æ¯”è’‚è¯ºçš„æ€»éƒ¨è¢«ç§°ä¸ºApple Parkï¼Œäº2017å¹´å¼€æ”¾ã€‚è¿™ä¸ªç¯å½¢å»ºç­‘ä½“ç°äº†è‹¹æœå…¬å¸å¯¹è®¾è®¡å’Œå¯æŒç»­å‘å±•çš„æ‰¿è¯ºã€‚"
        ]

        self.test_questions = [
            "è‹¹æœå…¬å¸æ˜¯ä»€ä¹ˆæ—¶å€™æˆç«‹çš„ï¼Ÿ",
            "è°åˆ›ç«‹äº†è‹¹æœå…¬å¸ï¼Ÿ",
            "iPhoneä»€ä¹ˆæ—¶å€™å‘å¸ƒçš„ï¼Ÿ",
            "è‹¹æœå…¬å¸çš„æ€»éƒ¨åœ¨å“ªé‡Œï¼Ÿ",
            "iPadæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
            "å²è’‚å¤«Â·ä¹”å¸ƒæ–¯çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ",
            "App Storeæ˜¯ç”¨æ¥åšä»€ä¹ˆçš„ï¼Ÿ"
        ]

    async def run_comparison(self):
        """è¿è¡Œå¯¹æ¯”æ¼”ç¤º"""
        print("âš–ï¸  AGraph vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”æ¼”ç¤º")
        print("=" * 60)

        # 1. åˆå§‹åŒ–ä¸¤ç§æ–¹æ³•
        print("\nğŸ“‹ 1. åˆå§‹åŒ–ç³»ç»Ÿ...")
        await self.initialize_systems()

        # 2. æ•°æ®å‡†å¤‡å¯¹æ¯”
        print("\nğŸ“Š 2. æ•°æ®å¤„ç†å¯¹æ¯”...")
        self.compare_data_processing()

        # 3. æ£€ç´¢èƒ½åŠ›å¯¹æ¯”
        print("\nğŸ” 3. æ£€ç´¢èƒ½åŠ›å¯¹æ¯”...")
        await self.compare_search_capabilities()

        # 4. é—®ç­”æ•ˆæœå¯¹æ¯”
        print("\nğŸ’¬ 4. é—®ç­”æ•ˆæœå¯¹æ¯”...")
        await self.compare_qa_performance()

        # 5. æ€»ç»“å’Œå»ºè®®
        print("\nğŸ“ˆ 5. æ€»ç»“å’Œå»ºè®®...")
        self.show_summary()

        print("\nâœ… å¯¹æ¯”æ¼”ç¤ºå®Œæˆï¼")

    async def initialize_systems(self):
        """åˆå§‹åŒ–ä¸¤ç§ç³»ç»Ÿ"""
        # ä¼ ç»Ÿæœç´¢
        self.traditional_search = TraditionalSearch(self.sample_documents)
        print("âœ… ä¼ ç»Ÿæ–‡æœ¬æ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

        # AGraphç³»ç»Ÿ
        self.agraph = AGraph(
            collection_name="comparison_demo",
            vector_store_type="memory",
            use_openai_embeddings=False
        )

        await self.agraph.initialize()
        print("âœ… AGraphçŸ¥è¯†å›¾è°±ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

        # æ„å»ºçŸ¥è¯†å›¾è°±
        try:
            await self.build_knowledge_graph()
        except Exception as e:
            print(f"âš ï¸  çŸ¥è¯†å›¾è°±æ„å»ºé‡åˆ°é—®é¢˜: {e}")
            await self.create_fallback_kg_data()

    async def build_knowledge_graph(self):
        """æ„å»ºçŸ¥è¯†å›¾è°±"""
        print("ğŸ”¨ æ„å»ºçŸ¥è¯†å›¾è°±...")

        knowledge_graph = self.agraph.build_from_texts(
            texts=self.sample_documents,
            graph_name="è‹¹æœå…¬å¸çŸ¥è¯†å›¾è°±",
            save_to_vector_store=True
        )

        print(f"âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ - å®ä½“:{len(knowledge_graph.entities)}, å…³ç³»:{len(knowledge_graph.relations)}")

    async def create_fallback_kg_data(self):
        """åˆ›å»ºå¤‡ç”¨çŸ¥è¯†å›¾è°±æ•°æ®"""
        from agraph.base.entities import Entity
        from agraph.base.relations import Relation
        from agraph.base.text import TextChunk
        from agraph.base.types import EntityType, RelationType

        # åˆ›å»ºå®ä½“
        entities = [
            Entity(name="è‹¹æœå…¬å¸", entity_type=EntityType.ORGANIZATION, confidence=0.95),
            Entity(name="å²è’‚å¤«Â·ä¹”å¸ƒæ–¯", entity_type=EntityType.PERSON, confidence=0.95),
            Entity(name="iPhone", entity_type=EntityType.PRODUCT, confidence=0.90),
            Entity(name="iPad", entity_type=EntityType.PRODUCT, confidence=0.90),
            Entity(name="åº“æ¯”è’‚è¯º", entity_type=EntityType.LOCATION, confidence=0.85),
        ]

        # åˆ›å»ºå…³ç³»
        relations = [
            Relation(head_entity=entities[1], tail_entity=entities[0],
                    relation_type=RelationType.FOUNDED_BY, confidence=0.90),
            Relation(head_entity=entities[0], tail_entity=entities[2],
                    relation_type=RelationType.DEVELOPS, confidence=0.85),
            Relation(head_entity=entities[0], tail_entity=entities[4],
                    relation_type=RelationType.LOCATED_IN, confidence=0.80),
        ]

        # åˆ›å»ºæ–‡æœ¬å—
        text_chunks = [
            TextChunk(content=doc[:200] + "..." if len(doc) > 200 else doc,
                     title=f"æ–‡æ¡£{i+1}", source=f"doc_{i+1}",
                     start_index=0, end_index=min(200, len(doc)))
            for i, doc in enumerate(self.sample_documents[:5])
        ]

        # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        if self.agraph.vector_store:
            await self.agraph.vector_store.batch_add_entities(entities)
            await self.agraph.vector_store.batch_add_relations(relations)
            await self.agraph.vector_store.batch_add_text_chunks(text_chunks)

        print("âœ… å¤‡ç”¨çŸ¥è¯†å›¾è°±æ•°æ®åˆ›å»ºå®Œæˆ")

    def compare_data_processing(self):
        """å¯¹æ¯”æ•°æ®å¤„ç†æ–¹å¼"""
        print("å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„æ•°æ®å¤„ç†ç‰¹ç‚¹:\n")

        print("ğŸ“ ä¼ ç»Ÿæ–‡æœ¬æ£€ç´¢:")
        print("   - æ•°æ®ç»“æ„: æ‰å¹³æ–‡æœ¬åˆ—è¡¨")
        print("   - å¤„ç†æ–¹å¼: ç®€å•åˆ†è¯å’Œé¢„å¤„ç†")
        print("   - å­˜å‚¨å½¢å¼: åŸå§‹æ–‡æœ¬")
        print("   - è¯­ä¹‰ç†è§£: åŸºäºå…³é”®è¯åŒ¹é…ï¼Œæ— è¯­ä¹‰ç†è§£")

        print("\nğŸ§  AGraphçŸ¥è¯†å›¾è°±:")
        print("   - æ•°æ®ç»“æ„: å®ä½“-å…³ç³»å›¾ç»“æ„")
        print("   - å¤„ç†æ–¹å¼: å®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–ã€èšç±»åˆ†æ")
        print("   - å­˜å‚¨å½¢å¼: ç»“æ„åŒ–çŸ¥è¯† + å‘é‡åµŒå…¥")
        print("   - è¯­ä¹‰ç†è§£: æ·±åº¦è¯­ä¹‰ç†è§£å’Œæ¨ç†èƒ½åŠ›")

        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   - æ–‡æ¡£æ•°é‡: {len(self.sample_documents)}")
        print(f"   - æ€»å­—ç¬¦æ•°: {sum(len(doc) for doc in self.sample_documents)}")

    async def compare_search_capabilities(self):
        """å¯¹æ¯”æ£€ç´¢èƒ½åŠ›"""
        print("å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„æ£€ç´¢èƒ½åŠ›:\n")

        search_queries = ["åˆ›å§‹äºº", "æ™ºèƒ½æ‰‹æœº", "æ€»éƒ¨ä½ç½®"]

        for query in search_queries:
            print(f"ğŸ” æœç´¢æŸ¥è¯¢: '{query}'")

            # ä¼ ç»Ÿæœç´¢ç»“æœ
            print("ğŸ“ ä¼ ç»Ÿæ–¹æ³•ç»“æœ:")
            traditional_results = self.traditional_search.search(query, top_k=2)
            for i, (doc, score) in enumerate(traditional_results):
                preview = doc[:60] + "..." if len(doc) > 60 else doc
                print(f"   {i+1}. [{score:.3f}] {preview}")

            # AGraphæœç´¢ç»“æœ
            print("ğŸ§  AGraphæ–¹æ³•ç»“æœ:")
            try:
                # æœç´¢å®ä½“
                entity_results = await self.agraph.search_entities(query, top_k=2)
                if entity_results:
                    print("   å®ä½“:")
                    for entity, score in entity_results:
                        print(f"      - {entity.name} ({entity.entity_type}) [{score:.3f}]")

                # æœç´¢æ–‡æœ¬
                text_results = await self.agraph.search_text_chunks(query, top_k=2)
                if text_results:
                    print("   æ–‡æ¡£:")
                    for chunk, score in text_results:
                        preview = chunk.content[:60] + "..." if len(chunk.content) > 60 else chunk.content
                        print(f"      - [{score:.3f}] {preview}")

            except Exception as e:
                print(f"   æœç´¢å¤±è´¥: {e}")

            print()

    async def compare_qa_performance(self):
        """å¯¹æ¯”é—®ç­”æ€§èƒ½"""
        print("å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„é—®ç­”æ•ˆæœ:\n")

        traditional_correct = 0
        agraph_correct = 0

        for i, question in enumerate(self.test_questions):
            print(f"â“ é—®é¢˜ {i+1}: {question}")

            # ä¼ ç»Ÿæ–¹æ³•å›ç­”
            traditional_answer = self.traditional_search.answer_question(question)
            print(f"ğŸ“ ä¼ ç»Ÿæ–¹æ³•: {traditional_answer}")

            # AGraphæ–¹æ³•å›ç­”
            try:
                response = await self.agraph.chat(
                    question=question,
                    entity_top_k=3,
                    text_chunk_top_k=2,
                    response_type="ç®€æ´å›ç­”"
                )
                agraph_answer = response['answer']
                print(f"ğŸ§  AGraphæ–¹æ³•: {agraph_answer}")

                # æ˜¾ç¤ºAGraphçš„é¢å¤–ä¿¡æ¯
                context = response['context']
                entity_count = len(context.get('entities', []))
                if entity_count > 0:
                    print(f"   ğŸ’¡ æ£€ç´¢äº†{entity_count}ä¸ªç›¸å…³å®ä½“")

            except Exception as e:
                print(f"ğŸ§  AGraphæ–¹æ³•: å›ç­”å¤±è´¥ - {e}")

            print()

    def show_summary(self):
        """æ˜¾ç¤ºå¯¹æ¯”æ€»ç»“"""
        print("ğŸ“‹ å¯¹æ¯”æ€»ç»“:")
        print("\nä¼ ç»Ÿæ–‡æœ¬æ£€ç´¢çš„ç‰¹ç‚¹:")
        print("âœ… ä¼˜åŠ¿:")
        print("   - å®ç°ç®€å•ï¼Œèµ„æºæ¶ˆè€—ä½")
        print("   - é€‚åˆç®€å•å…³é”®è¯åŒ¹é…")
        print("   - æ— éœ€å¤æ‚çš„é¢„å¤„ç†")

        print("âŒ å±€é™:")
        print("   - ç¼ºä¹è¯­ä¹‰ç†è§£èƒ½åŠ›")
        print("   - æ— æ³•å¤„ç†å¤æ‚æ¨ç†")
        print("   - æ£€ç´¢ç²¾åº¦æœ‰é™")
        print("   - éš¾ä»¥å‘ç°éšå«å…³ç³»")

        print("\nAGraphçŸ¥è¯†å›¾è°±çš„ç‰¹ç‚¹:")
        print("âœ… ä¼˜åŠ¿:")
        print("   - å¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›")
        print("   - æ”¯æŒå¤æ‚æ¨ç†å’Œå…³è”æŸ¥è¯¢")
        print("   - ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤º")
        print("   - å¯æ‰©å±•çš„å®ä½“å’Œå…³ç³»æ¨¡å‹")
        print("   - æ”¯æŒå¤šè½®å¯¹è¯å’Œä¸Šä¸‹æ–‡ç†è§£")

        print("âŒ å±€é™:")
        print("   - æ„å»ºæˆæœ¬ç›¸å¯¹è¾ƒé«˜")
        print("   - éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æº")
        print("   - å¯¹æ•°æ®è´¨é‡è¦æ±‚æ›´é«˜")

        print("\nğŸ¯ åº”ç”¨å»ºè®®:")
        print("ğŸ“ ä¼ ç»Ÿæ–¹æ³•é€‚åˆ:")
        print("   - ç®€å•çš„å…³é”®è¯æœç´¢")
        print("   - èµ„æºå—é™çš„ç¯å¢ƒ")
        print("   - å¿«é€ŸåŸå‹å¼€å‘")

        print("ğŸ§  AGraphé€‚åˆ:")
        print("   - ä¼ä¸šçŸ¥è¯†ç®¡ç†")
        print("   - æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
        print("   - å¤æ‚ä¿¡æ¯æ£€ç´¢")
        print("   - éœ€è¦è¯­ä¹‰ç†è§£çš„åº”ç”¨")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.agraph:
            await self.agraph.close()


async def main():
    """ä¸»å‡½æ•°"""
    demo = ComparisonDemo()

    try:
        await demo.run_comparison()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await demo.cleanup()


if __name__ == "__main__":
    print("âš–ï¸  å¯åŠ¨AGraph vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”æ¼”ç¤º...")
    print("ğŸ“Œ æ­¤æ¼”ç¤ºå°†å¯¹æ¯”ä¼ ç»Ÿæ–‡æœ¬æ£€ç´¢ä¸AGraphçŸ¥è¯†å›¾è°±æ–¹æ³•çš„å·®å¼‚")
    print("â±ï¸  æ¼”ç¤ºå¤§çº¦éœ€è¦3-5åˆ†é’Ÿ\n")

    if sys.version_info < (3, 7):
        print("âŒ éœ€è¦Python 3.7+ç‰ˆæœ¬")
        sys.exit(1)

    asyncio.run(main())
