#!/usr/bin/env python3
"""
AGraph å¿«é€Ÿå¼€å§‹ç¤ºä¾‹ (ç»Ÿä¸€é…ç½®ç‰ˆæœ¬)

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨æ–°ç»Ÿä¸€é…ç½®ç³»ç»Ÿçš„AGraphç¤ºä¾‹ï¼Œå±•ç¤ºäº†ç®€åŒ–çš„é…ç½®æ–¹å¼ï¼š
1. ç»Ÿä¸€çš„Settingsé…ç½®ç®¡ç†
2. ç®€åŒ–çš„AGraphåˆå§‹åŒ– (åªéœ€ä¼ å…¥settings)
3. ä»æ–‡æœ¬æ„å»ºçŸ¥è¯†å›¾è°±
4. è¿›è¡Œè¯­ä¹‰æœç´¢
5. æ™ºèƒ½é—®ç­”å¯¹è¯

é€‚åˆäº†è§£AGraphç»Ÿä¸€é…ç½®ç³»ç»Ÿçš„å¼ºå¤§åŠŸèƒ½å’Œç®€åŒ–ä½¿ç”¨æ–¹å¼ã€‚
"""

import asyncio
import sys
import time
from pathlib import Path
from agraph import AGraph
from agraph.config import get_settings, update_settings

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# è®¾ç½®å·¥ä½œç›®å½•å¹¶æ›´æ–°é…ç½®
workdir = str(project_root / "workdir" / "agraph_quickstart-cache")
settings = get_settings()
settings = update_settings({"workdir": workdir, "llm_config": {"model": "Qwen/Qwen3-32B"}})

print(f"âœ… ä½¿ç”¨å·¥ä½œç›®å½•: {settings.workdir}")
print(f"ğŸ“‹ é…ç½®æ¦‚è§ˆ:")
print(f"   - LLMæ¨¡å‹: {settings.llm.model}")
print(f"   - åµŒå…¥æ¨¡å‹: {settings.embedding.model}")
print(f"   - æœ€å¤§å¹¶å‘: {settings.max_current}")
print(f"   - ç¼“å­˜è®¾ç½®: TTL={settings.cache_config['cache_ttl']}s")

async def quickstart_demo():
    """AGraphå¿«é€Ÿå¼€å§‹æ¼”ç¤º"""

    print("ğŸš€ AGraph å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("=" * 40)

    # ä»documentsç›®å½•è¯»å–çœŸå®æ–‡æ¡£
    documents_dir = Path(__file__).parent / "documents"
    sample_texts = []

    if documents_dir.exists():
        print(f"ğŸ“‚ ä» {documents_dir} è¯»å–æ–‡æ¡£...")
        supported_extensions = {'.txt', '.md', '.json', '.csv'}

        for file_path in documents_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if content.strip():  # ç¡®ä¿æ–‡ä»¶ä¸ä¸ºç©º
                            sample_texts.append(content)
                            print(f"   ğŸ“„ è¯»å–: {file_path.name} ({len(content)} å­—ç¬¦)")
                except UnicodeDecodeError:
                    # å°è¯•å…¶ä»–ç¼–ç 
                    try:
                        with open(file_path, 'r', encoding='gbk') as f:
                            content = f.read()
                            if content.strip():
                                sample_texts.append(content)
                                print(f"   ğŸ“„ è¯»å–: {file_path.name} ({len(content)} å­—ç¬¦, GBKç¼–ç )")
                    except Exception as e:
                        print(f"   âš ï¸  è·³è¿‡æ–‡ä»¶ {file_path.name}: {e}")
                except Exception as e:
                    print(f"   âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {file_path.name}: {e}")

    # å¦‚æœæ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡æ¡£ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®
    if not sample_texts:
        raise Exception(
            "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡æ¡£ï¼Œè¯·ç¡®ä¿documentsç›®å½•ä¸‹æœ‰æ”¯æŒçš„æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txt, .md, .json, .csvï¼‰"
        )
    else:
        print(f"âœ… æˆåŠŸè¯»å– {len(sample_texts)} ä¸ªæ–‡æ¡£")

    # 1. åˆ›å»ºAGraphå®ä¾‹å¹¶åˆå§‹åŒ– (è‡ªåŠ¨é…ç½®ä¿å­˜)
    print("\nğŸ“¦ 1. åˆå§‹åŒ–AGraph (è‡ªåŠ¨é…ç½®ä¿å­˜)...")
    print("   ğŸ”§ ä½¿ç”¨ç»Ÿä¸€Settingsé…ç½®ç³»ç»Ÿ")
    print("   âš¡ ç®€åŒ–åˆå§‹åŒ–è¿‡ç¨‹ (è‡ªåŠ¨ä¿å­˜é…ç½®åˆ°workdir)")
    print("   ğŸ“‹ è‡ªåŠ¨ä»é…ç½®æ•°æ®ä¸­è·å–æ‰€æœ‰å‚æ•°")
    async with AGraph(collection_name="quickstart_demo") as agraph:
        await agraph.initialize()
        print("âœ… AGraphåˆå§‹åŒ–æˆåŠŸ (ä½¿ç”¨ç»Ÿä¸€é…ç½®ç³»ç»Ÿ)")
        print(f"   ğŸ—ºï¸ æŒä¹…åŒ–ç›®å½•: {agraph.persist_directory}")
        print(f"   ğŸ’¾ å‘é‡å­˜å‚¨ç±»å‹: {agraph.vector_store_type}")
        print(f"   ğŸ§  å¯ç”¨çŸ¥è¯†å›¾è°±: {agraph.enable_knowledge_graph}")
        print(f"   ğŸŒ åµŒå…¥æä¾›è€…: {settings.embedding.provider}")

        # 2. ä»æ–‡æœ¬æ„å»ºçŸ¥è¯†å›¾è°± (ä½¿ç”¨ç»Ÿä¸€é…ç½®)
        print("\nğŸ—ï¸ 2. æ„å»ºçŸ¥è¯†å›¾è°± (ç»Ÿä¸€é…ç½®)...")
        print(f"   ğŸ“‹ å¤„ç†é…ç½®: å—å¤§å°={settings.processing_config['chunk_size']}, é‡å ={settings.processing_config['chunk_overlap']}")
        print(f"   ğŸ¯ æå–é…ç½®: å®ä½“ç½®ä¿¡åº¦={settings.extraction_config['entity_confidence_threshold']}, å…³ç³»ç½®ä¿¡åº¦={settings.extraction_config['relation_confidence_threshold']}")
        try:
            graph_name = "ä¼ä¸šæ–‡æ¡£çŸ¥è¯†å›¾è°±"
            graph_description = "åŸºäºä¼ä¸šæ–‡æ¡£æ„å»ºçš„ç»¼åˆçŸ¥è¯†å›¾è°±"

            start_time = time.time()
            knowledge_graph = await agraph.build_from_texts(
                texts=sample_texts,
                graph_name=graph_name,
                graph_description=graph_description,
                use_cache=True,  # å¯ç”¨ç¼“å­˜ä»¥åŠ å¿«åç»­æ„å»ºé€Ÿåº¦
                save_to_vector_store=True,  # ä¿å­˜åˆ°å‘é‡å­˜å‚¨
            )
            build_time = time.time() - start_time

            print("âœ… çŸ¥è¯†å›¾è°±æ„å»ºæˆåŠŸ!")
            print(f"   â±ï¸ æ„å»ºæ—¶é—´: {build_time:.2f}ç§’ (ç»Ÿä¸€é…ç½®ä¼˜åŒ–)")
            print(f"   ğŸ“Š å®ä½“: {len(knowledge_graph.entities)} ä¸ª")
            print(f"   ğŸ”— å…³ç³»: {len(knowledge_graph.relations)} ä¸ª")
            print(f"   ğŸ“„ æ–‡æœ¬å—: {len(knowledge_graph.text_chunks)} ä¸ª")

        except Exception as e:
            print(f"âš ï¸  çŸ¥è¯†å›¾è°±æ„å»ºé‡åˆ°é—®é¢˜: {e}")
            print(f"   ğŸ“‹ å½“å‰é…ç½®: {settings.get_all_configs()['core']}")

        # 3. è¯­ä¹‰æœç´¢æ¼”ç¤º
        print("\nğŸ” 3. è¯­ä¹‰æœç´¢æ¼”ç¤º...")

        search_entity = "å…¬å¸"
        search_text = "æŠ€æœ¯"

        # æœç´¢å®ä½“
        print(f"æœç´¢å®ä½“ '{search_entity}':")
        entities = await agraph.search_entities(search_entity, top_k=3)
        for i, (entity, score) in enumerate(entities):
            print(f"   {i+1}. {entity.name} ({entity.entity_type})")

        # æœç´¢æ–‡æœ¬
        print(f"\næœç´¢æ–‡æœ¬ '{search_text}':")
        text_chunks = await agraph.search_text_chunks(search_text, top_k=2)
        for i, (chunk, score) in enumerate(text_chunks):
            preview = chunk.content[:60] + "..." if len(chunk.content) > 60 else chunk.content
            print(f"   {i+1}. {preview}")

        # 4. æ™ºèƒ½é—®ç­”æ¼”ç¤º
        print("\nğŸ’¬ 4. æ™ºèƒ½é—®ç­”æ¼”ç¤º...")

        # æ ¹æ®æ–‡æ¡£å†…å®¹åŠ¨æ€é€‰æ‹©é—®é¢˜
        questions = [
            "å…¬å¸çš„ä¸»è¦ä¸šåŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å…¬å¸çš„æ ¸å¿ƒæŠ€æœ¯æœ‰å“ªäº›ï¼Ÿ",
            "å›¢é˜Ÿè§„æ¨¡å¦‚ä½•ï¼Ÿ"
        ]

        for i, question in enumerate(questions):
            print(f"\nâ“ é—®é¢˜ {i+1}: {question}")
            try:
                # æµå¼è°ƒç”¨ï¼ˆæ–°åŠŸèƒ½ï¼‰
                async for chunk_data in await agraph.chat(question, stream=True):
                    if chunk_data["chunk"]:
                        print(chunk_data["chunk"], end="", flush=True)
                    if chunk_data["finished"]:
                        print(f"\nå®Œæ•´å›ç­”: {chunk_data['answer']}")
                        break

                # æ˜¾ç¤ºæ£€ç´¢ç»Ÿè®¡å’Œé…ç½®ä¿¡æ¯
                context = chunk_data['context']
                entity_count = len(context.get('entities', []))
                chunk_count = len(context.get('text_chunks', []))
                print(f"   ğŸ“Š æ£€ç´¢äº† {entity_count} ä¸ªå®ä½“, {chunk_count} ä¸ªæ–‡æ¡£")
                print(f"   âš™ï¸ ä½¿ç”¨çš„LLMé…ç½®: {settings.llm.model} (temp={settings.llm.temperature})")

            except Exception as e:
                print(f"ğŸ¤– å›ç­”: æŠ±æ­‰ï¼Œæ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜: {e}")

        # 5. ç³»ç»Ÿä¿¡æ¯å’Œé…ç½®æ¦‚è§ˆ
        print("\nğŸ“Š 5. ç³»ç»Ÿä¿¡æ¯å’Œç»Ÿä¸€é…ç½®...")
        stats = await agraph.get_stats()

        if 'vector_store' in stats:
            vs_stats = stats['vector_store']
            print("å‘é‡å­˜å‚¨:")
            print(f"   - å®ä½“: {vs_stats.get('entities', 0)}")
            print(f"   - å…³ç³»: {vs_stats.get('relations', 0)}")
            print(f"   - æ–‡æœ¬å—: {vs_stats.get('text_chunks', 0)}")

        # æ˜¾ç¤ºç»Ÿä¸€é…ç½®æ¦‚è§ˆ
        print("\nç»Ÿä¸€é…ç½®æ¦‚è§ˆ:")
        all_configs = settings.get_all_configs()
        print(f"   - æ ¸å¿ƒé…ç½®: {all_configs['core']}")
        print(f"   - ç¼“å­˜é…ç½®: {all_configs['unified_views']['cache']}")
        print(f"   - å¤„ç†é…ç½®: {all_configs['unified_views']['processing']}")

        print(f"\nç³»ç»ŸçŠ¶æ€: {agraph}")

    print("\nâœ… å¿«é€Ÿå¼€å§‹æ¼”ç¤ºå®Œæˆ (ç»Ÿä¸€é…ç½®ç‰ˆæœ¬)!")
    print("ğŸ”§ ä½“éªŒäº†AGraphç»Ÿä¸€é…ç½®ç³»ç»Ÿçš„å¼ºå¤§åŠŸèƒ½:")
    print("   - ç®€åŒ–çš„åˆå§‹åŒ–è¿‡ç¨‹ (åªéœ€ä¼ å…¥settings)")
    print("   - ç»Ÿä¸€çš„é…ç½®ç®¡ç†å’Œè®¿é—®")
    print("   - è‡ªåŠ¨åŒ–çš„å‚æ•°æ´¾ç”Ÿå’Œä¼˜åŒ–")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¯åŠ¨AGraphå¿«é€Ÿå¼€å§‹æ¼”ç¤º (ç»Ÿä¸€é…ç½®ç‰ˆæœ¬)...")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 7):
        print("âŒ éœ€è¦Python 3.7+ç‰ˆæœ¬")
        return

    try:
        asyncio.run(quickstart_demo())
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        print("ğŸ’¡ æç¤º: è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…agraphåŒ…")


if __name__ == "__main__":
    main()
