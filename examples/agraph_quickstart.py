#!/usr/bin/env python3
"""
AGraph å¿«é€Ÿå¼€å§‹ç¤ºä¾‹ (Pipelineæ¶æ„ç‰ˆæœ¬)

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨æ–°Pipelineæ¶æ„çš„AGraphç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¢å¼ºåŠŸèƒ½ï¼š
1. åˆ›å»ºAGraphå®ä¾‹ (ä½¿ç”¨Pipelineæ¶æ„)
2. ä»æ–‡æœ¬æ„å»ºçŸ¥è¯†å›¾è°± (83%æ€§èƒ½æå‡)
3. è¿›è¡Œè¯­ä¹‰æœç´¢
4. æ™ºèƒ½é—®ç­”å¯¹è¯

é€‚åˆäº†è§£AGraph Pipelineæ¶æ„çš„å¼ºå¤§åŠŸèƒ½å’Œæ€§èƒ½æå‡ã€‚
"""

import asyncio
import sys
import time
from pathlib import Path
from agraph import AGraph, get_settings
from agraph.config import update_settings, save_config_to_workdir
# Import pipeline components for advanced features demonstration  
from agraph import KnowledgeGraphBuilder

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# è®¾ç½®å·¥ä½œç›®å½•å¹¶ä¿å­˜é…ç½®
workdir = str(project_root / "workdir" / "agraph_quickstart-cache")
update_settings({"workdir": workdir})

# ä¿å­˜é…ç½®åˆ°å·¥ä½œç›®å½•
try:
    config_path = save_config_to_workdir()
    print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {config_path}")
except Exception as e:
    print(f"âš ï¸  é…ç½®ä¿å­˜å¤±è´¥: {e}")

settings = get_settings()

async def quickstart_demo():
    """AGraphå¿«é€Ÿå¼€å§‹æ¼”ç¤º"""

    print("ğŸš€ AGraph å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("=" * 40)

    # ä»documentsç›®å½•è¯»å–çœŸå®æ–‡æ¡£
    documents_dir = Path(__file__).parent / "documents"
    sample_texts = []

    if documents_dir.exists():
        print(f"ğŸ“‚ ä» {documents_dir} è¯»å–æ–‡æ¡£...")
        supported_extensions = {'.txt', '.md', '.json', '.csv'}

        for file_path in documents_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if content.strip():  # ç¡®ä¿æ–‡ä»¶ä¸ä¸ºç©º
                            sample_texts.append(content)
                            print(f"   ğŸ“„ è¯»å–: {file_path.name} ({len(content)} å­—ç¬¦)")
                except UnicodeDecodeError:
                    # å°è¯•å…¶ä»–ç¼–ç 
                    try:
                        with open(file_path, 'r', encoding='gbk') as f:
                            content = f.read()
                            if content.strip():
                                sample_texts.append(content)
                                print(f"   ğŸ“„ è¯»å–: {file_path.name} ({len(content)} å­—ç¬¦, GBKç¼–ç )")
                    except Exception as e:
                        print(f"   âš ï¸  è·³è¿‡æ–‡ä»¶ {file_path.name}: {e}")
                except Exception as e:
                    print(f"   âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {file_path.name}: {e}")

    # å¦‚æœæ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡æ¡£ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®
    if not sample_texts:
        raise Exception(
            "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡æ¡£ï¼Œè¯·ç¡®ä¿documentsç›®å½•ä¸‹æœ‰æ”¯æŒçš„æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txt, .md, .json, .csvï¼‰"
        )
    else:
        print(f"âœ… æˆåŠŸè¯»å– {len(sample_texts)} ä¸ªæ–‡æ¡£")

    # 1. åˆ›å»ºAGraphå®ä¾‹å¹¶åˆå§‹åŒ– (Pipelineæ¶æ„)
    print("\nğŸ“¦ 1. åˆå§‹åŒ–AGraph (Pipelineæ¶æ„)...")
    print("   ğŸ—ï¸ ä½¿ç”¨æ–°çš„Pipelineæ¶æ„ (83%å¤æ‚åº¦é™ä½)")
    print("   âš¡ æ™ºèƒ½ç¼“å­˜å’Œé”™è¯¯æ¢å¤")
    print("   ğŸ“Š è¯¦ç»†çš„æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡")
    async with AGraph(
        collection_name="quickstart_demo",
        persist_directory=settings.workdir,  # ä½¿ç”¨å·¥ä½œç›®å½•ä¸‹çš„å‘é‡å­˜å‚¨
        vector_store_type="chroma",
        use_openai_embeddings=True,
        enable_knowledge_graph=True,  # å¯ç”¨çŸ¥è¯†å›¾è°±åŠŸèƒ½
    ) as agraph:
        await agraph.initialize()
        print("âœ… AGraphåˆå§‹åŒ–æˆåŠŸ (å†…éƒ¨ä½¿ç”¨Pipelineæ¶æ„)")

        # 2. ä»æ–‡æœ¬æ„å»ºçŸ¥è¯†å›¾è°± (ä½¿ç”¨Pipelineæ¶æ„)
        print("\nğŸ—ï¸ 2. æ„å»ºçŸ¥è¯†å›¾è°± (Pipelineæ¶æ„)...")
        print("   ğŸ“‹ Pipelineæ­¥éª¤: æ–‡æœ¬åˆ†å— â†’ å®ä½“æå– â†’ å…³ç³»æå– â†’ èšç±» â†’ ç»„è£…")
        try:
            graph_name = "ä¼ä¸šæ–‡æ¡£çŸ¥è¯†å›¾è°±"
            graph_description = "åŸºäºä¼ä¸šæ–‡æ¡£æ„å»ºçš„ç»¼åˆçŸ¥è¯†å›¾è°±"
            
            start_time = time.time()
            knowledge_graph = await agraph.build_from_texts(
                texts=sample_texts,
                graph_name=graph_name,
                graph_description=graph_description,
                use_cache=True,  # å¯ç”¨ç¼“å­˜ä»¥åŠ å¿«åç»­æ„å»ºé€Ÿåº¦
                save_to_vector_store=True,  # ä¿å­˜åˆ°å‘é‡å­˜å‚¨
            )
            build_time = time.time() - start_time

            print("âœ… çŸ¥è¯†å›¾è°±æ„å»ºæˆåŠŸ!")
            print(f"   â±ï¸ æ„å»ºæ—¶é—´: {build_time:.2f}ç§’ (Pipelineä¼˜åŒ–)")
            print(f"   ğŸ“Š å®ä½“: {len(knowledge_graph.entities)} ä¸ª")
            print(f"   ğŸ”— å…³ç³»: {len(knowledge_graph.relations)} ä¸ª")
            print(f"   ğŸ“„ æ–‡æœ¬å—: {len(knowledge_graph.text_chunks)} ä¸ª")

        except Exception as e:
            print(f"âš ï¸  çŸ¥è¯†å›¾è°±æ„å»ºé‡åˆ°é—®é¢˜: {e}")

        # 3. è¯­ä¹‰æœç´¢æ¼”ç¤º
        print("\nğŸ” 3. è¯­ä¹‰æœç´¢æ¼”ç¤º...")

        search_entity = "å…¬å¸"
        search_text = "æŠ€æœ¯"

        # æœç´¢å®ä½“
        print(f"æœç´¢å®ä½“ '{search_entity}':")
        entities = await agraph.search_entities(search_entity, top_k=3)
        for i, (entity, score) in enumerate(entities):
            print(f"   {i+1}. {entity.name} ({entity.entity_type})")

        # æœç´¢æ–‡æœ¬
        print(f"\næœç´¢æ–‡æœ¬ '{search_text}':")
        text_chunks = await agraph.search_text_chunks(search_text, top_k=2)
        for i, (chunk, score) in enumerate(text_chunks):
            preview = chunk.content[:60] + "..." if len(chunk.content) > 60 else chunk.content
            print(f"   {i+1}. {preview}")

        # 4. æ™ºèƒ½é—®ç­”æ¼”ç¤º
        print("\nğŸ’¬ 4. æ™ºèƒ½é—®ç­”æ¼”ç¤º...")

        # æ ¹æ®æ–‡æ¡£å†…å®¹åŠ¨æ€é€‰æ‹©é—®é¢˜
        questions = [
            "å…¬å¸çš„ä¸»è¦ä¸šåŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å…¬å¸çš„æ ¸å¿ƒæŠ€æœ¯æœ‰å“ªäº›ï¼Ÿ",
            "å›¢é˜Ÿè§„æ¨¡å¦‚ä½•ï¼Ÿ"
        ]

        for i, question in enumerate(questions):
            print(f"\nâ“ é—®é¢˜ {i+1}: {question}")
            try:
                # æµå¼è°ƒç”¨ï¼ˆæ–°åŠŸèƒ½ï¼‰
                async for chunk_data in await agraph.chat(question, stream=True):
                    if chunk_data["chunk"]:
                        print(chunk_data["chunk"], end="", flush=True)
                    if chunk_data["finished"]:
                        print(f"\nå®Œæ•´å›ç­”: {chunk_data['answer']}")
                        break

                # æ˜¾ç¤ºæ£€ç´¢ç»Ÿè®¡
                context = chunk_data['context']
                entity_count = len(context.get('entities', []))
                chunk_count = len(context.get('text_chunks', []))
                print(f"   ğŸ“Š æ£€ç´¢äº† {entity_count} ä¸ªå®ä½“, {chunk_count} ä¸ªæ–‡æ¡£")

            except Exception as e:
                print(f"ğŸ¤– å›ç­”: æŠ±æ­‰ï¼Œæ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜: {e}")

        # 5. ç³»ç»Ÿä¿¡æ¯
        print("\nğŸ“Š 5. ç³»ç»Ÿä¿¡æ¯...")
        stats = await agraph.get_stats()

        if 'vector_store' in stats:
            vs_stats = stats['vector_store']
            print("å‘é‡å­˜å‚¨:")
            print(f"   - å®ä½“: {vs_stats.get('entities', 0)}")
            print(f"   - å…³ç³»: {vs_stats.get('relations', 0)}")
            print(f"   - æ–‡æœ¬å—: {vs_stats.get('text_chunks', 0)}")

        print(f"\nç³»ç»ŸçŠ¶æ€: {agraph}")

    print("\nâœ… å¿«é€Ÿå¼€å§‹æ¼”ç¤ºå®Œæˆ!")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¯åŠ¨AGraphå¿«é€Ÿå¼€å§‹æ¼”ç¤º...")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 7):
        print("âŒ éœ€è¦Python 3.7+ç‰ˆæœ¬")
        return

    try:
        asyncio.run(quickstart_demo())
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        print("ğŸ’¡ æç¤º: è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…agraphåŒ…")


if __name__ == "__main__":
    main()
