"""
LLM ISPæ„å»ºå™¨ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•æ ¹æ®ä¸åŒéœ€æ±‚é€‰æ‹©åˆé€‚çš„LLMå›¾æ„å»ºå™¨ï¼Œ
ä½“ç°Interface Segregation Principleçš„ä¼˜åŠ¿
"""

import asyncio
import logging

from agraph.builders import (
    BatchLLMGraphBuilder,
    FlexibleLLMGraphBuilder,
    LLMGraphBuilder,
    LLMSearchBuilder,
    MinimalLLMGraphBuilder,
    StreamingLLMGraphBuilder,
)
from agraph.config import settings
from agraph.embeddings import JsonVectorStorage
from agraph.entities import Entity
from agraph.types import EntityType

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def example_basic_builder():
    """
    ç¤ºä¾‹1: åŸºç¡€æ„å»ºå™¨

    é€‚ç”¨åœºæ™¯ï¼š
    - åªéœ€è¦ç®€å•çš„æ–‡æœ¬åˆ°å›¾è°±è½¬æ¢
    - ä¸éœ€è¦æ›´æ–°ã€åˆå¹¶ã€éªŒè¯ç­‰åŠŸèƒ½
    - è¿½æ±‚æœ€å°ä¾èµ–å’Œç®€å•æ€§
    """
    print("\n" + "=" * 50)
    print("ğŸ“ ç¤ºä¾‹1: LLMåŸºç¡€æ„å»ºå™¨")
    print("=" * 50)

    # åˆ›å»ºåŸºç¡€æ„å»ºå™¨
    builder = MinimalLLMGraphBuilder(
        openai_api_key=settings.OPENAI_API_KEY,
        openai_api_base=settings.OPENAI_API_BASE,
        llm_model=settings.LLM_MODEL,
        temperature=0.1,
    )

    # ç¤ºä¾‹æ–‡æœ¬
    texts = [
        "è‹¹æœå…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½æŠ€æœ¯å…¬å¸ï¼Œæ€»éƒ¨ä½äºåŠ åˆ©ç¦å°¼äºšå·åº“æ¯”è’‚è¯ºã€‚",
        "å²è’‚å¤«Â·ä¹”å¸ƒæ–¯æ˜¯è‹¹æœå…¬å¸çš„è”åˆåˆ›å§‹äººï¼Œä»–åœ¨2011å¹´å»ä¸–ã€‚",
        "iPhoneæ˜¯è‹¹æœå…¬å¸å¼€å‘çš„æ™ºèƒ½æ‰‹æœºäº§å“çº¿ã€‚",
    ]

    try:
        # æ„å»ºå›¾è°± - ç°åœ¨æ˜¯å¼‚æ­¥çš„
        graph = await builder.build_graph(texts=texts, graph_name="basic_example_graph")

        print("âœ… æˆåŠŸæ„å»ºåŸºç¡€å›¾è°±:")
        print(f"   - å®ä½“æ•°é‡: {len(graph.entities)}")
        print(f"   - å…³ç³»æ•°é‡: {len(graph.relations)}")
        print(f"   - å›¾è°±åç§°: {graph.name}")

        # æ˜¾ç¤ºä¸€äº›å®ä½“
        print("\nğŸ“‹ å®ä½“ç¤ºä¾‹:")
        for i, (entity_id, entity) in enumerate(list(graph.entities.items())[:3]):
            print(f"   {i+1}. {entity.name} ({entity.entity_type.value})")

    except Exception as e:
        print(f"âŒ åŸºç¡€æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")


async def example_updatable_builder():
    """
    ç¤ºä¾‹2: å¯æ›´æ–°æ„å»ºå™¨

    é€‚ç”¨åœºæ™¯ï¼š
    - éœ€è¦æ„å»ºå›¾è°±åè¿›è¡Œå¢é‡æ›´æ–°
    - ä¸éœ€è¦åˆå¹¶ã€éªŒè¯ç­‰é«˜çº§åŠŸèƒ½
    - è¿½æ±‚æ„å»º+æ›´æ–°çš„ç»„åˆåŠŸèƒ½
    """
    print("\n" + "=" * 50)
    print("ğŸ”„ ç¤ºä¾‹2: LLMå¯æ›´æ–°æ„å»ºå™¨")
    print("=" * 50)

    # åˆ›å»ºå¯æ›´æ–°æ„å»ºå™¨
    builder = FlexibleLLMGraphBuilder(
        openai_api_key=settings.OPENAI_API_KEY,
        openai_api_base=settings.OPENAI_API_BASE,
        llm_model=settings.LLM_MODEL,
        embedding_model=settings.EMBEDDING_MODEL,
        vector_storage=JsonVectorStorage(file_path="workdir/isp_vector_store.json"),  # å‡è®¾ä½¿ç”¨JSONå­˜å‚¨ä½œä¸ºå‘é‡å­˜å‚¨
    )

    # åˆå§‹æ–‡æœ¬
    initial_texts = ["å¾®è½¯å…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½æŠ€æœ¯å…¬å¸ã€‚", "æ¯”å°”Â·ç›–èŒ¨æ˜¯å¾®è½¯å…¬å¸çš„è”åˆåˆ›å§‹äººã€‚"]

    try:
        # æ„å»ºåˆå§‹å›¾è°±
        graph = await builder.build_graph(texts=initial_texts, graph_name="updatable_example_graph")

        print("âœ… åˆå§‹å›¾è°±æ„å»ºå®Œæˆ:")
        print(f"   - åˆå§‹å®ä½“æ•°: {len(graph.entities)}")
        print(f"   - åˆå§‹å…³ç³»æ•°: {len(graph.relations)}")

        # å‡†å¤‡æ–°å®ä½“è¿›è¡Œæ›´æ–°
        new_entity = Entity(
            id="entity_new_001",
            name="Windowsæ“ä½œç³»ç»Ÿ",
            entity_type=EntityType.PRODUCT,
            description="å¾®è½¯å…¬å¸å¼€å‘çš„æ“ä½œç³»ç»Ÿ",
        )

        # æ›´æ–°å›¾è°±
        updated_graph = await builder.update_graph(
            graph=graph,
            new_entities=[new_entity],
        )

        print("\nğŸ”„ å›¾è°±æ›´æ–°å®Œæˆ:")
        print(f"   - æ›´æ–°åå®ä½“æ•°: {len(updated_graph.entities)}")
        print(f"   - æ›´æ–°åå…³ç³»æ•°: {len(updated_graph.relations)}")

    except Exception as e:
        print(f"âŒ å¯æ›´æ–°æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")


async def example_streaming_builder():
    """
    ç¤ºä¾‹3: æµå¼æ„å»ºå™¨

    é€‚ç”¨åœºæ™¯ï¼š
    - å®æ—¶å¤„ç†æµå¼åˆ°è¾¾çš„æ–‡æ¡£
    - éœ€è¦æ–‡æ¡£çº§åˆ«çš„å¢åˆ æ“ä½œ
    - è¿½æ±‚å¢é‡å¤„ç†èƒ½åŠ›
    """
    print("\n" + "=" * 50)
    print("ğŸŒŠ ç¤ºä¾‹3: LLMæµå¼æ„å»ºå™¨")
    print("=" * 50)

    # åˆ›å»ºæµå¼æ„å»ºå™¨
    builder = StreamingLLMGraphBuilder(
        openai_api_key=settings.OPENAI_API_KEY,
        openai_api_base=settings.OPENAI_API_BASE,
        llm_model=settings.LLM_MODEL,
    )

    # åˆå§‹æ–‡æ¡£
    initial_docs = ["è°·æ­Œå…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½æŠ€æœ¯å…¬å¸ã€‚", "æ‹‰é‡ŒÂ·ä½©å¥‡å’Œè°¢å°”ç›–Â·å¸ƒæ—åˆ›ç«‹äº†è°·æ­Œã€‚"]

    try:
        # æ„å»ºåˆå§‹å›¾è°±
        graph = await builder.build_graph(texts=initial_docs, graph_name="streaming_example_graph")

        print("âœ… æµå¼å›¾è°±åˆå§‹åŒ–:")
        print(f"   - åˆå§‹å®ä½“æ•°: {len(graph.entities)}")

        # æ¨¡æ‹Ÿæ–°æ–‡æ¡£åˆ°è¾¾
        new_documents = ["YouTubeæ˜¯è°·æ­Œæ——ä¸‹çš„è§†é¢‘åˆ†äº«å¹³å°ã€‚", "Androidæ˜¯è°·æ­Œå¼€å‘çš„ç§»åŠ¨æ“ä½œç³»ç»Ÿã€‚"]

        # å¢é‡æ·»åŠ æ–‡æ¡£
        updated_graph = await builder.add_documents_async(
            documents=new_documents, document_ids=["doc_youtube", "doc_android"]
        )

        print("\nğŸ“„ æ–°æ–‡æ¡£å¤„ç†å®Œæˆ:")
        print(f"   - æ›´æ–°åå®ä½“æ•°: {len(updated_graph.entities)}")

        # æŸ¥çœ‹æ–‡æ¡£æ³¨å†Œè¡¨
        registry = builder.get_document_registry()
        print("\nğŸ“š æ–‡æ¡£æ³¨å†Œè¡¨:")
        for doc_id, entity_ids in registry.items():
            print(f"   - {doc_id}: {len(entity_ids)} ä¸ªå®ä½“")

    except Exception as e:
        print(f"âŒ æµå¼æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")


async def example_batch_builder():
    """
    ç¤ºä¾‹4: æ‰¹é‡æ„å»ºå™¨

    é€‚ç”¨åœºæ™¯ï¼š
    - éœ€è¦å¤„ç†å¤§é‡æ–‡æ¡£
    - éœ€è¦åˆå¹¶å¤šä¸ªæ•°æ®æº
    - è¿½æ±‚é«˜æ€§èƒ½æ‰¹é‡å¤„ç†
    """
    print("\n" + "=" * 50)
    print("ğŸ“¦ ç¤ºä¾‹4: LLMæ‰¹é‡æ„å»ºå™¨")
    print("=" * 50)

    # åˆ›å»ºæ‰¹é‡æ„å»ºå™¨
    builder = BatchLLMGraphBuilder(
        openai_api_key=settings.OPENAI_API_KEY,
        openai_api_base=settings.OPENAI_API_BASE,
        llm_model=settings.LLM_MODEL,
        embedding_model=settings.EMBEDDING_MODEL,
        max_concurrent=8,  # é«˜å¹¶å‘æ‰¹é‡å¤„ç†
    )

    # å¤§é‡æ–‡æ¡£ç¤ºä¾‹
    batch_texts = [
        "ç‰¹æ–¯æ‹‰æ˜¯ä¸€å®¶ç¾å›½ç”µåŠ¨æ±½è½¦åˆ¶é€ å•†ã€‚",
        "åŸƒéš†Â·é©¬æ–¯å…‹æ˜¯ç‰¹æ–¯æ‹‰çš„CEOã€‚",
        "Model Sæ˜¯ç‰¹æ–¯æ‹‰çš„è±ªåç”µåŠ¨è½¿è½¦ã€‚",
        "Autopilotæ˜¯ç‰¹æ–¯æ‹‰çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯ã€‚",
        "Gigafactoryæ˜¯ç‰¹æ–¯æ‹‰çš„ç”µæ± å·¥å‚ã€‚",
    ]

    try:
        # æ‰¹é‡æ„å»ºå›¾è°±
        graph = await builder.build_graph(texts=batch_texts, graph_name="batch_example_graph")

        print("âœ… æ‰¹é‡å›¾è°±æ„å»ºå®Œæˆ:")
        print(f"   - å¤„ç†æ–‡æ¡£æ•°: {len(batch_texts)}")
        print(f"   - ç”Ÿæˆå®ä½“æ•°: {len(graph.entities)}")
        print(f"   - ç”Ÿæˆå…³ç³»æ•°: {len(graph.relations)}")

        # æ¼”ç¤ºå¤šæºåˆå¹¶
        sources = [
            {"type": "text", "data": ["äºšé©¬é€Šæ˜¯å…¨çƒæœ€å¤§çš„ç”µå­å•†åŠ¡å…¬å¸ã€‚"]},
            {"type": "text", "data": ["æ°å¤«Â·è´ä½æ–¯åˆ›ç«‹äº†äºšé©¬é€Šå…¬å¸ã€‚"]},
        ]

        merged_graph = await builder.build_from_multiple_sources(sources=sources, graph_name="multi_source_graph")

        print("\nğŸ”— å¤šæºåˆå¹¶å®Œæˆ:")
        print(f"   - åˆå¹¶åå®ä½“æ•°: {len(merged_graph.entities)}")

    except Exception as e:
        print(f"âŒ æ‰¹é‡æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")


async def example_full_featured_builder():
    """
    ç¤ºä¾‹5: å…¨åŠŸèƒ½æ„å»ºå™¨

    é€‚ç”¨åœºæ™¯ï¼š
    - éœ€è¦æ‰€æœ‰åŠŸèƒ½ï¼šæ„å»ºã€æ›´æ–°ã€åˆå¹¶ã€éªŒè¯ã€å¯¼å‡º
    - ä¼ä¸šçº§åº”ç”¨ï¼Œéœ€è¦å®Œæ•´åŠŸèƒ½
    - å¯ä»¥æ‰¿å—é¢å¤–çš„å¤æ‚æ€§å’Œä¾èµ–
    """
    print("\n" + "=" * 50)
    print("ğŸ† ç¤ºä¾‹5: LLMå…¨åŠŸèƒ½æ„å»ºå™¨")
    print("=" * 50)

    # åˆ›å»ºå…¨åŠŸèƒ½æ„å»ºå™¨
    builder = LLMGraphBuilder(
        openai_api_key=settings.OPENAI_API_KEY,
        openai_api_base=settings.OPENAI_API_BASE,
        llm_model=settings.LLM_MODEL,
        embedding_model=settings.EMBEDDING_MODEL,
        max_concurrent=10,
        vector_storage=JsonVectorStorage(file_path="workdir/isp_vector_store.json"),  # å‡è®¾ä½¿ç”¨JSONå­˜å‚¨ä½œä¸ºå‘é‡å­˜å‚¨
    )

    # å¤æ‚æ–‡æ¡£
    complex_texts = [
        "é˜¿é‡Œå·´å·´é›†å›¢æ˜¯ä¸­å›½çš„ä¸€å®¶è·¨å›½æŠ€æœ¯å…¬å¸ã€‚",
        "é©¬äº‘æ˜¯é˜¿é‡Œå·´å·´é›†å›¢çš„åˆ›å§‹äººä¹‹ä¸€ã€‚",
        "æ·˜å®æ˜¯é˜¿é‡Œå·´å·´æ——ä¸‹çš„åœ¨çº¿è´­ç‰©å¹³å°ã€‚",
        "æ”¯ä»˜å®æ˜¯é˜¿é‡Œå·´å·´çš„æ•°å­—æ”¯ä»˜å¹³å°ã€‚",
    ]

    try:
        # æ„å»ºå›¾è°±ï¼ˆè‡ªåŠ¨åŒ…å«åµŒå…¥å’ŒéªŒè¯ï¼‰
        graph = await builder.build_graph(texts=complex_texts, graph_name="full_featured_graph")

        print("âœ… å…¨åŠŸèƒ½å›¾è°±æ„å»ºå®Œæˆ:")
        print(f"   - å®ä½“æ•°é‡: {len(graph.entities)}")
        print(f"   - å…³ç³»æ•°é‡: {len(graph.relations)}")

        # éªŒè¯å›¾è°±
        validation_result = await builder.validate_graph(graph)
        print("\nğŸ” å›¾è°±éªŒè¯ç»“æœ:")
        print(f"   - éªŒè¯é€šè¿‡: {validation_result.get('valid', False)}")
        if validation_result.get("issues"):
            print(f"   - å‘ç°é—®é¢˜: {len(validation_result['issues'])} ä¸ª")

        # å¯¼å‡ºå›¾è°±
        exported_data = await builder.export_to_format(graph, "json")
        print("\nğŸ“¤ å›¾è°±å¯¼å‡º:")
        print("   - å¯¼å‡ºæ ¼å¼: JSON")
        print(f"   - æ•°æ®é”®: {list(exported_data.keys())}")
        with open("workdir/full_featured_graph.json", "w", encoding="utf8") as f:
            import json

            json.dump(exported_data, f, ensure_ascii=False, indent=2)
        # è·å–è¯¦ç»†ç»Ÿè®¡
        detailed_stats = await builder.get_detailed_statistics(graph)
        print("\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
        for key, value in detailed_stats.items():
            if isinstance(value, (int, float)):
                print(f"   - {key}: {value}")

        # æ‰“å°ä½¿ç”¨æ‘˜è¦
        builder.print_usage_summary()

        # æ¸…ç†èµ„æº
        builder.cleanup()

    except Exception as e:
        print(f"âŒ å…¨åŠŸèƒ½æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")


async def example_search_builder():
    """
    ç¤ºä¾‹6: LLMæœç´¢æ„å»ºå™¨

    é€‚ç”¨åœºæ™¯ï¼š
    - éœ€è¦å¯¹å·²æ„å»ºçš„å›¾è°±è¿›è¡Œæ™ºèƒ½æœç´¢
    - åŸºäºé—®é¢˜è¿›è¡Œæ£€ç´¢å’Œé—®ç­”
    - åªéœ€è¦æœç´¢åŠŸèƒ½ï¼Œä¸éœ€è¦æ„å»ºåŠŸèƒ½
    """
    print("\n" + "=" * 50)
    print("ğŸ” ç¤ºä¾‹6: LLMæœç´¢æ„å»ºå™¨")
    print("=" * 50)

    try:
        # é¦–å…ˆåˆ›å»ºä¸€ä¸ªå›¾è°±ç”¨äºæœç´¢æ¼”ç¤º
        print("ğŸ—ï¸ å…ˆæ„å»ºä¸€ä¸ªç¤ºä¾‹å›¾è°±...")
        builder = FlexibleLLMGraphBuilder(
            openai_api_key=settings.OPENAI_API_KEY,
            openai_api_base=settings.OPENAI_API_BASE,
            llm_model=settings.LLM_MODEL,
            embedding_model=settings.EMBEDDING_MODEL,
            vector_storage=JsonVectorStorage(file_path="workdir/search_example_vectors.json"),
        )

        # æ„å»ºä¸€ä¸ªåŒ…å«å¤šç§å®ä½“çš„çŸ¥è¯†å›¾è°±
        knowledge_texts = [
            "OpenAIæ˜¯ä¸€å®¶äººå·¥æ™ºèƒ½ç ”ç©¶å…¬å¸ï¼Œæˆç«‹äº2015å¹´ã€‚",
            "GPT-4æ˜¯OpenAIå¼€å‘çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰å¼ºå¤§çš„è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›ã€‚",
            "ChatGPTæ˜¯åŸºäºGPTæ¨¡å‹çš„å¯¹è¯ç³»ç»Ÿï¼Œèƒ½å¤Ÿè¿›è¡Œæ™ºèƒ½å¯¹è¯ã€‚",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ã€‚",
            "Transformeræ˜¯ä¸€ç§ç¥ç»ç½‘ç»œæ¶æ„ï¼Œè¢«å¹¿æ³›ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚",
            "BERTæ˜¯Googleå¼€å‘çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œæ“…é•¿ç†è§£ä¸Šä¸‹æ–‡ã€‚",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œé€šè¿‡æ•°æ®å­¦ä¹ è§„å¾‹ã€‚",
            "ç¥ç»ç½‘ç»œæ˜¯æ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒå·¥ä½œæ–¹å¼çš„è®¡ç®—æ¨¡å‹ã€‚",
        ]

        graph = await builder.build_graph(texts=knowledge_texts, graph_name="search_example_graph")

        print("âœ… å›¾è°±æ„å»ºå®Œæˆ:")
        print(f"   - å®ä½“æ•°é‡: {len(graph.entities)}")
        print(f"   - å…³ç³»æ•°é‡: {len(graph.relations)}")

        # åˆ›å»ºæœç´¢æ„å»ºå™¨
        search_builder = LLMSearchBuilder(
            graph=graph,
            openai_api_key=settings.OPENAI_API_KEY,
            openai_api_base=settings.OPENAI_API_BASE,
            llm_model=settings.LLM_MODEL,
            embedding_model=settings.EMBEDDING_MODEL,
            vector_storage=JsonVectorStorage(file_path="workdir/search_vectors.json"),
        )

        print("\nğŸ” å¼€å§‹æœç´¢æ¼”ç¤º...")

        # 1. å®ä½“æœç´¢ç¤ºä¾‹
        print("\nğŸ“‹ å®ä½“æœç´¢ç¤ºä¾‹:")
        entity_query = "äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ "
        entities = await search_builder.search_entities(query=entity_query, top_k=3, similarity_threshold=0.6)

        print(f"   æŸ¥è¯¢: '{entity_query}'")
        print(f"   æ‰¾åˆ° {len(entities)} ä¸ªç›¸å…³å®ä½“:")
        for i, entity in enumerate(entities[:3], 1):
            print(f"   {i}. {entity['entity_name']} ({entity['entity_type']})")
            print(f"      ç›¸ä¼¼åº¦: {entity['similarity_score']:.3f}")
            print(f"      æè¿°: {entity['description'][:100]}...")

        # 2. å…³ç³»æœç´¢ç¤ºä¾‹
        print("\nğŸ”— å…³ç³»æœç´¢ç¤ºä¾‹:")
        relation_query = "å¼€å‘å’Œåˆ›å»º"
        relations = await search_builder.search_relations(query=relation_query, top_k=3, similarity_threshold=0.6)

        print(f"   æŸ¥è¯¢: '{relation_query}'")
        print(f"   æ‰¾åˆ° {len(relations)} ä¸ªç›¸å…³å…³ç³»:")
        for i, relation in enumerate(relations[:3], 1):
            head = relation["head_entity"]["name"] if relation["head_entity"] else "Unknown"
            tail = relation["tail_entity"]["name"] if relation["tail_entity"] else "Unknown"
            print(f"   {i}. {head} --({relation['relation_type']})--> {tail}")
            print(f"      ç›¸ä¼¼åº¦: {relation['similarity_score']:.3f}")

        # 3. ç»¼åˆæœç´¢ç¤ºä¾‹
        print("\nğŸ¯ ç»¼åˆæœç´¢ç¤ºä¾‹:")
        search_results = await search_builder.search_graph(
            query="æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œçš„å…³ç³»", search_type="hybrid", top_k=5
        )

        print("   æŸ¥è¯¢: 'æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œçš„å…³ç³»'")
        print(f"   å®ä½“ç»“æœ: {len(search_results['entities'])} ä¸ª")
        print(f"   å…³ç³»ç»“æœ: {len(search_results['relations'])} ä¸ª")

        # 4. æ™ºèƒ½é—®ç­”ç¤ºä¾‹
        print("\nğŸ¤– æ™ºèƒ½é—®ç­”ç¤ºä¾‹:")
        questions = [
            "ä»€ä¹ˆæ˜¯GPT-4ï¼Ÿ",
            "OpenAIå¼€å‘äº†å“ªäº›äº§å“ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ",
            "Transformeræ¶æ„æœ‰ä»€ä¹ˆç”¨é€”ï¼Ÿ",
        ]

        for i, question in enumerate(questions[:2], 1):  # åªæ¼”ç¤ºå‰2ä¸ªé—®é¢˜
            print(f"\n   é—®é¢˜ {i}: {question}")
            answer_result = await search_builder.answer_question(
                question=question, context_entities=3, context_relations=2, include_reasoning=True
            )

            print(f"   å›ç­”: {answer_result['answer']}")
            print(f"   ç½®ä¿¡åº¦: {answer_result['confidence']:.3f}")
            print(f"   ä½¿ç”¨å®ä½“: {answer_result['context']['entities_used']} ä¸ª")
            print(f"   ä½¿ç”¨å…³ç³»: {answer_result['context']['relations_used']} ä¸ª")

            if answer_result.get("reasoning"):
                print(f"   æ¨ç†è¿‡ç¨‹: {answer_result['reasoning'][:200]}...")

        # 5. ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æœç´¢æ„å»ºå™¨ç»Ÿè®¡:")
        stats = search_builder.get_statistics()
        print(f"   - å›¾è°±åç§°: {stats['graph_name']}")
        print(f"   - å®ä½“æ€»æ•°: {stats['entities_count']}")
        print(f"   - å…³ç³»æ€»æ•°: {stats['relations_count']}")
        print(f"   - LLMæ¨¡å‹: {stats['llm_model']}")
        print(f"   - æœç´¢èƒ½åŠ›: {', '.join(stats['search_capabilities'])}")

        # 6. å¯¼å‡ºåŠŸèƒ½æ¼”ç¤º
        print("\nğŸ“¤ å¯¼å‡ºåŠŸèƒ½æ¼”ç¤º:")
        summary = await search_builder.export_to_format(graph, "summary")
        print("   - å›¾è°±æ‘˜è¦å·²ç”Ÿæˆ")
        print(f"   - å®ä½“ç±»å‹: {len(summary['entity_types'])} ç§")
        print(f"   - å…³ç³»ç±»å‹: {len(summary['relation_types'])} ç§")

        # æ¸…ç†èµ„æº
        search_builder.cleanup()
        builder.cleanup()

        print("\nâœ… æœç´¢æ„å»ºå™¨ç¤ºä¾‹å®Œæˆ!")

    except Exception as e:
        print(f"âŒ æœç´¢æ„å»ºå™¨ç¤ºä¾‹å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def main():
    """
    è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    """
    print("ğŸ¯ LLM ISPæ„å»ºå™¨ç¤ºä¾‹é›†åˆ")
    print("æ¼”ç¤ºInterface Segregation Principleåœ¨LLMå›¾æ„å»ºä¸­çš„åº”ç”¨")

    # è¿è¡Œå„ä¸ªç¤ºä¾‹
    # await example_basic_builder()
    # await example_updatable_builder()
    # await example_streaming_builder()
    # await example_batch_builder()
    # await example_full_featured_builder()
    await example_search_builder()

    print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(main())
