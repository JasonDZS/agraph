#!/usr/bin/env python3
"""
AGraph æ–‡æ¡£å¤„ç†ç¤ºä¾‹

æ­¤ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨AGraphä»çœŸå®æ–‡æ¡£æ„å»ºçŸ¥è¯†å›¾è°±ï¼ŒåŒ…æ‹¬ï¼š
1. ä»documentsç›®å½•è¯»å–å„ç§æ ¼å¼çš„æ–‡æ¡£
2. æ„å»ºç»¼åˆçŸ¥è¯†å›¾è°±
3. åŸºäºæ–‡æ¡£å†…å®¹è¿›è¡Œæ™ºèƒ½é—®ç­”
4. æ¼”ç¤ºä¼ä¸šçº§åº”ç”¨åœºæ™¯
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agraph import AGraph, BuilderConfig


class DocumentsDemo:
    """åŸºäºçœŸå®æ–‡æ¡£çš„AGraphæ¼”ç¤º"""

    def __init__(self):
        self.documents_dir = Path(__file__).parent / "documents"
        self.workdir = project_root / "workdir" / "documents_demo"
        self.agraph = None

    async def run_demo(self):
        """è¿è¡Œæ–‡æ¡£å¤„ç†æ¼”ç¤º"""
        print("ğŸ“š AGraphæ–‡æ¡£å¤„ç†ç¤ºä¾‹")
        print("=" * 50)

        # 1. æ£€æŸ¥æ–‡æ¡£ç›®å½•
        if not self.check_documents():
            return

        # 2. åˆå§‹åŒ–ç³»ç»Ÿ
        await self.initialize_system()

        # 3. å¤„ç†æ–‡æ¡£å¹¶æ„å»ºçŸ¥è¯†å›¾è°±
        await self.process_documents()

        # 4. æ¼”ç¤ºä¼ä¸šçŸ¥è¯†é—®ç­”
        await self.demo_enterprise_qa()

        # 5. å±•ç¤ºæœç´¢åŠŸèƒ½
        await self.demo_search_capabilities()

        # 6. ç³»ç»Ÿä¿¡æ¯å±•ç¤º
        await self.show_system_info()

        print("\nâœ… æ–‡æ¡£å¤„ç†æ¼”ç¤ºå®Œæˆ!")

    def check_documents(self) -> bool:
        """æ£€æŸ¥æ–‡æ¡£ç›®å½•å’Œæ–‡ä»¶"""
        print("\nğŸ“‚ 1. æ£€æŸ¥æ–‡æ¡£ç›®å½•...")

        if not self.documents_dir.exists():
            print(f"âŒ æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {self.documents_dir}")
            return False

        # è·å–æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶
        doc_files = []
        supported_extensions = {'.txt', '.md', '.json', '.csv'}  # æš‚æ—¶åªæ”¯æŒè¿™äº›æ ¼å¼

        for file_path in self.documents_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                doc_files.append(file_path)

        if not doc_files:
            print("âŒ æœªæ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶")
            return False

        print(f"âœ… æ‰¾åˆ° {len(doc_files)} ä¸ªæ–‡æ¡£æ–‡ä»¶:")
        for doc in doc_files:
            file_size = doc.stat().st_size
            print(f"   ğŸ“„ {doc.name} ({file_size} bytes)")

        self.doc_files = doc_files
        return True

    async def initialize_system(self):
        """åˆå§‹åŒ–AGraphç³»ç»Ÿ"""
        print("\nâš™ï¸ 2. åˆå§‹åŒ–AGraphç³»ç»Ÿ...")

        # åˆ›å»ºå·¥ä½œç›®å½•
        self.workdir.mkdir(parents=True, exist_ok=True)

        # é…ç½®AGraph
        config = BuilderConfig(
            chunk_size=1000,
            chunk_overlap=200,
            entity_confidence_threshold=0.7,
            relation_confidence_threshold=0.6,
            cache_dir=str(self.workdir / "cache")
        )

        self.agraph = AGraph(
            collection_name="enterprise_documents",
            persist_directory=str(self.workdir / "vectordb"),
            vector_store_type="memory",  # ä½¿ç”¨å†…å­˜å­˜å‚¨è¿›è¡Œæ¼”ç¤º
            config=config,
            use_openai_embeddings=False
        )

        await self.agraph.initialize()
        print("âœ… AGraphç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    async def process_documents(self):
        """å¤„ç†æ–‡æ¡£å¹¶æ„å»ºçŸ¥è¯†å›¾è°±"""
        print("\nğŸ—ï¸ 3. å¤„ç†æ–‡æ¡£å¹¶æ„å»ºçŸ¥è¯†å›¾è°±...")

        try:
            # è¯»å–æ–‡æ¡£å†…å®¹
            document_contents = []
            for doc_file in self.doc_files:
                try:
                    with open(doc_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        document_contents.append(content)
                        print(f"   ğŸ“– è¯»å–: {doc_file.name} ({len(content)} å­—ç¬¦)")
                except UnicodeDecodeError:
                    # å°è¯•å…¶ä»–ç¼–ç 
                    try:
                        with open(doc_file, 'r', encoding='gbk') as f:
                            content = f.read()
                            document_contents.append(content)
                            print(f"   ğŸ“– è¯»å–: {doc_file.name} ({len(content)} å­—ç¬¦, GBKç¼–ç )")
                    except Exception as e:
                        print(f"   âš ï¸  è·³è¿‡æ–‡ä»¶ {doc_file.name}: {e}")
                except Exception as e:
                    print(f"   âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {doc_file.name}: {e}")

            if not document_contents:
                print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡æ¡£å†…å®¹")
                return

            print(f"\nğŸ”¨ å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°± (å…±{len(document_contents)}ä¸ªæ–‡æ¡£)...")

            # ä»æ–‡æ¡£å†…å®¹æ„å»ºçŸ¥è¯†å›¾è°±
            try:
                knowledge_graph = self.agraph.build_from_texts(
                    texts=document_contents,
                    graph_name="ä¼ä¸šæ–‡æ¡£çŸ¥è¯†å›¾è°±",
                    graph_description="åŸºäºä¼ä¸šå†…éƒ¨æ–‡æ¡£æ„å»ºçš„ç»¼åˆçŸ¥è¯†å›¾è°±",
                    save_to_vector_store=True
                )

                print("âœ… çŸ¥è¯†å›¾è°±æ„å»ºæˆåŠŸ!")
                print(f"   ğŸ·ï¸  å®ä½“æ•°é‡: {len(knowledge_graph.entities)}")
                print(f"   ğŸ”— å…³ç³»æ•°é‡: {len(knowledge_graph.relations)}")
                print(f"   ğŸ“„ æ–‡æœ¬å—æ•°é‡: {len(knowledge_graph.text_chunks)}")

                # æ˜¾ç¤ºæå–çš„å…³é”®å®ä½“
                if knowledge_graph.entities:
                    print("\nğŸ” æå–çš„å…³é”®å®ä½“:")
                    entities_by_type = {}
                    for entity_id, entity in knowledge_graph.entities.items():
                        entity_type = entity.entity_type.value if hasattr(entity.entity_type, 'value') else str(entity.entity_type)
                        if entity_type not in entities_by_type:
                            entities_by_type[entity_type] = []
                        entities_by_type[entity_type].append(entity.name)

                    for entity_type, names in entities_by_type.items():
                        print(f"   ğŸ“‹ {entity_type}: {', '.join(names[:5])}" +
                              (f" (åŠå…¶ä»–{len(names)-5}ä¸ª)" if len(names) > 5 else ""))

            except Exception as e:
                print(f"âš ï¸  çŸ¥è¯†å›¾è°±æ„å»ºé‡åˆ°é—®é¢˜: {e}")
                print("ğŸ“ åˆ›å»ºåŸºç¡€æ•°æ®ç»“æ„ç»§ç»­æ¼”ç¤º...")
                await self.create_fallback_data(document_contents)

        except Exception as e:
            print(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")

    async def create_fallback_data(self, document_contents):
        """åˆ›å»ºå¤‡ç”¨æ•°æ®ç»“æ„"""
        from agraph.base.entities import Entity
        from agraph.base.text import TextChunk
        from agraph.base.types import EntityType

        # ä»æ–‡æ¡£å†…å®¹ä¸­æå–å…³é”®è¯ä½œä¸ºå®ä½“
        entities = [
            Entity(name="äººå·¥æ™ºèƒ½", entity_type=EntityType.CONCEPT,
                  description="AIæŠ€æœ¯æ¦‚å¿µ", confidence=0.9),
            Entity(name="å…¬å¸", entity_type=EntityType.ORGANIZATION,
                  description="ä¼ä¸šç»„ç»‡", confidence=0.85),
            Entity(name="åŒ—äº¬å¸‚", entity_type=EntityType.LOCATION,
                  description="å…¬å¸æ‰€åœ¨åœ°", confidence=0.8),
            Entity(name="æ•°æ®åˆ†æ", entity_type=EntityType.CONCEPT,
                  description="æ•°æ®å¤„ç†æŠ€æœ¯", confidence=0.85),
        ]

        # åˆ›å»ºæ–‡æœ¬å—
        text_chunks = []
        for i, content in enumerate(document_contents[:3]):  # åªå–å‰3ä¸ªæ–‡æ¡£
            chunk = TextChunk(
                content=content[:500] + "..." if len(content) > 500 else content,
                title=f"æ–‡æ¡£{i+1}",
                source=f"doc_{i+1}",
                start_index=0,
                end_index=min(500, len(content))
            )
            text_chunks.append(chunk)

        # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        if self.agraph.vector_store:
            await self.agraph.vector_store.batch_add_entities(entities)
            await self.agraph.vector_store.batch_add_text_chunks(text_chunks)

        print("âœ… å¤‡ç”¨æ•°æ®ç»“æ„åˆ›å»ºå®Œæˆ")

    async def demo_enterprise_qa(self):
        """æ¼”ç¤ºä¼ä¸šçŸ¥è¯†é—®ç­”"""
        print("\nğŸ’¼ 4. ä¼ä¸šçŸ¥è¯†é—®ç­”æ¼”ç¤º...")

        # åŸºäºæ–‡æ¡£å†…å®¹çš„å®é™…é—®é¢˜
        questions = [
            "å…¬å¸çš„ä¸»è¦ä¸šåŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å…¬å¸æˆç«‹äºä»€ä¹ˆæ—¶å€™ï¼Ÿ",
            "å…¬å¸æ€»éƒ¨åœ¨å“ªé‡Œï¼Ÿ",
            "å›¢é˜Ÿæœ‰å¤šå°‘äººï¼Ÿ",
            "å…¬å¸çš„æ ¸å¿ƒæŠ€æœ¯æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å…¬å¸çš„æ„¿æ™¯æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]

        print("åŸºäºä¼ä¸šæ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜:\n")

        for i, question in enumerate(questions):
            print(f"â“ é—®é¢˜ {i+1}: {question}")

            try:
                response = await self.agraph.chat(
                    question=question,
                    entity_top_k=5,
                    relation_top_k=3,
                    text_chunk_top_k=3,
                    response_type="è¯¦ç»†å›ç­”"
                )

                answer = response['answer']
                print(f"ğŸ¤– å›ç­”: {answer}")

                # æ˜¾ç¤ºå¼•ç”¨ä¿¡æ¯
                context = response['context']
                if context.get('text_chunks'):
                    sources = []
                    for item in context['text_chunks'][:2]:
                        chunk = item['text_chunk']
                        sources.append(f"{chunk.title or chunk.source}")
                    if sources:
                        print(f"ğŸ“š å‚è€ƒæ–‡æ¡£: {', '.join(sources)}")

                print()

            except Exception as e:
                print(f"ğŸ¤– å›ç­”: æŠ±æ­‰ï¼Œæ— æ³•å›ç­”æ­¤é—®é¢˜: {e}\n")

    async def demo_search_capabilities(self):
        """æ¼”ç¤ºæœç´¢èƒ½åŠ›"""
        print("\nğŸ” 5. æœç´¢åŠŸèƒ½æ¼”ç¤º...")

        search_terms = ["äººå·¥æ™ºèƒ½", "æ•°æ®åˆ†æ", "æŠ€æœ¯å›¢é˜Ÿ", "åŒ—äº¬"]

        for term in search_terms:
            print(f"\nğŸ” æœç´¢å…³é”®è¯: '{term}'")

            try:
                # æœç´¢å®ä½“
                entities = await self.agraph.search_entities(term, top_k=3)
                if entities:
                    print("   ğŸ“‹ ç›¸å…³å®ä½“:")
                    for entity, score in entities:
                        print(f"      - {entity.name} ({entity.entity_type}) [ç›¸ä¼¼åº¦: {score:.3f}]")

                # æœç´¢æ–‡æ¡£
                text_chunks = await self.agraph.search_text_chunks(term, top_k=2)
                if text_chunks:
                    print("   ğŸ“„ ç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
                    for chunk, score in text_chunks:
                        preview = chunk.content[:80].replace('\n', ' ') + "..." if len(chunk.content) > 80 else chunk.content.replace('\n', ' ')
                        print(f"      - {preview} [ç›¸ä¼¼åº¦: {score:.3f}]")

                if not entities and not text_chunks:
                    print("   ğŸ” æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")

            except Exception as e:
                print(f"   âŒ æœç´¢å¤±è´¥: {e}")

    async def show_system_info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        print("\nğŸ“Š 6. ç³»ç»Ÿä¿¡æ¯...")

        try:
            stats = await self.agraph.get_stats()

            # å‘é‡å­˜å‚¨ç»Ÿè®¡
            if 'vector_store' in stats:
                vs_stats = stats['vector_store']
                print("ğŸ—‚ï¸  å‘é‡å­˜å‚¨ç»Ÿè®¡:")
                print(f"   - å®ä½“: {vs_stats.get('entities', 0)}")
                print(f"   - å…³ç³»: {vs_stats.get('relations', 0)}")
                print(f"   - æ–‡æœ¬å—: {vs_stats.get('text_chunks', 0)}")

            # çŸ¥è¯†å›¾è°±ç»Ÿè®¡
            if 'knowledge_graph' in stats:
                kg_stats = stats['knowledge_graph']
                print("\nğŸ•¸ï¸  çŸ¥è¯†å›¾è°±ç»Ÿè®¡:")
                for key, value in kg_stats.items():
                    print(f"   - {key}: {value}")

            # ç³»ç»ŸçŠ¶æ€
            print(f"\nâš™ï¸  ç³»ç»ŸçŠ¶æ€:")
            print(f"   - é›†åˆåç§°: {self.agraph.collection_name}")
            print(f"   - å­˜å‚¨ç±»å‹: {self.agraph.vector_store_type}")
            print(f"   - å·²åˆå§‹åŒ–: {self.agraph.is_initialized}")
            print(f"   - æœ‰çŸ¥è¯†å›¾è°±: {self.agraph.has_knowledge_graph}")

        except Exception as e:
            print(f"âŒ è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {e}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.agraph:
            await self.agraph.close()


async def main():
    """ä¸»å‡½æ•°"""
    demo = DocumentsDemo()

    try:
        await demo.run_demo()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await demo.cleanup()


if __name__ == "__main__":
    print("ğŸ“š å¯åŠ¨AGraphæ–‡æ¡£å¤„ç†æ¼”ç¤º...")
    print("ğŸ“Œ æ­¤æ¼”ç¤ºå°†å¤„ç†examples/documents/ç›®å½•ä¸­çš„æ–‡æ¡£æ–‡ä»¶")
    print("â±ï¸  å¤„ç†æ—¶é—´å–å†³äºæ–‡æ¡£æ•°é‡å’Œå¤§å°\n")

    if sys.version_info < (3, 7):
        print("âŒ éœ€è¦Python 3.7+ç‰ˆæœ¬")
        sys.exit(1)

    asyncio.run(main())
