#!/usr/bin/env python3
"""
AGraph å®Œæ•´ç¤ºä¾‹ï¼šçŸ¥è¯†å›¾è°±æ„å»ºã€å‘é‡å­˜å‚¨å’Œæ™ºèƒ½å¯¹è¯

æ­¤ç¤ºä¾‹å±•ç¤ºäº†AGraphçš„å®Œæ•´åŠŸèƒ½ï¼š
1. ä»æ–‡æ¡£æ„å»ºçŸ¥è¯†å›¾è°±
2. ä¿å­˜åˆ°å‘é‡å­˜å‚¨
3. è¿›è¡Œæ™ºèƒ½æ£€ç´¢
4. çŸ¥è¯†åº“å¯¹è¯
5. ç³»ç»Ÿç®¡ç†å’Œç›‘æ§
"""

import asyncio
import os
import sys
from pathlib import Path
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

from agraph import AGraph, BuilderConfig


class AGraphDemo:
    """AGraphåŠŸèƒ½æ¼”ç¤ºç±»"""

    def __init__(self):
        self.agraph: AGraph = None
        self.demo_data_dir = Path(__file__).parent / "demo_data"
        self.workdir = project_root / "workdir" / "agraph_complete_demo"

        # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
        os.makedirs(self.workdir, exist_ok=True)
        os.makedirs(self.demo_data_dir, exist_ok=True)

    async def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸš€ AGraph å®Œæ•´åŠŸèƒ½æ¼”ç¤º")
        print("=" * 60)

        # 1. åˆå§‹åŒ–ç³»ç»Ÿ
        await self.initialize_agraph()

        # 2. å‡†å¤‡æ¼”ç¤ºæ•°æ®
        self.prepare_demo_data()

        # 3. æ¼”ç¤ºçŸ¥è¯†å›¾è°±æ„å»º
        await self.demo_knowledge_graph_building()

        # 4. æ¼”ç¤ºå‘é‡æ£€ç´¢åŠŸèƒ½
        await self.demo_vector_search()

        # 5. æ¼”ç¤ºæ™ºèƒ½å¯¹è¯
        await self.demo_intelligent_chat()

        # 6. æ¼”ç¤ºç³»ç»Ÿç®¡ç†
        await self.demo_system_management()

        # 7. æ¸…ç†èµ„æº
        await self.cleanup()

        print("\nâœ… AGraphå®Œæ•´æ¼”ç¤ºå®Œæˆï¼")

    async def initialize_agraph(self):
        """åˆå§‹åŒ–AGraphç³»ç»Ÿ"""
        print("\nğŸ“¦ 1. åˆå§‹åŒ–AGraphç³»ç»Ÿ")
        print("-" * 30)

        # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
        config = BuilderConfig(
            chunk_size=800,
            chunk_overlap=150,
            entity_confidence_threshold=0.75,
            relation_confidence_threshold=0.65,
            llm_provider="openai",
            llm_model="gpt-3.5-turbo",
            cluster_algorithm="community_detection",
            cache_dir=str(self.workdir / "cache")
        )

        # åˆ›å»ºAGraphå®ä¾‹
        self.agraph = AGraph(
            collection_name="demo_knowledge_base",
            persist_directory=str(self.workdir / "vectordb"),
            vector_store_type="memory",  # ä½¿ç”¨å†…å­˜å­˜å‚¨è¿›è¡Œæ¼”ç¤º
            config=config,
            use_openai_embeddings=False  # é¿å…APIä¾èµ–
        )

        # åˆå§‹åŒ–ç³»ç»Ÿ
        await self.agraph.initialize()

        print("âœ… AGraphç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        print(f"   - é›†åˆåç§°: {self.agraph.collection_name}")
        print(f"   - å­˜å‚¨ç±»å‹: {self.agraph.vector_store_type}")
        print(f"   - å·¥ä½œç›®å½•: {self.workdir}")

    def prepare_demo_data(self):
        """å‡†å¤‡æ¼”ç¤ºæ•°æ®"""
        print("\nğŸ“ 2. å‡†å¤‡æ¼”ç¤ºæ•°æ®")
        print("-" * 30)

        # åˆ›å»ºæ¼”ç¤ºæ–‡æœ¬æ•°æ®
        demo_texts = [
            # ç§‘æŠ€å…¬å¸ä¿¡æ¯
            "è‹¹æœå…¬å¸ï¼ˆApple Inc.ï¼‰æ˜¯ä¸€å®¶ç¾å›½è·¨å›½ç§‘æŠ€å…¬å¸ï¼Œæ€»éƒ¨ä½äºåŠ åˆ©ç¦å°¼äºšå·åº“æ¯”è’‚è¯ºã€‚å…¬å¸è®¾è®¡ã€å¼€å‘å’Œé”€å”®æ¶ˆè´¹ç”µå­äº§å“ã€è®¡ç®—æœºè½¯ä»¶å’Œåœ¨çº¿æœåŠ¡ã€‚",

            "å²è’‚å¤«Â·ä¹”å¸ƒæ–¯ï¼ˆSteve Jobsï¼‰å’Œå²è’‚å¤«Â·æ²ƒå…¹å°¼äºšå…‹ï¼ˆSteve Wozniakï¼‰äº1976å¹´4æœˆ1æ—¥åˆ›ç«‹äº†è‹¹æœå…¬å¸ã€‚ä¹”å¸ƒæ–¯æ‹…ä»»é¦–å¸­æ‰§è¡Œå®˜ï¼Œæ¨åŠ¨äº†å…¬å¸çš„åˆ›æ–°å‘å±•ã€‚",

            "iPhoneæ˜¯è‹¹æœå…¬å¸å¼€å‘çš„æ™ºèƒ½æ‰‹æœºç³»åˆ—ï¼Œé¦–æ¬¾iPhoneäº2007å¹´1æœˆ9æ—¥å‘å¸ƒã€‚iPhoneé©å‘½æ€§åœ°æ”¹å˜äº†ç§»åŠ¨é€šä¿¡è¡Œä¸šï¼Œæˆä¸ºæ™ºèƒ½æ‰‹æœºçš„æ ‡æ†äº§å“ã€‚",

            "iPadæ˜¯è‹¹æœå…¬å¸çš„å¹³æ¿ç”µè„‘äº§å“çº¿ï¼Œäº2010å¹´é¦–æ¬¡å‘å¸ƒã€‚iPadå¼€åˆ›äº†ç°ä»£å¹³æ¿ç”µè„‘å¸‚åœºï¼Œå¹¿æ³›åº”ç”¨äºæ•™è‚²ã€å•†åŠ¡å’Œå¨±ä¹é¢†åŸŸã€‚",

            # ç«äº‰å¯¹æ‰‹ä¿¡æ¯
            "å¾®è½¯å…¬å¸ï¼ˆMicrosoft Corporationï¼‰æ˜¯è‹¹æœå…¬å¸çš„ä¸»è¦ç«äº‰å¯¹æ‰‹ä¹‹ä¸€ï¼Œä¸“æ³¨äºè½¯ä»¶ã€æœåŠ¡å’Œè§£å†³æ–¹æ¡ˆã€‚å¾®è½¯ç”±æ¯”å°”Â·ç›–èŒ¨å’Œä¿ç½—Â·è‰¾ä¼¦äº1975å¹´åˆ›ç«‹ã€‚",

            "è°·æ­Œå…¬å¸ï¼ˆGoogle LLCï¼‰å¼€å‘äº†Androidæ“ä½œç³»ç»Ÿï¼Œä¸è‹¹æœçš„iOSå½¢æˆç«äº‰å…³ç³»ã€‚Androidæ˜¯å…¨çƒä½¿ç”¨æœ€å¹¿æ³›çš„ç§»åŠ¨æ“ä½œç³»ç»Ÿã€‚",

            # äº§å“æŠ€æœ¯ä¿¡æ¯
            "iOSæ˜¯è‹¹æœå…¬å¸ä¸ºiPhoneå’ŒiPadå¼€å‘çš„ç§»åŠ¨æ“ä½œç³»ç»Ÿã€‚iOSä»¥å…¶æµç•…çš„ç”¨æˆ·ä½“éªŒå’Œå¼ºå¤§çš„å®‰å…¨æ€§è‘—ç§°ã€‚",

            "è‹¹æœå…¬å¸çš„Aç³»åˆ—èŠ¯ç‰‡æ˜¯ä¸“é—¨ä¸ºiPhoneå’ŒiPadè®¾è®¡çš„å¤„ç†å™¨ã€‚Aç³»åˆ—èŠ¯ç‰‡åœ¨æ€§èƒ½å’Œèƒ½è€—æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚",

            # å•†ä¸šä¿¡æ¯
            "è‹¹æœå…¬å¸æ˜¯å…¨çƒå¸‚å€¼æœ€é«˜çš„ç§‘æŠ€å…¬å¸ä¹‹ä¸€ï¼Œå…¶äº§å“åœ¨å…¨çƒèŒƒå›´å†…äº«æœ‰å¾ˆé«˜çš„å“ç‰Œå¿ è¯šåº¦ã€‚",

            "åº“æ¯”è’‚è¯ºå¸‚æ˜¯è‹¹æœå…¬å¸æ€»éƒ¨æ‰€åœ¨åœ°ï¼Œä¹Ÿæ˜¯ç¡…è°·çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚ç¡…è°·èšé›†äº†ä¼—å¤šç§‘æŠ€å…¬å¸å’Œåˆ›æ–°ä¼ä¸šã€‚"
        ]

        # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿä»æ–‡æ¡£è¯»å–ï¼‰
        for i, text in enumerate(demo_texts):
            file_path = self.demo_data_dir / f"demo_doc_{i+1}.txt"
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(text)

        self.demo_texts = demo_texts
        self.demo_files = list(self.demo_data_dir.glob("demo_doc_*.txt"))

        print(f"âœ… å‡†å¤‡äº† {len(demo_texts)} ä¸ªæ¼”ç¤ºæ–‡æœ¬")
        print(f"âœ… åˆ›å»ºäº† {len(self.demo_files)} ä¸ªæ¼”ç¤ºæ–‡æ¡£")

    async def demo_knowledge_graph_building(self):
        """æ¼”ç¤ºçŸ¥è¯†å›¾è°±æ„å»º"""
        print("\nğŸ—ï¸ 3. çŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤º")
        print("-" * 30)

        try:
            print("3.1 ä»æ–‡æœ¬æ„å»ºçŸ¥è¯†å›¾è°±...")

            # ä»æ–‡æœ¬æ„å»ºçŸ¥è¯†å›¾è°±
            kg = self.agraph.build_from_texts(
                texts=self.demo_texts,
                graph_name="ç§‘æŠ€è¡Œä¸šçŸ¥è¯†å›¾è°±",
                graph_description="åŸºäºç§‘æŠ€å…¬å¸å’Œäº§å“ä¿¡æ¯æ„å»ºçš„çŸ¥è¯†å›¾è°±",
                save_to_vector_store=False  # ç¨åæ‰‹åŠ¨ä¿å­˜
            )

            print("âœ… çŸ¥è¯†å›¾è°±æ„å»ºæˆåŠŸï¼")
            print(f"   - å®ä½“æ•°é‡: {len(kg.entities)}")
            print(f"   - å…³ç³»æ•°é‡: {len(kg.relations)}")
            print(f"   - èšç±»æ•°é‡: {len(kg.clusters)}")
            print(f"   - æ–‡æœ¬å—æ•°é‡: {len(kg.text_chunks)}")

            # æ˜¾ç¤ºéƒ¨åˆ†å®ä½“
            if kg.entities:
                print("\nğŸ“‹ æå–çš„å®ä½“æ ·ä¾‹:")
                for i, (entity_id, entity) in enumerate(list(kg.entities.items())[:8]):
                    print(f"   {i+1}. {entity.name} ({entity.entity_type}) - ç½®ä¿¡åº¦: {entity.confidence:.2f}")

            # æ˜¾ç¤ºéƒ¨åˆ†å…³ç³»
            if kg.relations:
                print("\nğŸ”— æå–çš„å…³ç³»æ ·ä¾‹:")
                for i, (rel_id, relation) in enumerate(list(kg.relations.items())[:5]):
                    head_name = relation.head_entity.name if relation.head_entity else "æœªçŸ¥"
                    tail_name = relation.tail_entity.name if relation.tail_entity else "æœªçŸ¥"
                    print(f"   {i+1}. {head_name} --[{relation.relation_type}]--> {tail_name}")

            # ä¿å­˜åˆ°å‘é‡å­˜å‚¨
            print("\nğŸ’¾ ä¿å­˜çŸ¥è¯†å›¾è°±åˆ°å‘é‡å­˜å‚¨...")
            await self.agraph.save_knowledge_graph()
            print("âœ… ä¿å­˜å®Œæˆ")

        except Exception as e:
            print(f"âŒ çŸ¥è¯†å›¾è°±æ„å»ºå¤±è´¥: {e}")
            # ä½¿ç”¨æ–‡æœ¬æ„å»ºä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            print("ğŸ“ ä½¿ç”¨ç®€åŒ–æ–‡æœ¬æ„å»ºå¤‡é€‰æ–¹æ¡ˆ...")
            await self.create_fallback_data()

    async def create_fallback_data(self):
        """åˆ›å»ºå¤‡é€‰æ¼”ç¤ºæ•°æ®"""
        from agraph.base.entities import Entity
        from agraph.base.relations import Relation
        from agraph.base.text import TextChunk
        from agraph.base.types import EntityType, RelationType

        # åˆ›å»ºæ¼”ç¤ºå®ä½“
        entities = [
            Entity(name="è‹¹æœå…¬å¸", entity_type=EntityType.ORGANIZATION,
                  description="ç¾å›½ç§‘æŠ€å…¬å¸", confidence=0.95),
            Entity(name="å²è’‚å¤«Â·ä¹”å¸ƒæ–¯", entity_type=EntityType.PERSON,
                  description="è‹¹æœå…¬å¸è”åˆåˆ›å§‹äºº", confidence=0.90),
            Entity(name="iPhone", entity_type=EntityType.PRODUCT,
                  description="æ™ºèƒ½æ‰‹æœºäº§å“", confidence=0.85),
            Entity(name="å¾®è½¯å…¬å¸", entity_type=EntityType.ORGANIZATION,
                  description="è½¯ä»¶å…¬å¸", confidence=0.90),
            Entity(name="åº“æ¯”è’‚è¯º", entity_type=EntityType.LOCATION,
                  description="è‹¹æœå…¬å¸æ€»éƒ¨æ‰€åœ¨åœ°", confidence=0.80)
        ]

        # åˆ›å»ºæ¼”ç¤ºå…³ç³»
        relations = [
            Relation(head_entity=entities[1], tail_entity=entities[0],
                    relation_type=RelationType.FOUNDED_BY, confidence=0.90),
            Relation(head_entity=entities[0], tail_entity=entities[2],
                    relation_type=RelationType.DEVELOPS, confidence=0.85),
            Relation(head_entity=entities[0], tail_entity=entities[4],
                    relation_type=RelationType.LOCATED_IN, confidence=0.80)
        ]

        # åˆ›å»ºæ¼”ç¤ºæ–‡æœ¬å—
        text_chunks = [
            TextChunk(content=text[:200] + "..." if len(text) > 200 else text,
                     title=f"æ¼”ç¤ºæ–‡æ¡£{i+1}", source=f"demo_doc_{i+1}",
                     start_index=0, end_index=len(text))
            for i, text in enumerate(self.demo_texts[:5])
        ]

        # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        if self.agraph.vector_store:
            await self.agraph.vector_store.batch_add_entities(entities)
            await self.agraph.vector_store.batch_add_relations(relations)
            await self.agraph.vector_store.batch_add_text_chunks(text_chunks)

        print("âœ… å¤‡é€‰æ¼”ç¤ºæ•°æ®åˆ›å»ºå®Œæˆ")

    async def demo_vector_search(self):
        """æ¼”ç¤ºå‘é‡æ£€ç´¢åŠŸèƒ½"""
        print("\nğŸ” 4. å‘é‡æ£€ç´¢åŠŸèƒ½æ¼”ç¤º")
        print("-" * 30)

        # å®šä¹‰æœç´¢æŸ¥è¯¢
        search_queries = [
            ("è‹¹æœå…¬å¸", "å®ä½“"),
            ("åˆ›å§‹äºº", "å…³ç³»"),
            ("æ™ºèƒ½æ‰‹æœº", "æ–‡æœ¬å—")
        ]

        for query, search_type in search_queries:
            print(f"\n4.{search_queries.index((query, search_type)) + 1} æœç´¢'{query}' ({search_type})")

            try:
                if search_type == "å®ä½“":
                    results = await self.agraph.search_entities(query, top_k=3)
                    print(f"   æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³å®ä½“:")
                    for entity, score in results:
                        print(f"   - {entity.name} ({entity.entity_type}) [ç›¸ä¼¼åº¦: {score:.3f}]")

                elif search_type == "å…³ç³»":
                    results = await self.agraph.search_relations(query, top_k=3)
                    print(f"   æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³å…³ç³»:")
                    for relation, score in results:
                        head_name = relation.head_entity.name if relation.head_entity else "æœªçŸ¥"
                        tail_name = relation.tail_entity.name if relation.tail_entity else "æœªçŸ¥"
                        print(f"   - {head_name} --[{relation.relation_type}]--> {tail_name} [ç›¸ä¼¼åº¦: {score:.3f}]")

                else:  # æ–‡æœ¬å—
                    results = await self.agraph.search_text_chunks(query, top_k=3)
                    print(f"   æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æœ¬å—:")
                    for chunk, score in results:
                        preview = chunk.content[:80] + "..." if len(chunk.content) > 80 else chunk.content
                        print(f"   - {preview} [ç›¸ä¼¼åº¦: {score:.3f}]")

            except Exception as e:
                print(f"   âŒ æœç´¢å¤±è´¥: {e}")

    async def demo_intelligent_chat(self):
        """æ¼”ç¤ºæ™ºèƒ½å¯¹è¯åŠŸèƒ½"""
        print("\nğŸ’¬ 5. æ™ºèƒ½å¯¹è¯åŠŸèƒ½æ¼”ç¤º")
        print("-" * 30)

        # é¢„å®šä¹‰çš„é—®é¢˜å’ŒæœŸæœ›ç±»å‹
        questions = [
            ("è‹¹æœå…¬å¸æ˜¯ä»€ä¹ˆï¼Ÿ", "ç®€æ´å›ç­”"),
            ("è‹¹æœå…¬å¸çš„åˆ›å§‹äººæ˜¯è°ï¼Ÿ", "è¯¦ç»†å›ç­”"),
            ("iPhoneä»€ä¹ˆæ—¶å€™å‘å¸ƒçš„ï¼Ÿ", "ç®€æ´å›ç­”"),
            ("è‹¹æœå…¬å¸å’Œå¾®è½¯å…¬å¸æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ", "è¯¦ç»†å›ç­”")
        ]

        conversation_history = []

        for i, (question, response_type) in enumerate(questions):
            print(f"\n5.{i+1} é—®ç­”æ¼”ç¤º")
            print(f"ğŸ‘¤ ç”¨æˆ·: {question}")

            try:
                response = await self.agraph.chat(
                    question=question,
                    conversation_history=conversation_history,
                    entity_top_k=3,
                    relation_top_k=2,
                    text_chunk_top_k=3,
                    response_type=response_type
                )

                answer = response["answer"]
                print(f"ğŸ¤– åŠ©æ‰‹: {answer}")

                # æ˜¾ç¤ºæ£€ç´¢ä¸Šä¸‹æ–‡ç»Ÿè®¡
                context = response["context"]
                entities_count = len(context.get("entities", []))
                relations_count = len(context.get("relations", []))
                chunks_count = len(context.get("text_chunks", []))

                print(f"ğŸ“Š æ£€ç´¢ç»Ÿè®¡: {entities_count}ä¸ªå®ä½“, {relations_count}ä¸ªå…³ç³», {chunks_count}ä¸ªæ–‡æ¡£")

                # æ›´æ–°å¯¹è¯å†å²
                conversation_history.append({
                    "user": question,
                    "assistant": answer
                })

                # æ˜¾ç¤ºéƒ¨åˆ†æ£€ç´¢ç»“æœ
                if entities_count > 0:
                    print("ğŸ·ï¸  ç›¸å…³å®ä½“:", end=" ")
                    entity_names = [item["entity"].name for item in context["entities"][:2]]
                    print(", ".join(entity_names))

            except Exception as e:
                print(f"ğŸ¤– åŠ©æ‰‹: æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯: {e}")

        print(f"\nâœ… å®Œæˆäº† {len(questions)} è½®å¯¹è¯æ¼”ç¤º")

    async def demo_system_management(self):
        """æ¼”ç¤ºç³»ç»Ÿç®¡ç†åŠŸèƒ½"""
        print("\nâš™ï¸ 6. ç³»ç»Ÿç®¡ç†åŠŸèƒ½æ¼”ç¤º")
        print("-" * 30)

        try:
            # è·å–ç³»ç»Ÿç»Ÿè®¡
            stats = await self.agraph.get_stats()

            print("6.1 ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯:")

            # å‘é‡å­˜å‚¨ç»Ÿè®¡
            if "vector_store" in stats:
                vs_stats = stats["vector_store"]
                print("ğŸ“Š å‘é‡å­˜å‚¨:")
                for key, value in vs_stats.items():
                    print(f"   - {key}: {value}")

            # çŸ¥è¯†å›¾è°±ç»Ÿè®¡
            if "knowledge_graph" in stats:
                kg_stats = stats["knowledge_graph"]
                print("ğŸ•¸ï¸  çŸ¥è¯†å›¾è°±:")
                for key, value in kg_stats.items():
                    print(f"   - {key}: {value}")

            # æ„å»ºå™¨ç»Ÿè®¡
            if "builder" in stats:
                builder_stats = stats["builder"]
                print("ğŸ—ï¸  æ„å»ºå™¨:")
                if "build_status" in builder_stats:
                    build_status = builder_stats["build_status"]
                    print(f"   - æ„å»ºè¿›åº¦: {build_status.get('progress', 0):.1f}%")
                    print(f"   - å®Œæˆæ­¥éª¤: {build_status.get('completed_steps', 0)}/{build_status.get('total_steps', 6)}")

                if "cache_info" in builder_stats:
                    cache_info = builder_stats["cache_info"]
                    if "backend" in cache_info:
                        backend_info = cache_info["backend"]
                        print(f"   - ç¼“å­˜æ–‡ä»¶: {backend_info.get('total_files', 0)}")
                        print(f"   - ç¼“å­˜å¤§å°: {backend_info.get('total_size', 0)} bytes")

            # æ¼”ç¤ºå±æ€§æ£€æŸ¥
            print("\n6.2 ç³»ç»ŸçŠ¶æ€:")
            print(f"âœ… å·²åˆå§‹åŒ–: {self.agraph.is_initialized}")
            print(f"âœ… æœ‰çŸ¥è¯†å›¾è°±: {self.agraph.has_knowledge_graph}")
            print(f"ğŸ“‚ é›†åˆåç§°: {self.agraph.collection_name}")
            print(f"ğŸ’¾ å­˜å‚¨ç±»å‹: {self.agraph.vector_store_type}")

        except Exception as e:
            print(f"âŒ è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {e}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\nğŸ§¹ 7. èµ„æºæ¸…ç†")
        print("-" * 30)

        try:
            # æ¸…é™¤æ•°æ®ï¼ˆå¯é€‰ï¼‰
            print("æ¸…ç†æ¼”ç¤ºæ•°æ®...")
            # await self.agraph.clear_all()

            # å…³é—­ç³»ç»Ÿ
            print("å…³é—­AGraphç³»ç»Ÿ...")
            await self.agraph.close()

            # æ¸…ç†æ¼”ç¤ºæ–‡ä»¶
            print("æ¸…ç†æ¼”ç¤ºæ–‡ä»¶...")
            if self.demo_data_dir.exists():
                import shutil
                shutil.rmtree(self.demo_data_dir)

            print("âœ… èµ„æºæ¸…ç†å®Œæˆ")

        except Exception as e:
            print(f"âš ï¸  æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°è­¦å‘Š: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    demo = AGraphDemo()

    try:
        await demo.run_complete_demo()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ç¡®ä¿èµ„æºæ¸…ç†
        if demo.agraph and demo.agraph.is_initialized:
            await demo.agraph.close()


if __name__ == "__main__":
    print("ğŸ¯ å¯åŠ¨AGraphå®Œæ•´åŠŸèƒ½æ¼”ç¤º...")
    print("ğŸ“Œ æç¤º: è¿™ä¸ªæ¼”ç¤ºå°†å±•ç¤ºAGraphçš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½")
    print("â±ï¸  æ¼”ç¤ºå¤§çº¦éœ€è¦2-3åˆ†é’Ÿæ—¶é—´")
    print()

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 7):
        print("âŒ éœ€è¦Python 3.7+ç‰ˆæœ¬")
        sys.exit(1)

    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main())
