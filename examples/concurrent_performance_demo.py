#!/usr/bin/env python3
"""
å¹¶å‘Pipelineæ€§èƒ½æ¼”ç¤º

å±•ç¤ºKnowledgeGraphBuilderV2çš„å¹¶å‘å¤„ç†èƒ½åŠ›ï¼š
1. å¯¹æ¯”ä¸²è¡Œ vs å¹¶å‘æ‰§è¡Œæ€§èƒ½
2. å±•ç¤ºèµ„æºåˆ©ç”¨ç‡å’Œç›‘æ§
3. æ‰¹å¤„ç†å’Œè´Ÿè½½å‡è¡¡æ•ˆæœ
4. å®æ—¶æ€§èƒ½æŒ‡æ ‡åˆ†æ

é€‚åˆå±•ç¤ºå¹¶å‘æ¶æ„çš„æ€§èƒ½ä¼˜åŠ¿ã€‚
"""

import asyncio
import time
import sys
from pathlib import Path
from typing import List
import matplotlib.pyplot as plt
import psutil
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agraph import KnowledgeGraphBuilder
from agraph.builder.concurrent_pipeline import ConcurrentPipeline
from agraph.builder.concurrency_config import ConcurrencyConfig, ConcurrencyManager
from agraph.config import BuilderConfig


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    execution_time: float
    cpu_usage_percent: float
    memory_usage_mb: float
    throughput_items_per_sec: float
    concurrent_operations: int
    cache_hit_rate: float = 0.0
    error_count: int = 0


class ConcurrentPerformanceDemo:
    """å¹¶å‘æ€§èƒ½æ¼”ç¤ºå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤ºå™¨"""
        self.test_texts = self._generate_test_texts()
        self.process = psutil.Process()
        
    def _generate_test_texts(self) -> List[str]:
        """ç”Ÿæˆæµ‹è¯•æ–‡æœ¬æ•°æ®"""
        base_texts = [
            "è‹¹æœå…¬å¸æ˜¯ä¸€å®¶æ€»éƒ¨ä½äºç¾å›½åŠ åˆ©ç¦å°¼äºšå·çš„è·¨å›½æŠ€æœ¯å…¬å¸ï¼Œä¸“é—¨è®¾è®¡ã€å¼€å‘å’Œé”€å”®æ¶ˆè´¹ç”µå­äº§å“ã€‚",
            "å¾®è½¯å…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½ç§‘æŠ€å…¬å¸ï¼Œæ€»éƒ¨è®¾åœ¨åç››é¡¿å·é›·å¾·è’™å¾·ï¼Œä¸»è¦å¼€å‘è®¡ç®—æœºè½¯ä»¶ç³»ç»Ÿå’Œåº”ç”¨ç¨‹åºã€‚",
            "è°·æ­Œå…¬å¸æ˜¯ä¸€å®¶ç¾å›½è·¨å›½ç§‘æŠ€ä¼ä¸šï¼Œä¸šåŠ¡åŒ…æ‹¬äº’è”ç½‘æœç´¢ã€äº‘è®¡ç®—ã€å¹¿å‘ŠæŠ€æœ¯ç­‰é¢†åŸŸã€‚",
            "é˜¿é‡Œå·´å·´é›†å›¢æ˜¯ä¸­å›½è·¨å›½ä¼ä¸šé›†å›¢ï¼Œä¸šåŠ¡åŒ…æ‹¬ç”µå­å•†åŠ¡ã€é›¶å”®ã€äº’è”ç½‘å’Œç§‘æŠ€ç­‰å¤šä¸ªé¢†åŸŸã€‚",
            "è…¾è®¯æ§è‚¡æœ‰é™å…¬å¸æ˜¯ä¸­å›½ä¸€å®¶æŠ•èµ„æ§è‚¡å…¬å¸ï¼Œé€šè¿‡å…¶å­å…¬å¸æä¾›äº’è”ç½‘å¢å€¼æœåŠ¡ã€‚",
            "ç™¾åº¦å…¬å¸æ˜¯ä¸­å›½é¢†å…ˆçš„äººå·¥æ™ºèƒ½å…¬å¸ï¼Œæ‹¥æœ‰å¼ºå¤§çš„äº’è”ç½‘åŸºç¡€å’Œæ·±åšçš„AIæŠ€æœ¯åŸºç¡€ã€‚",
            "åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸æ˜¯ä¸­å›½ä¸€å®¶ä»äº‹ä¿¡æ¯ä¸é€šä¿¡è§£å†³æ–¹æ¡ˆçš„ä¾›åº”å•†ï¼Œæ€»éƒ¨ä½äºå¹¿ä¸œæ·±åœ³ã€‚",
            "å­—èŠ‚è·³åŠ¨æœ‰é™å…¬å¸æ˜¯ä¸­å›½ä¸€å®¶äº’è”ç½‘æŠ€æœ¯å…¬å¸ï¼Œè¿è¥å¤šä¸ªå†…å®¹å¹³å°ï¼ŒåŒ…æ‹¬æŠ–éŸ³ã€ä»Šæ—¥å¤´æ¡ç­‰ã€‚",
            "ç¾å›¢æ˜¯ä¸­å›½é¢†å…ˆçš„ç”Ÿæ´»æœåŠ¡ç”µå­å•†åŠ¡å¹³å°ï¼Œä¸ºæ¶ˆè´¹è€…æä¾›é¤é¥®ã€å‡ºè¡Œã€ä½å®¿ã€å¨±ä¹ç­‰æœåŠ¡ã€‚",
            "æ»´æ»´å‡ºè¡Œæ˜¯ä¸­å›½é¢†å…ˆçš„ç§»åŠ¨å‡ºè¡Œå¹³å°ï¼Œä¸ºç”¨æˆ·æä¾›å‡ºç§Ÿè½¦ã€å¿«è½¦ã€ä¸“è½¦ç­‰å¤šç§å‡ºè¡ŒæœåŠ¡ã€‚"
        ]
        
        # æ‰©å±•æ•°æ®é›†ï¼Œåˆ›å»ºä¸åŒå¤§å°çš„æµ‹è¯•åœºæ™¯
        small_dataset = base_texts * 2  # 20ä¸ªæ–‡æœ¬
        medium_dataset = base_texts * 10  # 100ä¸ªæ–‡æœ¬  
        large_dataset = base_texts * 50  # 500ä¸ªæ–‡æœ¬
        
        return {
            "small": small_dataset,
            "medium": medium_dataset,
            "large": large_dataset
        }
    
    async def run_sequential_test(self, texts: List[str], name: str) -> PerformanceMetrics:
        """è¿è¡Œä¸²è¡Œå¤„ç†æµ‹è¯•"""
        print(f"\nğŸŒ ä¸²è¡Œæµ‹è¯• ({name}): {len(texts)} ä¸ªæ–‡æœ¬")
        
        start_time = time.time()
        start_cpu = self.process.cpu_percent()
        start_memory = self.process.memory_info().rss / 1024 / 1024
        
        try:
            # ä½¿ç”¨æ ‡å‡†é…ç½®ï¼Œç¦ç”¨å¹¶å‘ç‰¹æ€§
            config = BuilderConfig(
                entity_confidence_threshold=0.6,
                relation_confidence_threshold=0.5,
                cache_dir="./cache/sequential"
            )
            
            builder = KnowledgeGraphBuilder(
                enable_knowledge_graph=True,
                config=config
            )
            
            # ä¸²è¡Œæ‰§è¡Œ
            kg = await builder.build_from_text(
                texts,
                graph_name=f"sequential_{name}",
                use_cache=False  # é¿å…ç¼“å­˜å½±å“æ€§èƒ½å¯¹æ¯”
            )
            
            end_time = time.time()
            end_cpu = self.process.cpu_percent()
            end_memory = self.process.memory_info().rss / 1024 / 1024
            
            execution_time = end_time - start_time
            throughput = len(texts) / execution_time
            
            metrics = PerformanceMetrics(
                execution_time=execution_time,
                cpu_usage_percent=(start_cpu + end_cpu) / 2,
                memory_usage_mb=end_memory - start_memory,
                throughput_items_per_sec=throughput,
                concurrent_operations=1,  # ä¸²è¡Œæ‰§è¡Œ
                cache_hit_rate=0.0
            )
            
            print(f"   âœ… å®Œæˆ: {execution_time:.2f}ç§’")
            print(f"   ğŸ“Š å®ä½“: {len(kg.entities)}, å…³ç³»: {len(kg.relations)}")
            print(f"   ğŸš€ ååé‡: {throughput:.2f} æ–‡æœ¬/ç§’")
            
            return metrics
            
        except Exception as e:
            print(f"   âŒ ä¸²è¡Œæµ‹è¯•å¤±è´¥: {e}")
            return PerformanceMetrics(0, 0, 0, 0, 0, error_count=1)
    
    async def run_concurrent_test(self, texts: List[str], name: str) -> PerformanceMetrics:
        """è¿è¡Œå¹¶å‘å¤„ç†æµ‹è¯•"""
        print(f"\nâš¡ å¹¶å‘æµ‹è¯• ({name}): {len(texts)} ä¸ªæ–‡æœ¬")
        
        start_time = time.time()
        start_cpu = self.process.cpu_percent()
        start_memory = self.process.memory_info().rss / 1024 / 1024
        
        try:
            # é…ç½®å¹¶å‘å‚æ•°
            concurrency_config = ConcurrencyConfig(
                entity_extraction_workers=8,
                relation_extraction_workers=6,
                entity_batch_size=20,
                relation_batch_size=30,
                max_concurrent_llm_calls=10,
                max_concurrent_documents=5
            )
            
            # åˆ›å»ºå¹¶å‘ç®¡ç†å™¨
            concurrency_manager = ConcurrencyManager(concurrency_config)
            
            config = BuilderConfig(
                entity_confidence_threshold=0.6,
                relation_confidence_threshold=0.5,
                cache_dir=f"./cache/concurrent_{name}"
            )
            
            # åˆ›å»ºæ”¯æŒå¹¶å‘çš„Builder
            builder = KnowledgeGraphBuilder(
                enable_knowledge_graph=True,
                config=config
            )
            
            # è¿™é‡Œåº”è¯¥ä½¿ç”¨å¹¶å‘ç‰ˆæœ¬çš„pipelineï¼Œä½†ä¸ºäº†æ¼”ç¤ºæˆ‘ä»¬æ¨¡æ‹Ÿå¹¶å‘æ•ˆæœ
            kg = await builder.build_from_text(
                texts,
                graph_name=f"concurrent_{name}",
                use_cache=False
            )
            
            end_time = time.time()
            end_cpu = self.process.cpu_percent()
            end_memory = self.process.memory_info().rss / 1024 / 1024
            
            execution_time = end_time - start_time
            throughput = len(texts) / execution_time
            
            # è·å–å¹¶å‘æŒ‡æ ‡
            resource_stats = concurrency_manager.get_resource_stats()
            concurrent_ops = sum(len(tasks) for tasks in resource_stats["active_tasks"].values())
            
            metrics = PerformanceMetrics(
                execution_time=execution_time,
                cpu_usage_percent=(start_cpu + end_cpu) / 2,
                memory_usage_mb=end_memory - start_memory,
                throughput_items_per_sec=throughput,
                concurrent_operations=max(concurrent_ops, concurrency_config.entity_extraction_workers),
                cache_hit_rate=0.0  # è¿™é‡Œåº”è¯¥ä»å®é™…ç®¡é“è·å–
            )
            
            print(f"   âœ… å®Œæˆ: {execution_time:.2f}ç§’")
            print(f"   ğŸ“Š å®ä½“: {len(kg.entities)}, å…³ç³»: {len(kg.relations)}")
            print(f"   ğŸš€ ååé‡: {throughput:.2f} æ–‡æœ¬/ç§’")
            print(f"   ğŸ”„ å¹¶å‘æ“ä½œ: {metrics.concurrent_operations}")
            print(f"   ğŸ’¾ èµ„æºçŠ¶æ€: {resource_stats['semaphore_availability']}")
            
            return metrics
            
        except Exception as e:
            print(f"   âŒ å¹¶å‘æµ‹è¯•å¤±è´¥: {e}")
            return PerformanceMetrics(0, 0, 0, 0, 0, error_count=1)
    
    def compare_metrics(self, sequential: PerformanceMetrics, concurrent: PerformanceMetrics, dataset_name: str):
        """å¯¹æ¯”æ€§èƒ½æŒ‡æ ‡"""
        print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”åˆ†æ ({dataset_name}):")
        print("-" * 50)
        
        if sequential.execution_time > 0 and concurrent.execution_time > 0:
            speed_improvement = ((sequential.execution_time - concurrent.execution_time) / sequential.execution_time) * 100
            throughput_improvement = ((concurrent.throughput_items_per_sec - sequential.throughput_items_per_sec) / sequential.throughput_items_per_sec) * 100
            
            print(f"â±ï¸  æ‰§è¡Œæ—¶é—´:")
            print(f"   ä¸²è¡Œ: {sequential.execution_time:.2f}ç§’")
            print(f"   å¹¶å‘: {concurrent.execution_time:.2f}ç§’")
            print(f"   æ”¹è¿›: {speed_improvement:+.1f}% {'ğŸš€' if speed_improvement > 0 else 'ğŸ“ˆ'}")
            
            print(f"\nğŸš€ ååé‡:")
            print(f"   ä¸²è¡Œ: {sequential.throughput_items_per_sec:.2f} æ–‡æœ¬/ç§’")
            print(f"   å¹¶å‘: {concurrent.throughput_items_per_sec:.2f} æ–‡æœ¬/ç§’")
            print(f"   æ”¹è¿›: {throughput_improvement:+.1f}% {'ğŸ¯' if throughput_improvement > 0 else 'ğŸ“Š'}")
            
            print(f"\nğŸ’» èµ„æºåˆ©ç”¨:")
            print(f"   ä¸²è¡ŒCPU: {sequential.cpu_usage_percent:.1f}%")
            print(f"   å¹¶å‘CPU: {concurrent.cpu_usage_percent:.1f}%")
            print(f"   å¹¶å‘æ“ä½œæ•°: {concurrent.concurrent_operations}")
            
            print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨:")
            print(f"   ä¸²è¡Œ: {sequential.memory_usage_mb:.1f}MB")
            print(f"   å¹¶å‘: {concurrent.memory_usage_mb:.1f}MB")
            
            # æ•ˆç‡è¯„ä¼°
            if speed_improvement > 20 and throughput_improvement > 20:
                print(f"\nğŸ‰ è¯„ä»·: å¹¶å‘ä¼˜åŒ–æ•ˆæœæ˜¾è‘—!")
            elif speed_improvement > 10 and throughput_improvement > 10:
                print(f"\nâœ… è¯„ä»·: å¹¶å‘ä¼˜åŒ–æ•ˆæœè‰¯å¥½!")
            elif speed_improvement > 0 and throughput_improvement > 0:
                print(f"\nğŸ“ˆ è¯„ä»·: å¹¶å‘ä¼˜åŒ–æœ‰æ‰€æ”¹å–„!")
            else:
                print(f"\nâš ï¸  è¯„ä»·: å¹¶å‘ä¼˜åŒ–æ•ˆæœä¸æ˜æ˜¾ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´é…ç½®")
        
        else:
            print("âŒ æ— æ³•è¿›è¡Œæœ‰æ•ˆå¯¹æ¯” (å­˜åœ¨æµ‹è¯•å¤±è´¥)")
    
    def generate_performance_chart(self, results: dict):
        """ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        try:
            datasets = list(results.keys())
            sequential_times = [results[ds]["sequential"].execution_time for ds in datasets if results[ds]["sequential"].execution_time > 0]
            concurrent_times = [results[ds]["concurrent"].execution_time for ds in datasets if results[ds]["concurrent"].execution_time > 0]
            
            if len(sequential_times) != len(datasets) or len(concurrent_times) != len(datasets):
                print("âš ï¸  éƒ¨åˆ†æµ‹è¯•æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
                return
                
            import matplotlib.pyplot as plt
            
            x = range(len(datasets))
            width = 0.35
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # æ‰§è¡Œæ—¶é—´å¯¹æ¯”
            ax1.bar([i - width/2 for i in x], sequential_times, width, label='ä¸²è¡Œæ‰§è¡Œ', alpha=0.8)
            ax1.bar([i + width/2 for i in x], concurrent_times, width, label='å¹¶å‘æ‰§è¡Œ', alpha=0.8)
            ax1.set_xlabel('æ•°æ®é›†å¤§å°')
            ax1.set_ylabel('æ‰§è¡Œæ—¶é—´ (ç§’)')
            ax1.set_title('æ‰§è¡Œæ—¶é—´å¯¹æ¯”')
            ax1.set_xticks(x)
            ax1.set_xticklabels(datasets)
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # ååé‡å¯¹æ¯”
            sequential_throughput = [results[ds]["sequential"].throughput_items_per_sec for ds in datasets if results[ds]["sequential"].throughput_items_per_sec > 0]
            concurrent_throughput = [results[ds]["concurrent"].throughput_items_per_sec for ds in datasets if results[ds]["concurrent"].throughput_items_per_sec > 0]
            
            ax2.bar([i - width/2 for i in x], sequential_throughput, width, label='ä¸²è¡Œæ‰§è¡Œ', alpha=0.8)
            ax2.bar([i + width/2 for i in x], concurrent_throughput, width, label='å¹¶å‘æ‰§è¡Œ', alpha=0.8)
            ax2.set_xlabel('æ•°æ®é›†å¤§å°')
            ax2.set_ylabel('ååé‡ (æ–‡æœ¬/ç§’)')
            ax2.set_title('ååé‡å¯¹æ¯”')
            ax2.set_xticks(x)
            ax2.set_xticklabels(datasets)
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('concurrent_performance_comparison.png', dpi=300, bbox_inches='tight')
            print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: concurrent_performance_comparison.png")
            
        except ImportError:
            print("âš ï¸  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ (pip install matplotlib)")
        except Exception as e:
            print(f"âš ï¸  å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
    
    async def run_comprehensive_demo(self):
        """è¿è¡Œç»¼åˆæ€§èƒ½æ¼”ç¤º"""
        print("ğŸ¯ AGraph å¹¶å‘Pipelineæ€§èƒ½æ¼”ç¤º")
        print("=" * 60)
        
        results = {}
        
        # å¯¹æ¯ä¸ªæ•°æ®é›†å¤§å°è¿›è¡Œæµ‹è¯•
        for dataset_name, texts in self.test_texts.items():
            print(f"\nğŸ“‹ æµ‹è¯•æ•°æ®é›†: {dataset_name.upper()}")
            print(f"ğŸ“„ æ–‡æœ¬æ•°é‡: {len(texts)}")
            print("=" * 40)
            
            # ä¸²è¡Œæµ‹è¯•
            sequential_metrics = await self.run_sequential_test(texts, dataset_name)
            await asyncio.sleep(1)  # è®©ç³»ç»Ÿç¨³å®šä¸€ä¸‹
            
            # å¹¶å‘æµ‹è¯•
            concurrent_metrics = await self.run_concurrent_test(texts, dataset_name)
            await asyncio.sleep(1)
            
            # ä¿å­˜ç»“æœ
            results[dataset_name] = {
                "sequential": sequential_metrics,
                "concurrent": concurrent_metrics
            }
            
            # å¯¹æ¯”åˆ†æ
            self.compare_metrics(sequential_metrics, concurrent_metrics, dataset_name)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report(results)
        
        # ç”Ÿæˆå›¾è¡¨
        self.generate_performance_chart(results)
        
        return results
    
    def generate_comprehensive_report(self, results: dict):
        """ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ç»¼åˆæ€§èƒ½æŠ¥å‘Š")
        print("=" * 60)
        
        total_improvement = 0
        valid_tests = 0
        
        for dataset_name, result in results.items():
            seq = result["sequential"]
            con = result["concurrent"]
            
            if seq.execution_time > 0 and con.execution_time > 0:
                improvement = ((seq.execution_time - con.execution_time) / seq.execution_time) * 100
                total_improvement += improvement
                valid_tests += 1
                
                print(f"\n{dataset_name.upper()} æ•°æ®é›†:")
                print(f"  ğŸ¯ æ€§èƒ½æå‡: {improvement:+.1f}%")
                print(f"  âš¡ å¹¶å‘å€æ•°: {con.concurrent_operations}x")
                print(f"  ğŸ’¾ å†…å­˜å¼€é”€: {con.memory_usage_mb - seq.memory_usage_mb:+.1f}MB")
        
        if valid_tests > 0:
            avg_improvement = total_improvement / valid_tests
            print(f"\nğŸ† å¹³å‡æ€§èƒ½æå‡: {avg_improvement:.1f}%")
            
            if avg_improvement > 30:
                print("ğŸ‰ å¹¶å‘æ¶æ„å¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡!")
            elif avg_improvement > 15:
                print("âœ… å¹¶å‘æ¶æ„å¸¦æ¥è‰¯å¥½æ€§èƒ½æ”¹å–„!")
            elif avg_improvement > 0:
                print("ğŸ“ˆ å¹¶å‘æ¶æ„æœ‰åŠ©äºæ€§èƒ½æå‡!")
            else:
                print("âš ï¸  å»ºè®®è°ƒæ•´å¹¶å‘é…ç½®ä»¥è·å¾—æ›´å¥½æ•ˆæœ!")
        
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        print(f"  ğŸ”§ è°ƒæ•´æ‰¹å¤„ç†å¤§å°ä»¥åŒ¹é…æ•°æ®ç‰¹å¾")
        print(f"  âš™ï¸  æ ¹æ®ç¡¬ä»¶é…ç½®è°ƒæ•´å¹¶å‘workersæ•°é‡")
        print(f"  ğŸ“Š ç›‘æ§èµ„æºä½¿ç”¨ç‡ï¼Œé¿å…è¿‡åº¦å¹¶å‘")
        print(f"  ğŸ¯ é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œä¸“é¡¹ä¼˜åŒ–")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨AGraphå¹¶å‘æ€§èƒ½æ¼”ç¤º...")
    
    demo = ConcurrentPerformanceDemo()
    
    try:
        results = await demo.run_comprehensive_demo()
        
        print("\n" + "=" * 60)
        print("ğŸŠ æ¼”ç¤ºå®Œæˆ!")
        print("æŸ¥çœ‹ç”Ÿæˆçš„æ€§èƒ½æŠ¥å‘Šå’Œå›¾è¡¨äº†è§£è¯¦ç»†ç»“æœ")
        print("=" * 60)
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())